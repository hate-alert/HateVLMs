{"img": "/kaggle/input/bhm-dataset/BHM/Memes/tangaila (119).jpg", "text": "-\u0996\u09be\u09ac\u09be\u09b0 \u09ac\u0987\u09b8\u09be \u09ab\u09cb\u09a8 \u099f\u09bf\u09aa\u09b8 \u0995\u09c7\u09a8 ?? \u0986\u09b0 \u099f\u09bf\u09aa\u09ac\u09bf \u09a8\u09be...  \u0986\u09ae\u09bf\u0983- \u0986\u09ae\u09be\u09b0 \u098f\u0987 \u09ac\u09be\u099c\u09c7 \u09b8\u09cd\u09ac\u09ad\u09be\u09ac \u0995\u09cb\u09a8\u09cb \u09a6\u09bf\u09a8 \u09af\u09be\u09ac\u09c7 \u09a8\u09be ! ", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The meme is a picture of a man with a caption that is written in a foreign language. The caption is asking if the man is hateful or not.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/ovodro_img (988).jpg", "text": "\u0986\u099c \u09b0\u09be\u09a4\u09c7 9:00 \u098f\u09b0 \u09b8\u09ae\u09df \u09b8\u09ac\u09be\u0987 \u09b2\u09be\u0987\u099f \u09ac\u09a8\u09cd\u09a7 \u0995\u09b0\u09c7 \u09ae\u09cb\u09ae\u09ac\u09be\u09a4\u09bf , \u09aa\u09cd\u09b0\u09a6\u09bf\u09aa \u099c\u09be\u09b2\u09be\u09ac\u09c7\u09a8    \u09b2\u09c7 \u09ad\u0995\u09cd\u09a4 ---   oh fuck yeah spread the news", "label": 1}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The image is a meme that is not hateful, it is a political joke. The meme is a picture of a woman with a caption that says "Oh, you know you're a news channel when you're the first to break the news." The woman in the picture is not actually a news anchor, but the caption is a play on words.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/bangla-memes (24).jpg", "text": "No Caption", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The image is a meme that is not hateful, it is just a group of people in a street with a few logos and a caption.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/ovodro_img (978).jpg", "text": "A rare picture of \u09ac\u09be\u0982\u09b2\u09be\u09b0 \u09b0\u09c1\u09aa ", "label": 1}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The meme is not hateful, it is just a picture of a person with a caption that says 'a rare picture of'.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/Halal Memes (297).jpg", "text": "A playboy have only 4 moods   1) Horny     2) Horny     3) Party time with boys     4)    And also horny ", "label": 1}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The image is a meme that is not hateful, it is a playboy meme. The meme is a playboy meme, and it is not hateful.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/ovodro_img (29).jpg", "text": "\u0986\u09ae\u09bf \u09b8\u09c7\u09b0\u09be \u09a7\u09c1\u09b0 \u09ac\u09be\u09b2 \u09a4\u09c1\u0987 \u09b8\u09be\u09ae\u09a8\u09c7 \u09ac\u09be\u0981\u09a7\u09b2\u09c7 \u09b2\u09cb\u0995\u09c7\u09b0 \u09af\u09be\u09a4\u09cd\u09b0\u09be \u0996\u09be\u09b0\u09be\u09aa \u09b9\u09df    \u09a4\u09cb\u0995\u09c7 \u09a4\u09cb \u09b2\u09cb\u0995\u09c7 \u09b9\u09cb\u09df\u09be\u0987\u099f \u09aa\u09c1\u09b8\u09bf \u09ac\u09b2\u09c7    \u09b6\u09be\u09b2\u09be \u09a4\u09c1\u099a\u09bf\u09df\u09be ", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The meme is not hateful, it is just a funny picture of cats with different captions.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/CM (535).jpg", "text": "\u0997\u09b0\u09ae \u0995\u09be\u09b2\u09c7\u0993 \u0995\u09be\u0981\u09a5\u09be   \u0997\u09be\u09df\u09c7 \u09a6\u09c7\u0993\u09df\u09be \u09ae\u09be\u09a8\u09c1\u09b7*      \u09b6\u09df\u09a4\u09be\u09a8* ", "label": 1}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The meme is not hateful, it is not-hateful.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/nurani-memes (158).jpg", "text": "When no one gives you   \u09aa\u09cd\u09b0\u09c7\u09ae\u09bf\u0995\u09be\u09b0 \u09ad\u09be\u09b2\u09cb\u09ac\u09be\u09b8\u09be ", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The Office meme with the caption 'when no one gives you a hug' is not hateful. It is a funny meme that is not intended to harm or mock anyone.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/ovodro_img (672).jpg", "text": "\u09af\u0996\u09a8 \u0985\u0982\u0995 \u0995\u09b0\u09a4\u09c7 \u0995\u09b0\u09a4\u09c7 \u09b9\u09a0\u09be\u09a4 \u098f\u0995\u099f\u09be \u0985\u0982\u0995 \u0986\u099f\u0995\u09c7 \u09af\u09be\u09df \u0986\u09b0 \u0989\u09a4\u09cd\u09a4\u09b0 \u09a4\u09c1\u09ae\u09bf \u0995\u09bf\u099b\u09c1\u09a4\u09c7\u0987 \u09ae\u09bf\u09b2\u09be\u09a4\u09c7 \u09aa\u09be\u09b0\u09cb \u09a8\u09be     Oh my God !    it is so hard ! ", "label": 1}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The meme is not hateful, it is just a joke.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/chintashil (428).jpg", "text": "Me to \u0995\u09be\u0981\u09a0\u09be\u09b2   Oh dear , oh dear. Gorgeous.      Me to \u0995\u09be\u0981\u09a0\u09be\u09b2\u09c7\u09b0 Smell:  You fucking donkey.   ", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The meme is not hateful, it is just a funny joke. The man in the meme is not being hateful towards the girl, he is just making a funny comment.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/ovodro_img (175).jpg", "text": "\u099a\u09b2 \u09b8\u09bf\u09a8\u09c7\u09ae\u09be \u09a6\u09c7\u0996\u09a4\u09c7 \u09af\u09be\u09ac   \u099f\u09bf\u0995\u09bf\u099f \u0995\u09cb\u09a8 \u09b6\u09cd\u09b0\u09c7\u09a3\u09bf\u09b0 \u0995\u09be\u099f\u09ac\u09c7 ?    \u098f\u0995\u09a6\u09ae \u0995\u09b0\u09cd\u09a8\u09be\u09b0\u09c7\u09b0 \u09a6\u09c1\u099f\u09cb \u099f\u09bf\u0995\u09bf\u099f \u0995\u09be\u099f\u09ac...   \u09a8\u09be \u09ac\u09be\u09ac\u09be \u09a8\u09be \u0964  \u0995\u09b0\u09cd\u09a8\u09be\u09b0\u09c7\u09b0 \u099f\u09bf\u0995\u09bf\u099f \u0995\u09be\u099f\u09b2\u09cb \u099b\u09c7\u09b2\u09c7\u09b0\u09be \u099c\u09a8\u09bf \u09b8\u09bf\u09a8\u09cd\u09b8 \u09b9\u09df\u09c7 \u09af\u09be\u09df ", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The meme is not hateful, it is just a funny joke.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/tangaila (340).jpg", "text": "\u09ac\u09be\u09b0\u09cd\u09b8\u09cb\u09b2\u09cb\u09a8\u09be\u09b0 \u09af\u09be \u0995\u09bf\u099b\u09c1 \u09ae\u09b9\u09be\u09a8 \u09b8\u09c3\u09b7\u09cd\u099f\u09bf \u099a\u09bf\u09b0 \u0995\u09b2\u09cd\u09af\u09be\u09a3\u0995\u09b0    \u0985\u09b0\u09cd\u09a7\u09c7\u0995 \u09a4\u09be\u09b0 \u0995\u09b0\u09bf\u09df\u09be\u099b\u09c7 \u09ae\u09c7\u09b8\u09bf \u0985\u09b0\u09cd\u09a7\u09c7\u0995 \u09a4\u09be\u09b0 \u09ac\u09be\u0995\u09bf \u09b8\u09ac\u09be\u0987 ", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The image is a meme that is not hateful, it is not intended to denigrate, vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/ovodro_img (522).jpg", "text": "\u09a8\u09c1\u09b8\u09b0\u09be\u09a4 \u09e9\u09ec \u0995\u09c7 \u0987\u0982\u09b2\u09bf\u09b6\u09c7 \u0995\u09a4 \u09ac\u09b2\u09c7 ?   \u09e9\u09ec \u0995\u09c7 \u0987\u0982\u09b2\u09bf\u09b6\u09c7 34 \u09ac\u09b2\u09c7   \u098f\u0987 \u09a4\u09cb \u0986\u09ae\u09be\u09b0 \u09a6\u09b2\u09c7\u09b0 \u09b2\u09cb\u0995 \u09aa\u09c7\u09df\u09c7 \u0997\u09c7\u099b\u09bf ", "label": 1}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The image is a meme that is not hateful, it is a political joke.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/KAM (208).png", "text": "\u0985\u09a8\u09c7\u0995 \u09b8\u09ae\u09df \u09b6\u09c1\u09a8\u09bf \u09ac\u09dc \u09ac\u09cb\u09a8 \u09b0\u09c7 \u09a6\u09c7\u0996\u09a4\u09c7 \u09af\u09be\u0987\u09df\u09be \u099b\u09cb\u099f \u09ac\u09cb\u09a8 \u09b0\u09c7 \u09ac\u09bf\u09df\u09be \u0995\u0987\u09b0\u09be \u09a8\u09bf\u09df\u09be \u0997\u09c7\u09b8\u09c7! \u0995\u09bf\u09a8\u09cd\u09a4 \u09b6\u09be\u09b2\u09be\u09b0 \u09ac\u09dc \u09ad\u09be\u0987\u09b0\u09c7 \u09a6\u09c7\u0996\u09a4\u09c7 \u0997\u09c7\u09b2\u09c7 \u098f\u09ae\u09a8 \u09b9\u09df \u09a8\u09be \u0995\u09c7\u09b0\u09c7?", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The image is a meme that is not hateful, it is a funny joke.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/nurani-memes (15).jpg", "text": "When u r bargaining with a goru bepari and some other bepari comes and say  \"\u09ad\u09be\u0987 \u09a8\u09bf\u09df\u09be \u09a8\u09c7\u09a8, \u09a6\u09be\u09ae \u0995\u09bf\u09a8\u09cd\u09a4\u09c1 \u09ac\u09c7\u09b6\u09bf \u099a\u09be\u09df \u09a8\u09be\u0987 \"   \u09a4\u09cb\u09ae\u09be\u0995\u09c7 \u09a4\u09cb \u09a1\u09be\u0995\u09bf \u09a8\u09bf ", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The meme is a cartoon of a man with a window behind him, and the caption is in Hindi. The cartoon is a meme that is not hateful, but it is a joke that is not meant to be taken seriously.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/nurani-memes (225).jpg", "text": "Winter is here !     Winter is here, when i say Winter is here . ", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The meme is not hateful, it is just a joke.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/chosha (49).jpg", "text": "Don't cry baby  \u0995\u09be\u09a6\u09c7\u09a8\u09be \u09ac\u09be\u09ac\u09c1   \u09a8\u09c1\u09a8\u09c1 \u0995\u09be\u09a8\u09cd\u09a6\u09bf\u09b8 \u09a8\u09be, \u09a4\u09cb\u0995\u09c7 \u09ac\u09c7\u09b2\u09c1\u09a8 \u0995\u09bf\u09a8\u09c7 \u09a6\u09bf\u09ac\u09cb ", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The meme is a cartoon of a bear with the caption "don't cry baby." The bear is wearing a shirt that says "hateful" in a foreign language. The meme is not hateful, but it is a cartoon of a bear with a caption that is meant to be humorous.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/chosha (56).jpg", "text": "\u09aa\u09b0\u09cd\u09a3 \u09b9\u09b2\u09cb \u098f\u09ae\u09a8 \u098f\u0995 \u09b8\u09bf\u09a8\u09c7\u09ae\u09be    \u09af\u09c7\u0996\u09be\u09a8\u09c7 \u09ae\u09be\u09b0\u09be\u09ae\u09be\u09b0\u09bf \u09a8\u09c7\u0987 \u0996\u09c1\u09a8\u0996\u09be\u09b0\u09be\u09ac\u09bf \u09a8\u09c7\u0987 \u09b6\u09c1\u09a7\u09c1 \u09b6\u09bf\u0995\u09cd\u09b7\u09be\u09ae\u09c1\u09b2\u0995 \u09a6\u09bf\u0995 \u0986\u099b\u09c7 \u09af\u09be \u0986\u09ae\u09be\u09a6\u09c7\u09b0 \u09ad\u09ac\u09bf\u09b7\u09cd\u09af\u09a4\u09c7 \u0995\u09be\u099c\u09c7 \u09b2\u09be\u0997\u09ac\u09c7  ", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The image is a meme that is not hateful, it is a funny picture of a man with a speech bubble pointing at something. The meme is not hateful, it is just a funny image.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/chintashil (499).jpg", "text": "\u09ab\u09c1\u09b2\u099f\u09bf \u099d\u09dc\u09c7 \u0997\u09c7\u09b2    \u0995\u09bf\u09a8\u09cd\u09a4\u09c1 \u0986\u09ac\u09b0\u09cd\u099c\u09a8\u09be\u0997\u09c1\u09b2\u09cb \u09b0\u09df\u09c7 \u0997\u09c7\u09b2 ! ", "label": 1}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The image is a meme that is not hateful, it is just a funny picture of two men with a caption in a foreign language.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/bangla-memes (206).jpg", "text": "JAGONEWS24.COM    \u0986\u0993\u09df\u09be\u09ae\u09c0 \u09b2\u09c0\u0997 \u0995\u09b0\u09cd\u09ae\u09c0\u09b0 \u09b8\u09cd\u09a4\u09cd\u09b0\u09c0 \u09a8\u09bf\u09df\u09c7 \u09ac\u09bf\u098f\u09a8\u09aa\u09bf \u09a8\u09c7\u09a4\u09be \u09a8\u09bf\u09b0\u09c1\u09a6\u09cd\u09a6\u09c7\u09b6      \u09b0\u09be\u099c\u09b6\u09be\u09b9\u09c0\u09b0 \u09a4\u09be\u09a8\u09cb\u09b0\u09c7 \u0986\u0993\u09df\u09be\u09ae\u09c0 \u09b2\u09c0\u0997 \u0995\u09b0\u09cd\u09ae\u09c0\u09b0 \u09b8\u09cd\u09a4\u09cd\u09b0\u09c0\u0995\u09c7 \u09a8\u09bf\u09df\u09c7 \u09a8\u09bf\u09b0\u09c1\u09a6\u09cd\u09a6\u09c7\u09b6 \u09b9\u09df\u09c7\u099b\u09c7       \u09ac\u09bf\u098f\u09a8\u09aa\u09bf\u09b0 \u09aa\u09cd\u09b0\u09a4\u09bf\u09ad\u09be\u09df \u0986\u09ae\u09bf \u09b8\u099a\u09b0\u09be\u099a\u09b0 \u09ae\u09c1\u0997\u09cd\u09a7 \u09b9\u0987 \u09a8\u09be, \u09a4\u09ac\u09c7 \u0986\u099c \u09b9\u09b2\u09be\u09ae \u0964 ", "label": 1}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The image is a screenshot of a news article with a man in it. The article is in a foreign language, but the man is speaking in English.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/chintashil (108).jpg", "text": "Nobody:   Kiptas \u09e7\u09e6 \u099f\u09be\u0995\u09be\u09b0 \u09b6\u09b0\u09ac\u09a4 \u0995\u09c7\u09a8\u09be\u09b0 \u09aa\u09b0\u0983   Nobal:      \u09b6\u09b0\u09ac\u09a4 \u09ac\u09bf\u0995\u09cd\u09b0\u09c7\u09a4\u09be\u0983   \u0986\u0982\u0995\u09c7\u09b2 , \u09eb \u099f\u09be\u0995\u09be \u09b0\u09be\u0996\u09be \u09af\u09be\u09df \u09a8\u09be ? ", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The meme is not hateful, it is just a funny picture of a man holding a dog and a cup of coffee.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/chintashil (93).jpg", "text": "show me a *Kamlachodas* photo    I said the best ", "label": 1}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The image is a meme that is not hateful, but it is a meme that is hateful. The meme is a picture of a man in a pool with the caption "I'm a kiddie pool."
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/Halal Memes (70).jpg", "text": "\u098f\u0995\u09c7\u09ac\u09be\u09b0\u09c7 \u09b8\u09c7\u09b9\u09c7\u09b0\u09c0 \u0996\u09c7\u09df\u09c7 \u0998\u09c1\u09ae\u09be\u09a8\u09cb\u09b0 \u09aa\u09cd\u09b2\u09be\u09a8 \u0995\u09b0\u09be \u0986\u09ae\u09bf     \u09a0\u09bf\u0995 \u09e9 \u099f\u09be\u09df \u0998\u09c1\u09ae\u09be\u09df \u09af\u09be\u0993\u09df\u09be \u0986\u09ae\u09bf     \u09e9\u0983\u09e9\u09e6 \u098f \u0998\u09c1\u09ae \u09a5\u09c7\u0995\u09c7 \u099f\u09c7\u09a8\u09c7 \u09a4\u09c1\u09b2\u09c7 \u099f\u09c7\u09ac\u09bf\u09b2\u09c7 \u09ac\u09b8\u09be\u09a8\u09cb \u0986\u09ae\u09bf ", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The meme is a picture of a cat with the caption "Hateful" in the middle of the picture. The caption is in a foreign language, which is likely to be a language other than English.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/Memeholics (142).jpg", "text": "\u09ae\u09be\u099d\u09a8\u09a6\u09c0\u09a4\u09c7 \u09a8\u09bf\u09df\u09c7 \u09aa\u09cb\u09a8\u09cd\u09a6\u09be\u09ac\u09cb , \u09af\u09be\u09a4\u09c7 \u09aa\u09be\u09b2\u09be\u09a4\u09c7 \u09a8\u09be \u09aa\u09be\u09b0\u09cb  ", "label": 1}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The meme is not hateful, it is not intended to denigrate, vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/chintashil (852).jpg", "text": "How do I sleep knowing    Bangla is the sweetest language in the world ", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The meme is not hateful, it is just a funny picture of a man sleeping in a meeting room.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/bamboo-vaiya (271).jpg", "text": "laptop \u098f \u09aa\u09be\u09b0\u09a6\u09b0\u09cd\u09b6\u09c0 \u099b\u09be\u09a4\u09cd\u09b0   \u09b8\u09a6\u09cd\u09af \u09a8\u09a4\u09c1\u09a8  laptop \u0995\u09bf\u09a8\u09be \u09b8\u09cd\u09af\u09be\u09b0 ", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The image is a meme that is not hateful, but it is a meme that is not hateful.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/CM (25).jpg", "text": "When a middle east man visit dhaka nowadays   \u09ae\u09a8\u09c7 \u09b9\u099a\u09cd\u099b\u09c7 \u09af\u09c7\u0996\u09be\u09a8 \u09a5\u09c7\u0995\u09c7 \u098f\u09b8\u09c7\u099b\u09bf \u09b8\u09c7\u0996\u09be\u09a8\u09c7\u0987 \u0986\u09ac\u09be\u09b0 \u09ab\u09bf\u09b0\u09c7 \u098f\u09b2\u09be\u09ae ", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The meme is a picture of a man smiling while fishing in the ocean. The caption is in a foreign language, but the text is in English.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/CM (247).jpg", "text": "\u09a5\u09be\u09a8\u09bf\u09df\u09be \u099a\u09c1\u09a6\u09b8\u09c7 \u099c\u09be\u09a8\u09be\u09b0 \u09aa\u09b0 \u09b8\u09cd\u09af\u09be\u09b0     \u09a5\u09be\u09a8\u09bf\u09df\u09be Chittagong University Debating Society (CUDS) \u098f \u099c\u09be\u09a8\u09be\u09b0 \u09aa\u09b0 \u09b8\u09cd\u09af\u09be\u09b0 ", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The meme is a picture of the Hulk and two other characters, with the caption in a foreign language. The caption is not hateful, but it is not hateful either.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/bamboo-vaiya (518).jpg", "text": "*After two days Americans still don't know who's gonna win the election*   [disappoinment noises]", "label": 1}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The meme is a political statement that is not hateful, but it is a political statement. The woman in the meme is wearing a scarf and has a pink shirt. The meme is a political statement that is not hateful, but it is a political statement. The woman in the meme is wearing a scarf and has a pink shirt.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/ovodro_img (598).jpg", "text": "\u098f \u0995\u09c0 \u09ab\u09be\u09a6\u09c7 \u09ab\u09c7\u09b2\u09b2\u09c7 \u0986\u09ae\u09be\u09df \u09a0\u09be\u0995\u09c1\u09b0\u09aa\u09cb ?     \u0995\u09be\u09ae\u09c7\u09b0 \u09ab\u09be\u09a6 \u09ac\u09cc\u09a0\u09be\u09a8 \u0964 \u09af\u09c7 \u09ab\u09be\u09a6\u09c7 \u09a4\u09c1\u09ae\u09bf \u0986\u09ae\u09be\u09df \u09b0\u09cb\u099c \u09ab\u09c7\u09b2\u09cb ", "label": 1}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The meme is not hateful, it is just a funny picture of two people playing chess.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/chintashil (637).jpg", "text": "Average Chill sauce enjoyer, suffer while eating :     Tomato sauce enjoyer, finished fast food in time : ", "label": 1}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The image is a meme that is not hateful, but it is a meme that is hateful.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/chintashil (221).jpg", "text": "\u09ab\u09c7\u09b8\u09ac\u09c1\u0995   \u09ac\u09be\u09b8\u09cd\u09a4\u09ac\u09a4\u09be ", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The image is a meme that is not hateful, it is a picture of two people with a caption that is not hateful.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/CM (190).jpg", "text": "\u098f\u09b2\u09be\u0995\u09be\u09df \u0986\u09a1\u09cd\u09a1\u09be \u09a6\u09c7\u0993\u09df\u09be\u09b0 \u09b8\u09ae\u09df \u09af\u0996\u09a8 \u099b\u09be\u09a6\u09c7 \u0995\u09cb\u09a8 \u09b8\u09c1\u09a8\u09cd\u09a6\u09b0 \u09ae\u09c7\u09df\u09c7 \u09a6\u09c7\u0996\u09bf   ", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The image is a meme that is not hateful, it is a picture of a man with his hands on his head, and the caption is in a foreign language.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/Halal Memes (288).jpg", "text": "\u09ab\u09cd\u09b0\u09c7\u099e\u09cd\u099a \u09aa\u09cd\u09b0\u09cb\u09a1\u09be\u0995\u09cd\u099f \u09ac\u09df\u0995\u099f \u0995\u09b0\u09be\u09df \u0986\u09ae\u09be\u0995\u09c7 \u09a7\u09a8\u09cd\u09af\u09ac\u09be\u09a6 \u099c\u09be\u09a8\u09be\u09a8\u09cb \u09ac\u09a8\u09cd\u09a7\u09c1       \u098f\u0995\u099f\u09c1 \u0986\u0997\u09c7 \u09ab\u09cd\u09b0\u09c7\u099e\u09cd\u099a \u0995\u09bf\u09b8 \u0995\u09b0\u09c7 \u0986\u09b8\u09be \u0986\u09ae\u09bf   ", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The meme is not hateful, it is just a picture of two men shaking hands with a caption that says "happy to meet you."
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/netflix (7).jpg", "text": "- \u09b0\u09be\u09a4 \u09e9 \u099f\u09be , \u09af\u0996\u09a8 \u0986\u09ae\u09bf \u099b\u09be\u09dc\u09be \u09ac\u09be\u0995\u09bf \u09b8\u09ac\u09be\u0987 \u0998\u09c1\u09ae\u09be\u099a\u09cd\u099b\u09c7 \u09b0\u09be\u09a8\u09cd\u09a8\u09be\u0998\u09b0\u09c7\u09b0 \u09ad\u09bf\u09a4\u09b0\u09c7 \u09a5\u09be\u0995\u09be \u099c\u09bf\u09a8-\u09ad\u09c2\u09a4 \u09b8\u09ae\u09c2\u09b9 :", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The meme is not hateful, it is just a funny picture of two men dancing.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/CM (43).jpg", "text": "\u0986\u09ae\u09bf\u09bf - \u09ae\u09be\u09ae\u09be \u0993\u0987\u099f\u09be \u0995\u09a4 ?     \u09a6\u09cb\u0995\u09be\u09a8\u09a6\u09be\u09b0 - \u09ae\u09be\u09ae\u09be \u09e8\u09e7\u09eb\u09e6     \u0986\u09ae\u09bf - \u09ae\u09be\u09ae\u09be \u0995\u09ae\u09be\u09df \u09ac\u09b2\u09c7\u09a8 \u09a8\u09c7\u0993\u09df\u09be\u09b0 \u09ae\u09a4\u09cb \u09a6\u09cb\u0995\u09be\u09a8\u09a6\u09be\u09b0 - \u0986\u099a\u09cd\u099b\u09be \u09eb\u09e6 \u099f\u09be\u0995\u09be \u0995\u09ae\u09be\u09df \u09a6\u09c7\u09a8    \u0986\u09ae\u09bf -     \u0996\u09c1\u09ac \u0989\u09aa\u0995\u09be\u09b0 \u09b9\u0987\u09b2\u09cb ", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The image is a meme that is not hateful, it is a picture of a man sitting in a chair with a phone in his hand. The caption is in a foreign language, but the image itself is not hateful.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/TR (562).jpg", "text": "\u09a8\u09a4\u09c1\u09c1\u09a8 \u09ac\u09be\u09b8\u09b8\u09cd\u099f\u09cd\u09af\u09be\u09a8\u09cd\u09a1\u09c7 \u09af\u09be\u0993\u09df\u09be \u09ac\u09bf\u09a6\u09cd\u09af\u09ae\u09be\u09a8     \u09ac\u09be\u09b8\u09c7\u09b0 \u09b9\u09c7\u09b2\u09cd\u09aa\u09be\u09b0 to me :-    \u0990 \u0995\u09be\u09ae\u09be\u09b0\u0996\u09be\u09b2\u09c0 \u09ae\u09be\u0997\u09c1\u09b0\u09be*     \u0990 \u09b0\u09be\u099c\u09ac\u09be\u09dc\u09c0 \u09a6\u09cc\u09b2\u09a4\u09a6\u09bf\u09df\u09be ", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The image is a meme that is not hateful, it is a funny scene with a group of men pointing guns at each other.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/bangla-gag (77).jpg", "text": "\u09a4\u09cb\u09b0 \u09a8\u09a4\u09c1\u09a8 \u0997\u09be\u09b2\u09ab\u09cd\u09b0\u09c7\u09a8\u09cd\u09a1 \u0995\u09c7 \u09b0\u09c7 ?    \u09a4\u09cb\u09b0 \u09ae\u09be \u09b0\u09c7 \u099c\u09bf\u0997\u09be !   CIVIL WAR    May 6, 2016", "label": 1}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The meme is not hateful, it is just a funny joke.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/netflix (163).jpg", "text": "\u09ae\u09c7\u0998    \u09b0\u09cb\u09a6     \u09ac\u09be\u09a6\u09b2 ", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: A meme with three different people, one of them being a woman, and the words "hateful" and "not-hateful" above them.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/KAM (41).png", "text": "\u0995\u09bf\u09b0\u09c7 \u09a4\u09c1\u0987 \u09a8\u09be \u09b0\u09cb\u099c\u09be? \u09a7\u09c1\u09b0 \u09b6\u09be\u09b2\u09be \u09ad\u09c1\u0987\u09b2\u09be \u0997\u09c7\u099b\u09bf", "label": 1}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The image is a meme that is not hateful, it is just a funny picture of three different men with different expressions.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/bangla-memes (159).jpg", "text": "When you realise your parents won't live forever and you have to live a long life without them ", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The text is a meme that says "when you realize your parents won't live forever and you have to live without them." The meme features a picture of a baby yoda with the caption "when you realize your parents won't live forever and you have to live without them." The meme is not hateful, but it is a reminder that people will eventually pass away and that life is short.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/CM (381).jpg", "text": "\u09aa\u09be\u09b6\u09c7\u09b0 \u09ac\u09be\u09b8\u09be\u09b0 \u0995\u09c1\u09b0\u09ac\u09be\u09a8\u09bf\u09b0 \u0997\u09b0\u09c1\u09b0 \u09b6\u09bf\u0982 \u09af\u0996\u09a8 \u0986\u09ae\u09be\u09a6\u09c7\u09b0 \u0995\u09c1\u09b0\u09ac\u09be\u09a8\u09bf\u09b0 \u0997\u09b0\u09c1\u09b0 \u09b6\u09bf\u0982 \u098f\u09b0 \u099a\u09c7\u09df\u09c7 \u09ac\u09dc \u09b9\u09df ", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The image is a meme that is not hateful, it is just a funny picture of a man with a funny caption. The caption is in a foreign language, but the image itself is not hateful.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/Memeholics (163).jpg", "text": "* Ancient Egyptians working their ass off to build the pyramids*    Humans after 4500 years :   aliens have built it.  Ancient Egyptians : ", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The meme is not hateful, it is just a joke. The meme is a cartoon of an ancient Egyptian man with a stick, and the caption is a quote from the movie The Mummy. The meme is not hateful, it is just a joke.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/ovodro_img (536).jpg", "text": "\u09af\u0996\u09a8 \u09aa\u09cd\u09b0\u09c7\u09df\u09be\u09b0 \u09b2\u09be\u0987\u09a8\u09c7 \u09b9\u09c7\u09a1 \u09b8\u09cd\u09af\u09be\u09b0 \u098f\u09b8\u09c7 \u09ac\u09b2\u09c7\u09a8, \"\u0986\u099c \u09b8\u09ac\u09be\u09b0 \u09a6\u09be\u0981\u09a4 \u09a6\u09c7\u0996\u09be \u09b9\u09ac\u09c7 \"    5 years old me and my friends...", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The meme is not hateful, it is just a funny joke. The meme is a picture of two people, one of whom is a man and the other is a woman. The caption reads "5 years old me and my friends." The meme is not hateful, it is just a funny joke.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/chosha (40).jpg", "text": "\u0986\u0987 \u09b2\u09be\u0989 \u0987\u0989  \u0995\u09bf\u09a8\u09cd\u09a4\u09c1 \u0986\u09ae\u09bf \u09a4\u09cb\u09ae\u09be\u0995\u09c7 \u09ad\u09be\u09b2\u09ac\u09be\u09b8\u09bf\u09a8\u09be   \u098f\u09ae\u09a8 \u09ac\u09b2\u09cb \u09a8\u09be \u09aa\u09cd\u09b2\u09bf\u099c, \u0986\u09ae\u09be\u09b0 \u09a8\u09c1\u09a8\u09c1\u09a4\u09c7 \u09a4\u09cb\u09ae\u09be\u09b0 \u09ac\u09be\u099a\u09cd\u099a\u09be \u09b2\u09be\u09b2\u09a8\u09aa\u09be\u09b2\u09a8 \u0995\u09b0\u099b\u09bf ", "label": 1}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The image is a meme that is not hateful, it is a funny joke that is not meant to harm or denigrate anyone.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/bamboo-vaiya (131).jpg", "text": "\u09a4\u09ac\u09c1\u0993 \u099c\u09c0\u09ac\u09a8 \u0995\u09c7\u099f\u09c7 \u09af\u09be\u099a\u09cd\u099b\u09c7 ... \u09ae\u09be\u09b0\u09be \u0996\u09c7\u09a4\u09c7 \u0996\u09c7\u09a4\u09c7  !", "label": 1}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The meme is a picture of a woman with the text 'hateful' or 'not-hateful' above it. The text is in a foreign language, possibly Thai.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/Bangla Thug Life (268).jpg", "text": "Boys Weakness     Kya maal hai yaar", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The image is a meme that is not hateful, but it is a meme that is not hateful.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/CM (188).jpg", "text": "Her: He's probably thinking about other women.    Him: How do i show 29th February's memory next year ?   ", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The meme is not hateful, it is just a joke.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/netflix (14).jpg", "text": " \u09b8\u09a6\u09cd\u09af \u09ac\u09bf\u0997\u09a4 \u09b9\u0993\u09df\u09be \u099a\u09be\u099a\u09be\u09b0 \u09ac\u09c7\u09b9\u09c7\u09b6\u09a4 \u09aa\u09cd\u09b0\u09be\u09aa\u09cd\u09a4\u09bf\u09b0 \u09b2\u0995\u09cd\u09b7\u09cd\u09af\u09c7 \u09b8\u09c3\u09b7\u09cd\u099f\u09bf\u0995\u09b0\u09cd\u09a4\u09be\u09b0 \u09a8\u09bf\u0995\u099f \u09aa\u09cd\u09b0\u09be\u09b0\u09cd\u09a5\u09a8\u09be\u09b0\u09a4 \u0986\u09aa\u09a8\u09bf :     \u0986\u09aa\u09a8\u09be\u09b0 \u099a\u09be\u099a\u09be \u09af\u09c7 \u0995\u09bf\u09a8\u09be \u09ac\u09c7\u0981\u099a\u09c7 \u09a5\u09be\u0995\u09be\u0995\u09be\u09b2\u09c0\u09a8 \u09b2\u09c7\u09ac\u09c1\u09b0 \u09a8\u09bf\u09b0\u09cd\u099c\u09be\u09b8 \u09aa\u09be\u09a8 \u0995\u09b0\u09a4\u09cb \u09a8\u09be ", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The meme is a picture of a man with a skeleton face, and the text is in a foreign language. The meme is not hateful, but it is not hateful either.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/TR (433).jpg", "text": "Faridpuirra Auto-wala be like    \u09a8\u09a4\u09c1\u09c1\u09a8 \u09ac\u09be\u09b8\u09b8\u09cd\u099f\u09cd\u09af\u09be\u09a8\u09cd\u09a1    \u09a8\u09a4\u09c1\u09a8 \u0987\u09b7\u09cd\u099f\u09be\u09a8 ", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The meme is a picture of a man in a red jacket, with the caption 'Faridpur Auto Wala Like' in Bengali. The meme is not hateful, but it is not hateful either.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/TR (486).jpg", "text": "\u09ab\u09b0\u09bf\u09a6\u09aa\u09c1\u09b0 \u0987\u099e\u09cd\u099c\u09bf\u09a8\u09bf\u09df\u09be\u09b0\u09bf\u0982 \u0995\u09b2\u09c7\u099c\u09c7 \u09ad\u09b0\u09cd\u09a4\u09bf \u09b9\u0993\u09df\u09be\u09b0 \u09aa\u09b0\u0983-     \u098f\u0996\u09a8 \u0986\u09ae\u09be\u09b0 \u09aa\u09cd\u09b0\u09a5\u09ae \u0995\u09be\u099c \u09b9\u099a\u09cd\u099b\u09c7 \u0985\u09a4\u09bf\u09b0\u09bf\u0995\u09cd\u09a4 \u09ad\u09be\u09ac \u09a8\u09c7\u0993\u09df\u09be ", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The image is a meme that is not hateful, it is a picture of a man hugging a woman with a caption that is not hateful.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/TR (371).jpg", "text": "\u09af\u0996\u09a8 \u0995\u09c7\u0989 \u099c\u09bf\u099c\u09cd\u099e\u09be\u09b8\u09be \u0995\u09b0\u09c7 \u0987\u099e\u09cd\u099c\u09bf\u09a8\u09bf\u09df\u09be\u09b0\u09bf\u0982 \u09a8\u09bf\u09b8\u09bf \u0995\u09c7\u09a8 ?     *\u0986\u09ae\u09bf   \u09ae\u09be\u09a8\u09c1\u09b7 \u09b9\u0987\u09df\u09be \u099c\u09a8\u09cd\u09ae\u09be\u0987\u099b\u09bf , \u09e8-\u09e7 \u099f\u09be \u09ad\u09c1\u09b2 \u0995\u09b0\u09ac\u09cb \u09a8\u09be ? ", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The image is a meme that is not hateful, it is not intended to denigrate, vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status. It is a meme that is not hateful.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/ovodro_img (590).jpg", "text": "mi, csk \u098f\u09b0 \u09ac\u09bf\u09b0\u09c1\u09a6\u09cd\u09a7\u09c7 \u09a4\u09bf\u09a8 \u09ae\u09cd\u09af\u09be\u099a \u099c\u09c7\u09a4\u09be\u09b0 \u09aa\u09b0\u09c7  rohit be like    wo csk ka sath match khelna zaruri hai keya ", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: A meme with a man in a baseball cap and a caption that says "mi csk sk roti be like" is a hateful meme.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/TR (80).jpg", "text": "\u099b\u09c7\u09b2\u09c7\u09b0\u09be \u09ac\u09be\u09b0\u09c0 \u09aa\u09cd\u09b2\u09be\u099c\u09be \u09a5\u09c7\u0995\u09c7 \u09b6\u09aa\u09bf\u0982 \u0995\u09b0\u09be\u09b0 \u09aa\u09b0 \u09a8\u09bf\u099c\u09c7\u0995\u09c7 \u09af\u09c7\u09ae\u09a8\u099f\u09be \u09ae\u09a8\u09c7 \u0995\u09b0\u09c7 ...   ", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The meme is a picture of a man in front of the Big Ben clock tower in London, England. The caption is in a foreign language, but the man in the picture is wearing a suit and tie, and the caption is in English.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/CM (265).jpg", "text": "Corona      \u09af\u09be\u09b0\u09be \u09ac\u09b2\u09c7 \u099b\u09bf\u09b2\u09cb \u098f\u0987 \u09ac\u099b\u09b0 \u09b8\u09b0\u0995\u09be\u09b0\u09bf \u099b\u09c1\u099f\u09bf \u0995\u09ae*  ", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The image is a meme that is not hateful, but it is a meme that is hateful. The meme is a picture of a child drinking water from a faucet, and the caption is in Bengali.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/Halal Memes (122).jpg", "text": "\u0997\u09c7\u09ae\u09c7\u09b0 \u09ae\u09a7\u09cd\u09af\u09c7 \u09ae\u09be\u0987\u0995 \u0985\u09a8 \u0995\u09b0\u09c7 \u0989\u09b0\u09be\u09a7\u09c1\u09b0\u09be \u0997\u09be\u09b2\u09bf \u09a6\u09c7\u0993\u09df\u09be \u0986\u09ae\u09bf        \u09aa\u09be\u09b6\u09c7\u09b0 \u0998\u09b0\u09c7 \u09a5\u09c7\u0995\u09c7 \u0986\u09ac\u09cd\u09ac\u09c1  ", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The image is a meme that is not hateful, it is just a funny picture of a man making a gesture with his hand.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/CM (196).jpg", "text": "\u09ac\u09bf\u09b6\u09cd\u09ac \u09ad\u09be\u09b2\u09cb\u09ac\u09be\u09b8\u09be \u09a6\u09bf\u09ac\u09b8     \u09aa\u09b9\u09c7\u09b2\u09be \u09ab\u09be\u09b2\u09cd\u0997\u09c1\u09a8    \u09aa\u09ac\u09bf\u09a4\u09cd\u09b0 \u099c\u09c1\u09ae\u09cd\u09ae\u09be \u09a6\u09bf\u09a8  ", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The image is a meme that is not hateful, it is a quote from a movie. The quote is from the movie 'The Matrix' and is not hateful.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/netflix (92).jpg", "text": "\u09ac\u09a8\u09cd\u09a7\u09c1\u0997\u09a3    \u09af\u09a6\u09bf \u0986\u09aa\u09a8\u09be\u09b0 \u09aa\u09cd\u09b0\u09c7\u09df\u09b8\u09c0\u09b0 \u09a5\u09be\u0995\u09c7 \u098f\u0995\u099c\u09cb\u09dc\u09be \u0986\u0995\u09b0\u09cd\u09b7\u09a8\u09c0\u09df \u099a\u09cb\u0996     \u09ae\u09cb\u09b9\u09a8\u09c0\u09df \u09b8\u09cc\u09a8\u09cd\u09a6\u09b0\u09cd\u09af\u09af\u09c1\u0995\u09cd\u09a4 \u099a\u09c7\u09b9\u09be\u09b0\u09be    \u098f\u09ac\u0982 \u09af\u09a6\u09bf \u09a4\u09be\u09b0 \u09a6\u09bf\u0995\u09c7 \u09a4\u09be\u0995\u09be\u09b2\u09c7 \u099a\u09cb\u0996 \u09ab\u09c7\u09b0\u09be\u09a8\u09cb \u09af\u09be\u09df\u09a8\u09be    \u09a4\u09ac\u09c7 \u098f\u099f\u09bf \u0986\u09aa\u09a8\u09be\u09b0 \u09aa\u09cd\u09b0\u09c7\u09df\u09b8\u09c0 \u09a8\u09df !! \u098f\u099f\u09bf \u098f\u09b8\u09b8\u09bf\u09aa\u09bf - \u09e7\u09ed\u09e9 ", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The image is a meme that is not hateful, but it is still a meme.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/ovodro_img (1357).jpg", "text": "\u0993\u09b9\u09c7 ! \u09aa\u09cd\u09b0\u09bf\u09df \u0995\u09c0 \u09a8\u09be\u09ae\u09c7 \u09a1\u09be\u0995\u09bf \u09a4\u09cb\u09ae\u09be\u0995\u09c7 ?    \u0986\u099c \u0986\u09ae\u09be\u0995\u09c7 \u09b9\u09b0\u09bf\u09a8\u09c0 \u09ac\u09b2\u09c7 \u09a1\u09be\u0995\u09cb \u09aa\u09cd\u09b0\u09bf\u09df \u0964   \u09ac\u09be\u0987 \u09a4\u09cb \u09ae\u09a8\u09c7 \u09b9\u099a\u09cd\u099b\u09c7 \u0996\u09c1\u09ac \u0989\u09a0\u09c7\u099b\u09c7 \u0986\u099c ", "label": 1}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The meme is a picture of a man and woman, with the caption "Hateful if it intends to denigrate, vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status." The meme is not hateful, but it is a caption that is meant to be humorous.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/TR (62).jpg", "text": "\u0995\u09c7\u0989\u09a8\u09be\u0983 \u09ae\u09c7 \u09a1\u09c7 \u09a4\u09c7 \u099b\u09c1\u099f\u09bf \u09aa\u09be\u0993\u09df\u09be \u09a2\u09be\u0995\u09be\u09ac\u09be\u09b8\u09c0    \u09aa\u09cd\u09b0\u09b8\u09c1\u09b0 \u0986\u09b0\u09be\u09ae ", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The image is a meme that is not hateful, it is a funny picture of a man laying in a bathtub with a caption that is not intended to harm or denigrate anyone.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/ovodro_img (235).jpg", "text": "I LOVE YOU  love u 2 \u0995\u09c7 \u09a4\u09c1\u0987 BC  \u0993\u09b0\u09c7 \u09aa\u09be\u09b2\u09be \u09b0\u09c7, \u098f\u099f\u09be \u0995\u09cb\u09a8 \u09ac\u09bf\u09ad\u09c2\u09a4\u09bf \u0986\u09a8\u09cd\u099f\u09bf !! ", "label": 1}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The image is a meme that is not hateful, but it is a meme that is not hateful.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/tangaila (32).jpg", "text": "WHEN THERE IS A  \u0997\u09cd\u09af\u09be\u099e\u09cd\u099c\u09be\u09ae  TOMORROW & YOU ARE \u098f\u09b2\u09be\u0995\u09be\u09b0 \u09ac\u09dc \u09ad\u09be\u0987    \u09a4\u09c1\u0987 \u09af\u09c1\u0995\u09cd\u09a4\u09b0\u09be\u099c\u09cd\u09af \u09a5\u09c7\u0995\u09c7 \u0986\u09ae\u09be\u09b0 \u099c\u09a8\u09cd\u09af \u09b0\u09a1 \u09aa\u09be\u09a0\u09be    ", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The meme is not hateful, it is just a funny picture of a man on a phone with a caption that says "when there is a problem, you are a tomorrow."
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/tangaila (263).jpg", "text": "\u0995\u09be\u0995\u09c1 \u0995\u09ac\u09b0\u09b8\u09cd\u09a5\u09be\u09a8 \u099f\u09be \u0995\u09cb\u09a8\u09a6\u09bf\u0995\u09c7 ?   \u098f\u0987\u09af\u09c7 \u09b8\u09be\u09ae\u09a8\u09c7 \u0997\u09bf\u09df\u09c7 \u09ac\u09be\u09ae \u09a6\u09bf\u0995\u09c7\u0987 \u0964  \u0986\u09ae\u09be\u09b0 \u0995\u09ac\u09b0\u099f\u09be\u09b0 \u099c\u09bf\u09df\u09be\u09b0\u09a4 \u0995\u0987\u09b0\u09cb    \u0986\u09ae\u09bf\u0983  (confused unga bunga) ", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The image is a meme that is not hateful, it is a joke. The meme is a picture of a man with a beard and a caption that reads "Confused Uganda". The meme is not hateful, it is a joke.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/CM (598).jpg", "text": "HSC CANDIDATES 2020    \u09a8\u09be \u0986\u09ae\u09b0\u09be \u0985\u099f\u09cb\u09aa\u09be\u09b8\u09c7\u09b0 \u09b0\u09c7\u099c\u09be\u09b2\u09cd\u099f \u09ae\u09be\u09a8\u09ac\u09cb\u09a8\u09be     GPA 5 ", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The image is a meme that is not hateful, but it is a hateful meme.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/chintashil (788).jpg", "text": "What men think women will be after he says \" I feel proud that women are safe around me\"   \u0986\u09ae\u09be\u09b0 \u0995\u09cb\u09a8 \u09ae\u09cb\u09b9\u09b0 \u09b6\u09cb\u09a7 \u09b9\u09ac\u09c7 \u0997\u09cb \u098f\u09a4\u09cb \u09ac\u09dc \u098b\u09a3 ", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The meme is a picture of a man and woman with the caption "What think men will be after he says he's proud that women are safe around him." The meme is not hateful, but it is a joke.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/CM (178).jpg", "text": "\u0986\u09ae\u09cd\u09ae\u09c1\u0983 \u09e7\u09e6 \u09ae\u09bf\u09a8\u09bf\u099f \u09aa\u09b0 \u099a\u09c1\u09b2\u09be \u099f\u09be \u09ac\u09a8\u09cd\u09a7 \u0995\u09b0\u09c7 \u09a6\u09bf\u09b8 \u09e8\u09e6 \u09ae\u09bf\u09a8\u09bf\u099f \u09aa\u09b0 \u09b0\u09be\u09a8\u09cd\u09a8\u09be \u0998\u09b0 \u09a5\u09c7\u0995\u09c7 \u09af\u0996\u09a8 \u09aa\u09cb\u09dc\u09be \u0997\u09a8\u09cd\u09a7 \u09aa\u09be\u0987\u0983    Fuck ", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The image is a meme that is not hateful, but it is a meme that is not hateful. It is a meme that is not hateful, but it is a meme that is not hateful.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/netflix (54).jpg", "text": "\u099c\u09c0\u09ac\u09a8\u09c7\u09b0 \u09b8\u09ac\u099f\u09c1\u0995\u09c1 \u09a6\u09bf\u09df\u09c7 \u099a\u09c7\u09b7\u09cd\u099f\u09be \u0995\u09b0\u09be\u09b0 \u09aa\u09b0 \u0986\u09ae\u09be\u09b0 \u099c\u09a8\u09cd\u09af \u0995\u09cd\u09b0\u09be\u09b6\u09c7\u09b0 \u09ae\u09a8\u09c7\u09b0 \u09a6\u09b0\u099c\u09be        \u09b9\u09c1\u09ae\u09be\u09df\u09c2\u09a8 \u0986\u09b9\u09ae\u09c7\u09a6\u09c7\u09b0  \u09ac\u0987 \u09a5\u09c7\u0995\u09c7 \u09a6\u09c1\u0987 \u09b2\u09be\u0987\u09a8 \u09ac\u09b2\u09be\u09b0 \u09aa\u09b0 \u09ac\u09be\u09ac\u09be \u0986\u09b8\u0995\u09cd\u09a4 \u099b\u09c7\u09b2\u09c7\u09b0 \u099c\u09a8\u09cd\u09af \u0995\u09cd\u09b0\u09be\u09b6\u09c7\u09b0 \u09ae\u09a8\u09c7\u09b0 \u09a6\u09b0\u099c\u09be   ", "label": 1}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The meme is a picture of a chicken with a caption that is written in a foreign language. The caption is not hateful, but it is not hateful either.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/Memeholics (211).jpg", "text": "Your husband: I'm thinking about getting married again.    Bisexual you: ", "label": 1}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The meme is a picture of a woman with a caption that says 'your husband, I'm thinking about getting married again.' The meme is not hateful, but it is a joke.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/ovodro_img (862).jpg", "text": "***** \u09b0\u09be\u09b8\u09cd\u09a4\u09be\u09b0 \u09ae\u09cb\u09b0\u09c7 \u09ac\u09b8\u09c7 \u09b8\u09bf\u0997\u09be\u09b0\u09c7\u099f \u0996\u09be\u0993\u09df\u09be\u09b0 \u09b8\u09ae\u09df *****   \u099b\u09c7\u09b2\u09c7\u09b0\u09be \u09ad\u09be\u09ac\u09c7 \u09a4\u09be\u09a6\u09c7\u09b0 \u09af\u09c7\u09ae\u09a8 \u09b2\u09be\u0997\u09c7 !       \u0995\u09bf\u09a8\u09cd\u09a4\u09c1 \u0986\u09b8\u09b2\u09c7 \u09a4\u09be\u09a6\u09c7\u09b0 \u09af\u09c7\u09ae\u09a8 \u09b2\u09be\u0997\u09c7 ...", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The meme is not hateful, it is just a funny picture of two men smoking and talking.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/ovodro_img (1210).jpg", "text": "if \" \u09a4\u09cb\u09ae\u09be\u09b0 \u0997\u09be\u09b2\u09ab\u09cd\u09b0\u09c7\u09a8\u09cd\u09a1 \u09a4\u09cb\u09ae\u09be\u0995\u09c7 \u099a\u09bf\u099f \u0995\u09b0\u09be\u09b0 \u0995\u09be\u09b0\u09a8\u09c7 \u09b8\u09c1\u0987\u09b8\u09be\u0987\u09a1 \u0995\u09b0 \u0995\u09bf\u09a8\u09cd\u09a4\u09c1 \u09b6\u09c7\u09b7\u09c7 \u09a4\u09cb\u09ae\u09be\u09b0 \u099c\u09a8\u09cd\u09ae \u09a4\u09cb\u09ae\u09be\u09b0 \u0997\u09be\u09b2\u09ab\u09cd\u09b0\u09c7\u09a8\u09cd\u09a1\u09c7\u09b0 \u0997\u09b0\u09cd\u09ad\u09c7\u0987 \u09b9\u09df     \"  had a face ", "label": 1}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The meme is not hateful, it is just a funny picture of a mother and her baby. The caption is in a foreign language, but the image is not hateful.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/Bangla Thug Life (153).jpg", "text": "Nibbi : \u099c\u09be\u09a8 \u0995\u09bf \u0996\u09c7\u09a4\u09c7 \u09a4\u09cb\u09ae\u09be\u09b0 \u09ad\u09be\u09b2\u09cb \u09b2\u09be\u0997\u09c7 ? Fuckboy : \u0995\u099a\u09bf \u09a1\u09be\u09ac\u09c7\u09b0 \u09aa\u09be\u09a8\u09bf ", "label": 1}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The image is a meme that is not hateful, it is a political statement that is not hateful.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/chintashil (242).jpg", "text": "\u09ae\u09be\u09a6\u09cd\u09b0\u09be\u09b8\u09be\u09b0 \u099b\u09be\u09a4\u09cd\u09b0 - \u09ac\u09b2 \u099f\u09be \u098f\u0995\u099f\u09c1 \u09a6\u09c7\u09a8 , \u0985\u09a8\u09c7\u0995 \u09a6\u09bf\u09a8 \u0996\u09c7\u09b2\u09bf\u09a8\u09be , \u098f\u0995\u099f\u09be \u0993\u09ad\u09be\u09b0 \u0995\u09b0\u09bf    \u0986\u09ae\u09bf - \u0986\u099a\u09cd\u099b\u09be \u0995\u09bf\u09a8\u09cd\u09a4\u09c1 \u0986\u09b8\u09cd\u09a4\u09c7 \u09ac\u09b2 \u0995\u0987\u09b0\u09c7\u09a8   \u09ac\u09b2 \u09aa\u09be\u0993\u09df\u09be\u09b0 \u09aa\u09b0 \u09b9\u09c1\u099c\u09c1\u09b0 -   So you have chosen ... death ", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The meme is a quote from the movie Harry Potter and the Deathly Hallows. The quote is in a foreign language, but the English translation is "So you have chosen death."
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/CM (41).jpg", "text": "Right -  \u0986\u099a\u09cd\u099b\u09be \u09a4\u09c1\u09ae\u09bf \u0995\u09bf \u0988\u09a6 ?    Left -   \u09a8\u09be \u09ae\u09be\u09a8\u09c7 \u09ac\u09c1\u099d\u09b2\u09be\u09ae \u09a8\u09be    Right - \u09ae\u09be\u09a8\u09c7 \u09a4\u09c1\u09ae\u09bf \u09af\u09a4\u09ac\u09be\u09b0\u0987 \u0986\u09b8\u09cb \u09a4\u09a4\u09ac\u09be\u09b0\u0987 \u0986\u09ae\u09be\u09b0 \u0985\u09a8\u09c7\u0995 \u09ad\u09be\u09b2\u09cb\u09b2\u09be\u0997\u09c7  ", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The meme is a picture of a man and woman sitting at a table, with the caption "right left" in the middle. The meme is not hateful, but it is not hateful either.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/bamboo-vaiya (419).jpg", "text": "someone:- tumi ki prem koro ?   *Le me:-  \u09a4\u09c1\u09ae\u09bf \u0995\u09bf \u0986\u09ae\u09be\u0995\u09c7 \u0986\u09b9\u09a4 \u0995\u09b0\u09be\u09b0 \u099c\u09a8\u09cd\u09af \u0995\u09a5\u09be\u0997\u09c1\u09b2\u09cb \u09ac\u09b2\u09b2\u09c7  ", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The meme is a picture of a woman with a caption that says 'someone tumi prem kono?' which translates to 'someone, you are prem kono?' The meme is not hateful, but it is a joke that is not appropriate for all audiences.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/Halal Memes (195).jpg", "text": "Teacher  : Accha bolo toh tiktiki keno dewale hate ?    Me :  Sir, amrao to mati te hati tiktiki konodin jiggesh koreche ?    Teacher  \u09b2\u09c7\u0983 \u0986\u09ae\u09bf   my crush  my friends", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The image is a meme that is not hateful, but it is a meme that is hateful.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/KAM (114).jpg", "text": "\u09ac\u09bf\u09df\u09c7\u09a4\u09c7 \u09aa\u09b0\u09c7 \u099f\u09df\u09b2\u09c7\u099f\u09c7", "label": 1}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The meme is not hateful, it is just a funny picture of a group of people eating food.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/bangla-memes (123).jpg", "text": "\u09a8\u09be\u09ae \u0995\u09bf \u09ac\u09be\u09ac\u09be \u09a4\u09cb\u09ae\u09be\u09b0 ?       \u09b8\u09be\u09a6\u09ae\u09be\u09a8 \u09b8\u09be\u0995\u09bf\u09ac", "label": 1}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The meme is a comedic scene with a man and a woman, and the caption is in a foreign language. The caption is not hateful, but it is not hateful.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/ovodro_img (108).jpg", "text": "\u099a\u09b2 \u09ae\u09a7\u09c1 , \u0986\u09ae\u09b0\u09be \u09a0\u09be\u0995\u09c1\u09b0 \u09a6\u09c7\u0996\u09a4\u09c7 \u09af\u09be\u09ac   \u09a4\u09cb\u09ae\u09b0\u09be \u09af\u09be\u0993     \u09a4\u09be\u09b9\u09b2\u09c7 \u098f\u099f\u09be\u0987 \u099b\u09bf\u09b2 \u09a4\u09cb\u09ae\u09be\u09b0 \u09aa\u09cd\u09b2\u09be\u09a8 ?     \u09b9\u09cd\u09af\u09be\u0981, \u09b8\u09c1\u09af\u09cb\u0997 \u09aa\u09c7\u09b2\u09c7 \u0993\u09ad\u09be\u09b0\u099f\u09be\u0987\u09ae\u09c7 \u0987\u09a8\u0995\u09be\u09ae \u0995\u09b0\u09bf     \u09b2\u09be \u098f \u09b9\u09a4\u09c7 \u09aa\u09be\u09b2\u09c7 \u09b2\u09be ", "label": 1}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The meme is not hateful, it is just a funny picture of people with a caption that is not meant to be harmful or offensive.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/chintashil (767).jpg", "text": "\" \u09ae\u09b0\u09c7 \u09af\u09be\u099a\u09cd\u099b\u09c7 \"  is such an ugly world   Instead say \"Engineering \u09aa\u09dc\u09a4\u09c7\u09b8\u09c7 \" ", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The meme is not hateful, it is just a joke. The man is holding his head in frustration while studying, and the caption is a play on words. The caption is in a foreign language, but the meaning is clear.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/chintashil (487).jpg", "text": "\u099f\u09bf\u09ab\u09bf\u09a8 \u099f\u09be\u0987\u09ae\u09c7 \u0986\u09ae\u09be\u09b0 \u09ac\u09a8\u09cd\u09a7\u09c1\u09b0\u09be    *\u099f\u09bf\u09ab\u09bf\u09a8\u09c7 \u0986\u09a8\u09be \u0986\u09ae\u09be\u09b0 \u09ac\u09bf\u09b0\u09bf\u09df\u09be\u09a8\u09bf\u09b0 \u09ac\u0995\u09cd\u09b8* ", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The meme is not hateful, it is just a funny picture of a man with a hat on.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/tangaila (178).jpg", "text": " \u09b8\u09cd\u09af\u09be\u09b0*    \u09aa\u09cd\u09b0\u09be\u0995\u09cd\u099f\u09bf\u0995\u09cd\u09af\u09be\u09b2 \u09a8\u09be\u09ae\u09cd\u09ac\u09be\u09b0    \u0995\u09cd\u09b2\u09be\u09b8\u09c7\u09b0 \u09ab\u09be\u09b0\u09cd\u09b8\u09cd\u099f \u09ac\u09df ", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The image is a meme that is not hateful, it is a meme that is not hateful.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/TR (40).jpg", "text": "Theme song of every boy/girl who are living in Hostel/ \u09ae\u09c7\u09b8    \u09ac\u09bf\u09a7\u09bf \u09a4\u09c1\u09ae\u09bf \u09ac\u09b2\u09c7 \u09a6\u09be\u0993 , \u0986\u09ae\u09bf \u0995\u09be\u09b0 \u09ae\u09b6\u09be \u09a8\u09be\u0995\u09bf \u099b\u09be\u09dc\u09aa\u09cb\u0995\u09be\u09b0 ,   \u09a6\u09c1\u099f\u09bf \u09aa\u09cd\u09b0\u09be\u09a3\u09c0 \u098f\u0995\u099f\u09bf \u09a6\u09c7\u09b9\u09c7\u09b0 \u09a6\u09be\u09ac\u09c0\u09a6\u09be\u09b0 ", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The meme is a hateful one, as it is mocking a girl who is living in a hostel.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/ovodro_img (1304).jpg", "text": "\u0986\u099c \u09b0\u09be\u09a4\u09c7 \u0995\u09c0 LUBRICANT \u0987\u0989\u09b8 \u0995\u09b0\u09ac\u09c0 ?     LUBRICANT \u098f\u09b0 \u0995\u09c0 \u09a6\u09b0\u0995\u09be\u09b0 , \u09ac\u09bf\u09ae\u09b2 \u0996\u09c7\u09df\u09c7 \u09a5\u09c1\u09a5\u09c1 \u09ae\u09c7\u0996\u09c7 \u09a8\u09c7\u09ac      \u09b6\u09be\u09b2\u09be \u09ac\u09bf\u09ae\u09b2\u09be\u09b8\u09cb\u09a6\u09be    ***", "label": 1}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The meme is not hateful, it is just a funny picture of a man and woman smiling together.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/Bangla Thug Life (412).jpg", "text": "\u09e7\u09ea \u09ab\u09c7\u09ac\u09cd\u09b0\u09c1\u09df\u09be\u09b0\u09bf \u09b8\u0995\u09be\u09b2 \u09e7\u09e6 \u099f\u09be \u0964  \u09e7\u09ea \u09ab\u09c7\u09ac\u09cd\u09b0\u09c1\u09df\u09be\u09b0\u09bf \u09b0\u09be\u09a4 \u09e7\u09e6 \u099f\u09be \u0964", "label": 1}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The image is a meme that is not hateful, it is just a funny picture of a fish with a caption in Hindi.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/netflix (32).jpg", "text": "\u09af\u0996\u09a8 \u0986\u09ae\u09bf \u0995\u09cd\u09b0\u09be\u09b6\u09c7\u09b0 \u09ac\u09df\u09ab\u09cd\u09b0\u09c7\u09a8\u09cd\u09a1\u09c7\u09b0 \u098f\u09b2\u09be\u0995\u09be\u09df \u098f\u0995\u09be \u0997\u09bf\u09df\u09c7 \u09b9\u09c1\u09ae\u0995\u09bf \u09a6\u09bf\u09df\u09c7 \u09ae\u09be\u09b0 \u0996\u09c7\u09df\u09c7 \u0986\u09b8\u09bf    me :    I'll see you again ", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The meme is a picture of a man with a finger pointing at the camera, and the caption is in a foreign language. The caption is not hateful, but it is not hateful either.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/KAM (73).png", "text": "\u09ac\u09be\u0982\u09b2\u09be\u09a6\u09c7\u09b6 \u099f\u09bf\u09ae \u09aa\u09c1\u09b0\u09be\u0987 \u098f\u09b0\u09b6\u09be\u09a6\u09c7\u09b0 \u09ae\u09a4 \u09aa\u09b2\u09cd\u099f\u09bf \u09ae\u09be\u09b0\u09b2\u09cb \u098f\u0987\u09a1\u09be \u0995\u09bf\u099b\u09c1 \u09b9\u0987\u09b2\u09cb? ", "label": 1}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The meme is not hateful, it is just a picture of a man with a skull and a caption that says "I am not hateful."
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/ovodro_img (183).jpg", "text": "\u098f\u0995\u099f\u09c1 \u09aa\u09be\u09a4\u09be \u09aa\u09be\u09a4\u09be \u0996\u09c7\u09b2\u09ac\u09cb    RUPAM ISLAM \u098f\u09b0 \u0997\u09be\u09a8 \u099a\u09be\u09b2\u09bf\u09df\u09c7 \u09a6\u09bf\u09df\u09c7\u099b\u09bf ", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The meme is a picture of an older man sitting at a computer with a cup of coffee, and the caption is in Bengali. The caption is a joke, and the meme is not hateful.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/ovodro_img (728).jpg", "text": "\u09af\u09c7 \u09ae\u09c7\u09df\u09c7 \u09a4\u09cb\u09ae\u09be\u09b0 \u09a6\u09bf\u0995\u09c7 \u098f\u0987 \u09ad\u09be\u09ac\u09c7 \u09a4\u09be\u0995\u09be\u09ac\u09c7 \u09a4\u09be\u0995\u09c7 \u0995\u0996\u09a8\u0993 \u099b\u09c7\u09dc\u09c7 \u09a6\u09bf\u0993 \u09a8\u09be ", "label": 1}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The image is a meme that is not hateful, it is a picture of a crowded train with people taking pictures and talking on their phones.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/Memeholics (41).jpg", "text": "*\u09af\u0996\u09a8 \u0986\u09aa\u09a8\u09bf virgin \u09b9\u0993\u09df\u09be\u09b0 \u09aa\u09b0\u09c7\u0993 \u0986\u09aa\u09a8\u09be\u09b0 \u09ac\u09a8\u09cd\u09a7\u09c1\u09b0\u09be \u0986\u09aa\u09a8\u09be\u0995\u09c7 fuckboy \u09a1\u09be\u0995\u09c7*    \u09a8\u09be \u099a\u09c1\u09a6\u09c7 \u09a8\u09bf\u09ac\u09cd\u09ac\u09bf , \u0996\u09c7\u09a4\u09be\u09ac \u09aa\u09c7\u09b2\u09be\u09ae \u09a6\u09bf\u09ac\u09cd\u09ac\u09bf ", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The meme is a cartoon of a man with a mustache and a caption that says "Hateful Virus Luckboy". The cartoon is in a foreign language, possibly Bengali.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/bangla-memes (126).jpg", "text": "*First Date*     Her : * does nothing*    Me: \u0995\u09b2\u09be \u09b9\u09be\u09a4\u09c7 \u09ac\u09b8\u09c7 \u0986\u099b\u09bf\u09b8 \u0995\u09c7\u09a8 ? ...\u0996\u09be !    ", "label": 1}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The meme is a picture of a family sitting on a bench, with the caption "First date her, she does nothing." The caption is a play on words, as the person is not actually on a date, but rather with their family.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/KAM (175).png", "text": "\u0986\u09a8\u09c1\u09b6\u0995\u09be \u098f\u0996\u09a8 \u09ac\u09bf\u09b0\u09be\u099f \u0995\u09c1\u09b2\u09bf \u0995\u09c7 \u099b\u09c7\u09b0\u09c7 \u09b0\u09c1\u09ac\u09c7\u09b2 \u098f\u09b0 \u09b8\u0999\u09cd\u0997\u09c7 ", "label": 1}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The meme is not hateful, it is just a funny picture of two people with a caption that says "hateful" in a foreign language.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/ovodro_img (75).jpg", "text": "\u09b8\u09b0\u0995\u09be\u09b0\u09c0 \u099a\u09be\u0995\u09b0\u09c0 \u09a8\u09be  \u09ac\u09c7\u09b8\u09b0\u0995\u09be\u09b0\u09c0 \u099a\u09be\u0995\u09b0\u09c0 ?    \u09b8\u09b0\u0995\u09be\u09b0\u09c0 \u099a\u09be\u0995\u09b0\u09c0 ", "label": 1}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The meme is not hateful, it is just a funny scene from the movie.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/CM (491).jpg", "text": "\u09b6\u09c7\u09b7\u09c7\u09b0 \u09a6\u09bf\u0995\u09c7 \u09b8\u09ac \u09ac\u09cd\u09af\u09ac\u09b9\u09be\u09b0\u09bf\u0995 \u098f\u0995\u09b8\u09be\u09a5\u09c7 \u0995\u09b0\u09be \u0995\u09a4 \u0995\u09b7\u09cd\u099f \u09a4\u09be \u09a8\u09bf\u09df\u09c7 \u0986\u09b2\u09cb\u099a\u09a8\u09be \u0995\u09b0\u09be \u09ac\u09a8\u09cd\u09a7\u09c1      \u09b2\u09be\u0987\u09ac\u09cd\u09b0\u09c7\u09b0\u09bf\u09a4\u09c7 \u099f\u09be\u0995\u09be \u09a6\u09bf\u09b2\u09c7\u0987 \u09b8\u09ac \u09ac\u09cd\u09af\u09ac\u09b9\u09be\u09b0\u09bf\u0995 \u09b8\u09ae\u09df\u09ae\u09a4\u09cb \u0993\u09b0\u09be \u0995\u09b0\u09c7 \u09a6\u09bf\u09ac\u09c7 \u099c\u09be\u09a8\u09be \u0986\u09ae\u09bf  ", "label": 1}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The image is a meme that is not hateful, it is a political joke that is not meant to harm or denigrate any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/Halal Memes (142).jpg", "text": "\u09af\u09c7 \u0986\u09ae\u09be\u09b0 \u0987\u099a\u09cd\u099b\u09c7 \u09aa\u09c1\u09b0\u09a3 \u0995\u09b0\u09ac\u09c7 \u09a4\u09be\u0995\u09c7 \u0986\u09ae\u09bf \u098f\u0987 \u0997\u09cd\u09b0\u09c1\u09aa \u098f\u09b0 \u09ae\u09a1\u09be\u09b0\u09c7\u099f\u09b0 \u09ac\u09be\u09a8\u09be\u09ac\u09cb     \u09a4\u09cb\u09b0 \u0987\u099a\u09cd\u099b\u09be \u0995\u09bf ?     \u0986\u09ae\u09be\u0995\u09c7 \u098f\u09a1\u09ae\u09bf\u09a8 \u09ac\u09be\u09a8\u09be\u09a4\u09c7 \u09b9\u09ac\u09c7     ", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The meme is a comic strip with a caption in Bengali, which is a language spoken in Bangladesh. The caption is a joke about a man who is being beaten up by another man, and the caption reads "I'm not a man, I'm a manly man." The meme is not hateful, but it is a comical representation of a man who is being beaten up.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/Memeholics (152).jpg", "text": "\u0986\u0987 \u09ab\u09be\u0995 \u09ac\u09be\u0982\u09b2\u09be\u09a6\u09c7\u09b6\u09bf \u09b8\u09bf\u09b8\u09cd\u099f\u09c7\u09ae      They called me a madman ", "label": 1}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The meme is a comic strip that is not hateful, but it is a comic strip that is not hateful.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/chintashil (82).jpg", "text": "\u0995\u09bf \u0996\u09ac\u09b0 \u09a4\u09cb\u09ae\u09be\u09a6\u09c7\u09b0    \u09ae\u09c1\u0987 \u09ac\u09c7\u09b2\u09be\u09b2 \u09a4\u09cb\u09ae\u09be\u09a6\u09c7\u09b0 \u09b9\u09cb\u0997\u09be \u09b8\u09be\u09b0    \u09ae\u09cb\u09b0\u09c7 \u099a\u09bf\u09a8\u099b\u09cb\u09a8\u09bf \u09a4\u09cb\u09ae\u09b0\u09be ", "label": 1}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The image is a meme that is not hateful, but it is a meme that is not hateful.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/Halal Memes (218).jpg", "text": "\u0995\u09bf Meme \u09ac\u09be\u09a8\u09be\u09ac\u09c7 \u09a4\u09be \u09a8\u09bf\u09df\u09c7 \u09b8\u09be\u09b0\u09be\u09a6\u09bf\u09a8 \u099a\u09bf\u09a8\u09cd\u09a4\u09be \u0995\u09b0\u09be Memer       \u098f\u09a6\u09bf\u0995\u09c7 \u0995\u09cb\u09a8\u09cb meme \u09a8\u09be \u09ac\u09be\u09a8\u09bf\u09df\u09c7 \u09b8\u09be\u09b0\u09be\u09a6\u09bf\u09a8 \u09ae\u099c\u09be \u09a8\u09c7\u0993\u09df\u09be \u09b8\u09be\u09a7\u09be\u09b0\u09a3 \u09aa\u09be\u09ac\u09b2\u09bf\u0995 ", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The meme is a picture of a man with glasses and a caption that says 'hateful meme' in a foreign language.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/tangaila (28).jpg", "text": "WHEN YOU SAY HI & THE OTHER PERSON SAYS ASSALAM WALAIKUM ", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The image is a meme that is not hateful, but it is a meme that is not hateful. It is a meme that is not hateful and follows social norms.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/bamboo-vaiya (330).jpg", "text": "\u0989\u099a\u09cd\u099a\u09ac\u09bf\u09a4\u09cd\u09a4    \u09ae\u09a7\u09cd\u09af\u09ac\u09bf\u09a4\u09cd\u09a4  \u09a8\u09bf\u09ae\u09cd\u09ae\u09ac\u09bf\u09a4\u09cd\u09a4    \u09b8\u09ae\u0995\u09be\u09ae\u09bf-\u09ac\u09bf\u09a4\u09cd\u09a4 ", "label": 1}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The image is a collection of different posters, including a hateful meme and a not-hateful meme. The hateful meme is a poster with a group of people in it, and the not-hateful meme is a poster with a group of people in it as well.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/Bangla Thug Life (5).jpg", "text": "Charlie puth   Khankir Puth", "label": 1}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The meme is not hateful, it is just a funny picture of two men with the same name.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/chintashil (919).jpg", "text": "\u09a8\u09a4\u09c1\u09a8 \u09ac\u09cd\u09af\u09be\u099f \u0995\u09bf\u09a8\u09c7 \u09ae\u09be\u09a0\u09c7 \u09a8\u09bf\u09df\u09c7 \u09af\u09be\u0993\u09df\u09be\u09b0 \u09aa\u09b0 \u09e7\u09e6/\u09e7\u09e7 \u09ac\u099b\u09b0 \u09ac\u09df\u09b8\u09c7 \u0986\u09ae\u09bf\u0983  ", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: A group of men are standing on a field, one of them holding a bat. The picture is a meme, and the caption is written in a foreign language.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/chintashil (151).jpg", "text": "\u099b\u09df\u09ac\u09be\u09b0 \u09b9\u09be\u09a4 \u09ac\u09cb\u09b2\u09be\u09a8\u09cb\u09b0 \u09aa\u09b0 \u09af\u0996\u09a8 \u09b8\u09aa\u09cd\u09a4\u09ae \u09ac\u09be\u09b0\u09c7\u09b0 \u099c\u09a8\u09cd\u09af \u0989\u09a0\u09c7 \u09a6\u09be\u0981\u09dc\u09be\u09df      *me    *my dick    i'm still worthy ", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The meme is a picture of a man with a hammer, and the caption reads "I'm still wrong." The meme is not hateful, but it is not hateful either. It is a meme that is not hateful, but it is not hateful either.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/CM (286).jpg", "text": "Abbu forcing me to talk with relatives in phone call ", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The image is a meme that is not hateful, but it is a hateful meme.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/Halal Memes (169).jpg", "text": "\u09af\u0996\u09a8 \u0995\u09be\u0989\u0995\u09c7 \u09a6\u09c7\u0996\u09be\u09a8\u09cb\u09b0 \u099c\u09a8\u09cd\u09af \u09b8\u09cd\u099f\u09cb\u09b0\u09bf \u09a6\u09bf\u0987  \u098f\u09ac\u0982 \u09b8\u09c7 \u09af\u0996\u09a8 \u09b8\u09c7\u099f\u09be \u09a6\u09c7\u0996\u09c7  Operation Successful ", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The image is a meme that is not hateful, it is a funny picture of two men in surgical scrubs with a caption that says 'operation successful'.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/chintashil (432).jpg", "text": "Single  me in my dream    Me*    Crush*", "label": 1}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: A man is standing in front of a group of cows, with the caption 'single me in my dream' above the photo. The man is standing in front of a group of cows, with the caption 'single me in my dream' above the photo.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/KAM (48).png", "text": "\u09b9\u09b2\u09cd\u09af\u09be\u09a8\u09cd\u09a1\u09c7\u09b0 \u09aa\u09cd\u09b0\u09a5\u09ae \u0997\u09cb\u09b2 \u0995\u09c7  \u09a6\u09bf\u099b\u09c7? PERSIE  \u09a4\u09c1\u0987 \u09aa\u09be\u09b0\u099b\u09cb\u099b \u09a8\u09be\u0995\u09bf \u09aa\u09be\u09b0\u09cb\u099b \u09a8\u09be\u0987 \u09a4\u09be \u099c\u09be\u09a8\u09a4\u09c7 \u099a\u09be\u0987 \u09a8\u09be\u0987 \u09aa\u09cd\u09b0\u09a5\u09ae \u0997\u09cb\u09b2 \u0995\u09c7 \u09a6\u09bf\u099b\u09c7 \u09a4\u09be \u09ac\u09b2!", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The image is a meme that is not hateful, it is just a funny picture of two men with different backgrounds.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/chosha (113).jpg", "text": "\u09a4\u09c1\u09ae\u09bf \u0995\u09bf \u0996\u09c7\u09a4\u09c7 \u099a\u09be\u0993 \u09ac\u09b2\u09cb \u0986\u099c\u0995\u09c7 \u09af\u09be \u099a\u09be\u0987\u09ac\u09c7 \u09a4\u09be\u0987 \u0996\u09be\u0993\u09df\u09be\u09ac\u09cb   \u0995\u09cd\u09b0\u09bf\u09ae !! \u0987\u09df\u09c7 \u09ae\u09be\u09a8\u09c7 \u0986\u0987\u09b8\u09cd\u0995\u09cd\u09b0\u09bf\u09ae ", "label": 1}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The image is a meme that is not hateful, it is just a funny picture of a woman with glasses and a bald man. The meme is not hateful, it is just a funny picture.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/ovodro_img (147).jpg", "text": "Neha, myself coming from village area    Neha kakkar  Neha Kakkar \u098f\u09b0 \u099a\u09cb\u0996\u09c7\u09b0 \u099c\u09cd\u09ac\u09b2...", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The image is a meme that is not hateful, it is a funny picture of a man and woman in a boat with a caption that says "Neha Kakkar" and "Pakistan".
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/TR (355).jpg", "text": "me :-  \u09b9\u09be\u099c\u09c0 \u09b6\u09b0\u09c0\u09df\u09a4\u09c1\u09b2\u09cd\u09b2\u09be\u09b9 \u09ac\u09be\u099c\u09be\u09b0\u09c7 \u0986\u09ae\u09be\u0997\u09cb \u09aa\u09c7\u09df\u09be\u099c\u09c7\u09b0 \u0986\u09dc\u09a4 \u0986\u099b\u09c7       She :-   i love u &  \u0986\u09ae\u09bf \u09a4\u09cb\u09ae\u09be\u0995\u09c7 \u099b\u09be\u09dc\u09be \u09ac\u09be\u0981\u099a\u09ac\u09cb \u09a8\u09be     me & my gf  ", "label": 1}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The meme is not hateful, it is just a funny picture of a couple sitting in a field of onions.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/ovodro_img (414).jpg", "text": "No Caption ", "label": 1}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The meme is not hateful, it is just a funny picture of a man with glasses and a flag.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/ovodro_img (1118).jpg", "text": "\u09ad\u09be\u0999\u09be , \u0997\u09b0\u09cd\u09a4 , \u0989\u099a\u09c1\u09a8\u09bf\u099a\u09c1 \u09b0\u09be\u09b8\u09cd\u09a4\u09be \u09a6\u09bf\u09df\u09c7 \u09af\u0996\u09a8 \u09a4\u09c1\u09ae\u09bf \u099c\u09cb\u09b0\u09c7 \u09ac\u09be\u0987\u0995 \u099a\u09be\u09b2\u09be\u0993   \u09a4\u09cb\u09ae\u09be\u09b0 \u09ac\u09cd\u09af\u09be\u0995\u09b8\u09bf\u099f\u09c7 \u09ac\u09b8\u09be \u09ac\u09cd\u09af\u09be\u0995\u09cd\u09a4\u09bf    Yeah. Go  slow ", "label": 1}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The meme is a picture of a man and woman in bed, with the caption "yeah go slow" in a foreign language. The meme is not hateful, but it is not hateful either.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/CM (126).jpg", "text": "\u0986\u099c\u0995\u09c7 \u09a5\u09c7\u0995\u09c7 \u09ad\u09be\u09b2\u09cb \u09ae\u09a4\u09cb \u09aa\u09dc\u09ac\u09cb*   And , now it begins .     \u09aa\u09b0\u09c0\u0995\u09cd\u09b7\u09be*     No, now it ends . ", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The meme is a comparison between a hateful and not-hateful meme. The hateful meme is a picture of a man in armor with a caption that is not hateful. The not-hateful meme is a picture of a man in armor with a caption that is not hateful.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/ovodro_img (166).jpg", "text": "\u0995\u09c0 \u099b\u09bf\u09b2    \u0995\u09c0 \u09b9\u09df\u09c7 \u0997\u09c7\u09b2     \u09ae\u09be\u09b0\u09cd\u0995 \u0995\u09b0\u09be \u09ac\u09b2 \u099f\u09be \u0995\u09c7\u09ae\u09a8 ? ", "label": 1}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The image is a meme that is not hateful, it is a picture of two women playing tennis and the caption is in a foreign language.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/ovodro_img (203).jpg", "text": "\u0993\u099f\u09be\u0987 \u09a4\u09cb \u09ae\u09a7\u09c1\u09b0 \u09a4\u09cb\u09a4\u09b2\u09be \u09a6\u09be\u09b2\u09be\u09b2   \u09a4\u09be\u0995\u09be\u09ac \u09b2\u09be \u0986\u09b0 \u0995\u09bf\u09a4\u09c1 \u09ac\u09b2\u09ac\u0993 \u09a8\u09be    \u09a4\u09cb\u09b0 \u09ae\u09a7\u09c1 \u09b8\u09a4\u09c0 \u09a8\u09be , \u09a4\u09cb\u09b0 \u09ae\u09a7\u09c1 \u098f\u0995\u099f\u09be \u09ac\u09c7#   \u0986\u09b2 \u09ac\u09be\u0981\u099a\u09a4\u09c7 \u099a\u09be\u0987 \u09b2\u09be \u0993\u09df\u09be\u09b2\u09be ", "label": 1}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The image is a comic strip with a car and a man in it. The car is being driven by a man who is looking at his hair in the rearview mirror. The comic strip is in a foreign language, possibly Bengali.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/TR (582).jpg", "text": "Nobody :-  \u0995\u09cd\u09b2\u09be\u09b8\u09c7 \u09ad\u09c7\u099c\u09be\u09b2 \u09b2\u09be\u0997\u09be \u09ac\u09bf\u09a6\u09cd\u09af\u09ae\u09be\u09a8    \u09ab\u09b0\u09bf\u09a6\u09aa\u09c1\u09b0 \u099c\u09bf\u09b2\u09be \u09b8\u09cd\u0995\u09c1\u09b2     10 /12 years old me:-   \u09b8\u09cd\u09af\u09be\u099f\u09be\u09b0 \u099b\u09be\u0993\u09df\u09be\u09b2 \u098f\u09ac\u09be\u09b0 \u09a4\u09cb\u09b0 \u09b8\u09cd\u09af\u09be\u099f\u09be \u09ad\u09be\u0999\u09ac\u09cb  ", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The image is a meme that is not hateful, it is a picture of a man with a sign that says "I am old" in Hindi.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/nurani-memes (100).jpg", "text": "-\u09ad\u09be\u09ac\u09c0, \u0986\u09aa\u09a8\u09be\u09b0 \u099b\u09c7\u09b2\u09c7 \u09a8\u09be\u0995\u09bf \u0995\u09cb\u09a8 \u09ae\u09c7\u09df\u09c7\u09b0\u09c7 \u0996\u09c7\u09df\u09c7 \u099b\u09c7\u09dc\u09c7 \u09a6\u09bf\u09b8\u09c7 ?   - \u099c\u09bf \u09ad\u09be\u09ac\u09bf , \u0986\u09aa\u09a8\u09be\u09b0 \u09ae\u09c7\u09df\u09c7\u09b0 \u09b8\u09be\u09a5\u09c7 \u098f\u0987\u09b0\u0995\u09ae \u0995\u09b0\u09be \u099f\u09be \u0993\u09b0 \u098f\u0995\u09a6\u09ae \u0989\u099a\u09bf\u09ce \u09b9\u09df\u09a8\u09be\u0987    \u09aa\u09be\u09b6\u09c7\u09b0 \u09ac\u09be\u09b8\u09be\u09b0 Nigga  \u09ad\u09be\u09ac\u09c0* ", "label": 1}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The meme is a picture of a child with a caption that is written in a foreign language. The caption is not hateful, but it is not hateful either.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/tangaila (150).jpg", "text": "\u09ae\u09be\u0997\u09b0\u09bf\u09ac\u09c7\u09b0 \u09a8\u09be\u09ae\u09be\u099c \u09b6\u09c7\u09b7 \u0995\u09b0\u09c7 \u09b6\u09c1\u09a8\u09b2\u09be\u09ae \u0986\u09ae\u09bf \u09ae\u09be\u09b0\u09be \u0997\u09c7\u099b\u09bf    jagaonews24.com", "label": 1}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The meme is not hateful, it is not intended to denigrate, vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/tangaila (138).jpg", "text": "\u09af\u0996\u09a8 \u09ae\u09bf\u09ae \u0986\u09ae\u09be\u09b0 \u09aa\u09cd\u09b0\u09aa\u09cb\u099c\u09be\u09b2 \u09b0\u09bf\u099c\u09c7\u0995\u09cd\u099f \u0995\u09b0\u09c7 \u09a6\u09c7\u09df \u09a4\u0996\u09a8\u0983-   \u0986\u09ae\u09bf*   \u09ae\u09bf\u09ae", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The meme is a picture of a man holding a gun to a woman's head, with the caption "Hateful if it intends to denigrate, vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status." The meme is not hateful, but it is a violent and potentially dangerous situation.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/CM (375).jpg", "text": "*\u09b2\u0995\u09a1\u09be\u0989\u09a8 \u09a6\u09c0\u09b0\u09cd\u0998\u09b8\u09cd\u09a5\u09be\u09df\u09c0 \u09b9\u09b2\u09c7 \u0985\u09a8\u09b2\u09be\u0987\u09a8 \u0995\u09cd\u09b2\u09be\u09b8\u09c7\u09b0 \u099c\u09a8\u09cd\u09af \u09a1\u09bf\u09b8\u09c7\u09ae\u09cd\u09ac\u09b0 \u09ae\u09be\u09b8\u09c7 PS5  \u09ae\u09a1\u09c7\u09b2\u09c7\u09b0 \u0989\u099a\u09cd\u099a \u0997\u09a4\u09bf\u09b0 \u09b0\u09be\u0989\u099f\u09be\u09b0 \u0995\u09c7\u09a8\u09be\u09b0 \u09aa\u09cd\u09b0\u09df\u09cb\u099c\u09a8\u09c0\u09df\u09a4\u09be \u09ac\u09b0\u09cd\u09a3\u09a8\u09be \u0995\u09b0\u09be \u0986\u09ae\u09bf     *\u0986\u09ae\u09be\u09b0 \u0986\u09ae\u09cd\u09ae\u09c1  ", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The image is a meme that is not hateful, it is a funny and lighthearted moment between two people.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/chosha (57).jpg", "text": "\u09ad\u09be\u0987 \u099c\u09be\u09a8\u09bf\u09b8 \u09ac\u09be\u0982\u09b2\u09be\u09a6\u09c7\u09b6 \u098f\u0996\u09a8 \u09a1\u09bf\u099c\u09bf\u099f\u09be\u09b2 \u0995\u09b0\u09cd\u09ae\u0995\u09be\u09a8\u09cd\u09a1 \u09b8\u09ab\u09b2 \u09b9\u099a\u09cd\u099b\u09c7     \u09ae\u09be\u09a4\u09be\u09b2 \u09ac\u09a8\u09cd\u09a7\u09c1    \u09af\u09c7\u09a6\u09bf\u09a8 \u0998\u09b0\u09c7 \u09ac\u09b8\u09c7 \u0995\u09cd\u09b0\u09c7\u09a1\u09bf\u099f\u0995\u09be\u09b0\u09cd\u09a1 \u09a6\u09bf\u09df\u09c7 \u09ae\u09a6 \u0995\u09bf\u09a8\u09ac\u09cb , \u0986\u09b0 Olx  \u098f \u0996\u09be\u09b2\u09bf \u09ac\u09cb\u09a4\u09b2 \u09ac\u09c7\u099a\u09ac\u09cb \u09b8\u09c7\u0987\u09a6\u09bf\u09a8 \u09ac\u09be\u0982\u09b2\u09be\u09a6\u09c7\u09b6 \u09a1\u09bf\u099c\u09bf\u099f\u09be\u09b2 \u09b9\u09ac\u09c7 ", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The image is a meme that is not hateful, it is a joke between two people. The meme is not hateful, it is a funny joke between two people.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/bangla-troll (24).jpg", "text": "\u0985\u09a8\u09a8\u09cd\u09a4 \u09ac\u09b2\u09cb \u09a6\u09c7\u0996\u09bf, \u09aa\u09be\u09df\u099c\u09be\u09ae\u09be\u09b0 \u09ab\u09bf\u09a4\u09be \u0995\u09c7 ENGLISH \u098f  \u0995\u09bf \u09ac\u09b2\u09c7  P.H.D. \u09ac\u09b2\u09c7 \u09ae\u09cd\u09af\u09be\u09a1\u09be\u09ae... \u09ae\u09be\u09a8\u09c7 \u0995\u09bf ?!\"paayjama Holding Device\" ", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The meme is not hateful, it is just a funny picture of a man with glasses and a woman with a fake mustache.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/ovodro_img (469).jpg", "text": "\u098f\u0995 \u099f\u09be\u09a8\u09c7 \u09a4\u09c7 \u09af\u09c7\u09ae\u09a8 \u09a4\u09c7\u09ae\u09a8 \u09a6\u09c1\u0987 \u099f\u09be\u09a8\u09c7\u09a4\u09c7 \u09b0\u09be\u099c\u09be    \u09a4\u09bf\u09a8\u099f\u09be\u09a4\u09c7 \u09b0\u09c1\u09aa\u09ae \u0986\u09ae\u09bf \u09b0\u0995\u09b8\u09cd\u099f\u09be\u09b0\u09a6\u09c7\u09b0 \u09ac\u09be\u09ac\u09be !", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The image is a meme that is not hateful, it is a funny picture of a man with glasses and a beard playing a guitar.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/bamboo-vaiya (298).jpg", "text": "*\u0986\u09ae\u09be\u09b0 \u098f\u09a4 \u09b8\u09be\u09a7\u09c7\u09b0 \u09ae\u09a8 \u09ac\u09a7\u09c1\u09df\u09be , \u09b9\u09be\u09df \u09b0\u09c7 \u0995\u09bf \u099c\u09be\u09a8\u09bf, \u0995\u09bf \u0995\u09b0\u09c7 !* line arrives    My mind- ", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: A purple bed sheet with a microphone on it, and a caption that says "my mind" is displayed on a computer screen. The caption is in a foreign language, which is likely to be Bengali.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/KAM (122).png", "text": "\u09ac\u09cd\u09b0\u09be\u099c\u09bf\u09b2-\u0986\u09b0\u09cd\u099c\u09c7\u09a8\u09cd\u099f\u09bf\u09a8\u09be\u09b0 \u09b8\u09ae\u09b0\u09cd\u09a5\u0995\u09b0\u09be \u099a\u09be\u09df \u09ac\u09cd\u09b0\u09be\u099c\u09bf\u09b2 \u09ac\u09a8\u09be\u09ae \u0986\u09b0\u09cd\u099c\u09c7\u09a8\u09cd\u099f\u09bf\u09a8\u09be \u09ab\u09be\u0987\u09a8\u09be\u09b2! \u0986\u09ac\u09be\u09b0 \u09a4\u09be\u09b0\u09be\u0987 \u099a\u09be\u09df, \u09a4\u09be\u09a6\u09c7\u09b0 \u09ac\u09bf\u09aa\u09b0\u09c0\u09a4 \u099f\u09bf\u09ae \u09af\u09be\u09a4\u09c7 \u09a4\u09be\u09a6\u09c7\u09b0 \u0986\u0997\u09c7 \u09ac\u09be\u09a6 \u09b9\u09df\u09c7 \u09af\u09be\u09df", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The image is a meme that is not hateful, it is a political joke that is not meant to harm or mock anyone.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/tangaila (206).jpg", "text": "\u09a4\u09cb\u09b0\u09be \u0996\u09c7\u09b2\u09be    \u09a4\u09cb\u09b0\u09be \u0996\u09c7\u09b2\u09be  Na", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The image is a meme that is not hateful, but it is a meme that is hateful.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/ovodro_img (127).jpg", "text": "2018  \u09b8\u09be\u09b2 \u099f\u09be \u09b8\u09a4\u09cd\u09af\u09bf\u0987 \u0985\u09ac\u09be\u0995 \u0995\u09b0\u09b2 ", "label": 1}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The image is a collage of four different pictures, each featuring a different person. The caption reads "2018 hateful or not hateful."
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/ovodro_img (1).jpg", "text": "\u0993 \u09ae\u09be\u0987 \u0997\u09a1   \u0986\u09b9 \u0989\u09b9 \u0993 \u0987\u09df\u09be    BRAZZERS", "label": 1}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The image is a meme that is not hateful, it is a woman being thrown in the air by a man in a wrestling ring. The meme is not hateful, it is just a funny image of a woman being thrown in the air by a man.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/ovodro_img (962).jpg", "text": "\u09b0\u09be\u099c\u09be : \u0995\u09bf \u09ac\u09cd\u09af\u09be\u09aa\u09be\u09b0 ! \u0995\u09cb\u09ae\u09b0 \u09ac\u09be\u0981\u0995\u09bf\u09df\u09c7 \u09b9\u09be\u099f\u099b\u09cb \u0995\u09c7\u09a8\u09cb ?   \u09b0\u09be\u09a8\u09bf :  \u0995\u09be\u09b2 \u09ad\u09c1\u09b2 \u09ab\u09c1\u099f\u09cb\u09df \u09a2\u09c1\u0995\u09bf\u09df\u09c7\u099b\u09bf\u09b2\u09c7  ", "label": 1}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The meme is a cartoon with a woman and a man, and the caption is in a foreign language. The meme is not hateful, but it is not hateful either.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/chintashil (885).jpg", "text": "\u09ed\u099f\u09be\u09b0 \u09b8\u09ae\u09df \u09aa\u09dc\u09a4\u09c7 \u09ac\u09b8\u099b\u09bf \u09a6\u09c1\u0987 \u0998\u09a8\u09cd\u099f\u09be \u099f\u09be\u09a8\u09be \u09aa\u09dc\u09be\u09b0 \u09aa\u09b0 \u0989\u09a0\u09c7 \u09a6\u09c7\u0996\u09bf \u09ed \u099f\u09be \u09eb \u09ac\u09be\u099c\u09c7  ", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The image is a meme that is not hateful, it is a funny picture of a man making a peace sign with his hand. The meme is not hateful, it is just a funny picture.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/ovodro_img (1162).jpg", "text": "\u09ad\u09be\u0987 \u09ad\u09be\u0987 \u099a\u09c1\u09a6\u09bf\u09b0 \u09ad\u09be\u0987     \u0995\u09be\u099c \u09b9\u09df\u09c7 \u0997\u09c7\u09b2\u09c7 \u099d\u0997\u09dc\u09be \u09b2\u09be\u0997\u09be\u0987 ", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The meme is not hateful, it is just a funny picture of two boys making funny faces.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/Bangla Thug Life (295).jpg", "text": "\"\u0986\u09ae\u09b0\u09be \u09a6\u09c7\u09b6\u0995\u09c7 \u09ac\u09bf\u09b6\u09cd\u09ac\u09c7\u09b0 \u0995\u09be\u099b\u09c7 \u09b0\u09bf\u09aa\u09cd\u09b0\u09c7\u099c\u09c7\u09a8\u09cd\u099f \u0995\u09b0\u09bf\"  \" \u09b9\u09cd\u09af\u09be, \u0986\u09ae\u09bf \u09a4\u09cb \u0995\u09cd\u09b0\u09bf\u0995\u09c7\u099f \u09ae\u09be\u09a0\u09c7 \u0998\u09cb\u09dc\u09be\u09b0 \u099c\u09a8\u09cd\u09af \u0998\u09be\u09b8 \u0995\u09be\u099f\u09bf\" ", "label": 1}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The meme is not hateful, it is just a funny picture of a cricket player with a caption that is not hateful.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/bamboo-vaiya (321).jpg", "text": "\u09ae\u09a7\u09cd\u09af\u09b0\u09be\u09a4\u09c7 \u09b8\u09ae\u09df \u0995\u09be\u099f\u09be\u09a8\u09cb\u09b0 \u099c\u09a8\u09cd\u09af \u099b\u09be\u09a6\u09c7 \u0989\u09a0\u09c7 \u09af\u0996\u09a8 \u09aa\u09cd\u09b0\u09a4\u09bf\u09ac\u09c7\u09b6\u09c0 \u09ac\u09dc \u09ad\u09be\u0987\u09df\u09c7\u09b0 \u09b8\u09be\u09a5\u09c7 \u09a6\u09c7\u0996\u09be \u09b9\u09df \u0995\u09bf\u09a8\u09cd\u09a4\u09c1 \u09a4\u09ce\u0995\u09cd\u09b7\u09a3\u09be\u09ce \u09ae\u09a8\u09c7 \u09aa\u09dc\u09c7 \u09a4\u09bf\u09a8\u09bf \u09e8 \u09ae\u09be\u09b8 \u0986\u0997\u09c7 \u0986\u09a4\u09cd\u09ae\u09b9\u09a4\u09cd\u09af\u09be \u0995\u09b0\u09c7\u099b\u09c7\u09a8\u0983 ", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The meme is not hateful, it is just a funny picture of a boy looking at a camera with a caption that says "I'm not hateful."
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/chintashil (664).jpg", "text": "When it comes to food blogging    Faiza is a good couple flexer", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The woman in the meme is wearing a hijab, a traditional head covering worn by some Muslim women.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/ovodro_img (1360).jpg", "text": "\u09b9\u09cd\u09af\u09be , \u0986\u09ae\u09be\u09b0 \u09ab\u09cd\u09af\u09be\u09a8 \u09a6\u09c7\u09b0 \u09ac\u09b2\u099b\u09bf    \u0986\u09ae\u09be\u09b0 \u09aa\u09cd\u09b0\u09a4\u09bf \u09af\u09be \u0987\u09ae\u09cb\u09b6\u09a8 \u099b\u09bf\u09b2  \u09b8\u09be\u09a8\u09b2\u09be\u0987\u099f \u09a6\u09bf\u09df\u09c7 \u09a7\u09c1\u09df\u09c7 \u09a8\u09c7 \u0964 ", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The meme is not hateful, it is just a sports player giving a thumbs up.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/chintashil (554).jpg", "text": "\u098f\u0987\u09b8\u09ac\u09c7\u09b0 \u0995\u09bf \u09a6\u09b0\u0995\u09be\u09b0 \u099b\u09bf\u09b2\u09cb    \u0986\u09ae\u09bf \u09a4\u09cb just FB \u09a4\u09c7 \"works at TransEnd\"    \u09aa\u09cb\u09b8\u09cd\u099f \u09a6\u09bf\u09b2\u09be\u09ae ", "label": 1}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The meme is not hateful, it is just a funny joke.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/bamboo-vaiya (105).jpg", "text": "\u09ac\u09be\u0982\u09b2\u09be\u09a6\u09c7\u09b6 \u099f\u09c7\u09b2\u09bf\u09ad\u09bf\u09b6\u09a8 - \u09ac\u09bf\u099f\u09bf\u09ad\u09bf     \u09ad\u09cb\u099f\u09c7 \u09a6\u09be\u09dc\u09be\u09a8\u09cb\u09b0 \u0997\u09cd\u09af\u09be\u09dc\u09be \u09b8\u09be\u09ae\u09b2\u09be\u09a4\u09c7 \u09a8\u09be \u09aa\u09c7\u09b0\u09c7 \u09a8\u09bf\u09b0\u09cd\u09ac\u09be\u099a\u09a8\u09c7\u09b0 \u0986\u0997\u09c7\u0987 \u0996\u09be\u099f\u09c7 \u09b6\u09c1\u09df\u09c7 \u09b6\u09c1\u09df\u09c7 \u09ad\u09cd\u09af\u09be\u09b2\u099f \u09ac\u09be\u0995\u09cd\u09b8\u09c7 \u09ad\u09cb\u099f \u09a2\u09c1\u0995\u09be\u099a\u09cd\u099b\u09c7\u09a8 \u09a8\u09cd\u09af\u09be\u09b0\u09cb \u0986\u09b2\u09ae \u0964 ", "label": 1}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The image is a meme that is not hateful, it is a picture of two people in bed together with a caption that is not hateful.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/chintashil (879).jpg", "text": "Nothing bro    Me successfully cross freeport to Agrabad ", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The meme is a hateful one, as it is mocking a person's appearance.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/netflix (140).jpg", "text": "Anya Taylor-joy in The Queen's Gambit      Anya Taylor-joy in The New Mutants ", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The image is a meme that is not hateful, it is just a funny joke. The meme is a comparison between two women, one of whom is a famous actress and the other is a woman who is not as well known. The meme is not hateful, it is just a funny joke.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/Bangla Thug Life (313).jpg", "text": "I'm weak in maths      what you see      what a mathematician see", "label": 1}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The meme is not hateful, it is just a funny picture of a man with a big butt.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/chintashil (426).jpg", "text": "Girl - **choke me harder**   \u09ac\u09cb\u09ac\u09be \u099c\u09c0\u09a8 -   Careful now, girl.    be careful.    ", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The meme is a picture of a man with the caption 'girl, choke me harder.' The caption is in a foreign language, which is not English.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/chintashil (561).jpg", "text": "\u09aa\u09c7\u09df\u09be\u09b0\u09be \u0996\u09be\u0993\u09df\u09be\u09b0 \u09b8\u09ae\u09df \u09af\u0996\u09a8 \u09b8\u09ac\u09be\u09b0 \u09aa\u09c7\u09df\u09be\u09b0\u09be\u09b0 \u09ad\u09c7\u09a4\u09b0\u09c7\u09b0 \u0985\u0982\u09b6 \u09b8\u09be\u09a6\u09be \u09a5\u09be\u0995\u09c7 \u0995\u09bf\u09a8\u09cd\u09a4\u09c1 \u0986\u09ae\u09be\u09b0 \u099f\u09be \u0997\u09cb\u09b2\u09be\u09aa\u09bf \u09b9\u09df :-     \u09ec-\u09ed \u09ac\u099b\u09b0 \u09ac\u09df\u09b8\u09c0 \u0986\u09ae\u09bf :-  my happiness.... is immeasurable and my day is made. ", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The meme is not hateful, it is just a joke. The man is making a funny face and the text is in a foreign language.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/Halal Memes (188).jpg", "text": "\u09e7 \u09ae\u09bf\u09a8\u09bf\u099f \u09a7\u09b0\u09c7 \u0995\u09b0\u09cb\u09a8\u09be \u09b8\u09a4\u09b0\u09cd\u0995\u09a4\u09be \u09ac\u09be\u09b0\u09cd\u09a4\u09be \u09b6\u09cb\u09a8\u09be\u09b0 \u09aa\u09b0 \u09af\u0996\u09a8 \u09a6\u09c7\u0996\u09bf \u09af\u09be\u0995\u09c7 \u0995\u09b2 \u09a6\u09bf\u09df\u09c7\u099b\u09bf \u09a4\u09be\u09b0 \u09ab\u09cb\u09a8 \u09ac\u09a8\u09cd\u09a7     \u099a\u09c1\u09a6\u09c7 \u099a\u09be\u099f\u09a8\u09bf, \u09ac\u09c7\u0995\u09be\u09b0 \u0996\u09be\u099f\u09a8\u09bf   \u0964", "label": 1}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The meme is a cartoon of a man with a mustache and a speech bubble. The speech bubble contains a message that is not hateful.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/bamboo-vaiya (197).jpg", "text": "\u09b6\u09aa\u09bf\u0982 \u09ae\u09b2\u09c7 \u0986\u0997\u09c1\u09a8 \u09b2\u09be\u0997\u09be\u09df \u09ae\u09be\u0987\u0995\u09c7 \u09ae\u09b2 \u09a4\u09cd\u09af\u09be\u0997 \u0995\u09b0\u09a4\u09c7 \u09ac\u09b2\u09b2\u09c7 \u09af\u0996\u09a8 \u0986\u09aa\u09a8\u09bf \u09aa\u09cd\u09af\u09be\u09a8\u09cd\u099f \u0996\u09cb\u09b2\u09be \u09b6\u09c1\u09b0\u09c1 \u0995\u09b0\u09c7\u09a8    You:- Your father:   Your gay friend:  pasher dokander:", "label": 1}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The meme is not hateful, it is just a cartoon with a caption that is not hateful. The caption is a joke and is not meant to be taken seriously. The meme is not hateful, it is just a cartoon with a caption that is not hateful. The caption is a joke and is not meant to be taken seriously.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/CM (641).jpg", "text": "\u09eb \u099f\u09be\u0995\u09be \u09ac\u09be\u09b8 \u09ad\u09be\u09dc\u09be \u09ac\u09be\u099a\u09be\u09a8\u09cb\u09b0 \u099c\u09a8\u09cd\u09af \u09b9\u09c7\u099f\u09c7 \u09b9\u09c7\u0981\u099f\u09c7 \u09ac\u09be\u09b8\u09be\u09df \u09ab\u09bf\u09b0\u09be\u09b0 \u09b8\u09ae\u09df \u09e8\u09e6 \u099f\u09be\u0995\u09be\u09b0 \u0995\u09cb\u0995\u09be - \u0995\u09cb\u09b2\u09be \u0996\u09c7\u09df\u09c7 \u09ab\u09c7\u09b2\u09bf     BREAKING NEWS    MAN SOLD TV TO BUY REMOTE  \" I WON'T DO IT AGAIN. I JUST NEEDED IT FOR MY-OH\" - HE SAID. ", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The meme is not hateful, it is just a news article with a man's face on it.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/KAM (6).jpg", "text": "\u09b9\u09be\u09b0\u09bf \u0986\u09ae\u09b0\u09be, \u0995\u09be\u09a8\u09cd\u09a6\u09c7 \u0987\u09a8\u09cd\u09a1\u09bf\u09df\u09be", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The meme is not hateful, it is just a funny picture of two men with different languages.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/KAM (158).jpg", "text": "\u09a8\u09c7\u09a4\u09be\u09b0\u09be V \u099a\u09bf\u09b9\u09cd\u09a8 \u09a6\u09c7\u0996\u09bf\u09df\u09c7 \u09ac\u09c1\u099d\u09be\u09df \u09af\u09be \u09a4\u09be\u09b0\u09be \u098f\u0995\u099f\u09be \u09a6\u09c1 \u09a8\u09ae\u09cd\u09ac\u09b0 \u09ae\u09be\u09b2", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The image is a meme that is not hateful, it is a political statement that is not intended to harm or mock anyone. The man in the picture is a political leader and the meme is a political statement.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/Bangla Thug Life (68).jpg", "text": "*Gang-bang vidieos exists ; women pornstar : \u09ac\u09bf\u09a7\u09bf \u09a4\u09c1\u09ae\u09bf \u09ac\u09b2\u09c7 \u09a6\u09be\u0993 \u0986\u09ae\u09bf \u0995\u09be\u09b0 ", "label": 1}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The meme is a hateful one, as it is mocking a woman's appearance and gender.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/CM (198).jpg", "text": "Islamic University of Technology  ", "label": 1}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The image is a meme that is not hateful, but it is a meme that is not hateful. The meme features a man with a beard and a hat, sitting in a chair with a bottle of ketchup in his hand. The caption reads "Islamic University of Technology".
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/Memeholics (227).jpg", "text": "EKTU NICHE ASHEN FOODPANDAR DELIVERY NIYE ASCHI ", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The meme is a cartoon of three men in a row, with the first one being a food delivery man. The caption reads 'Et tu, Aschen, foodpanda delivery Nye Ashi?'
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/tangaila (221).jpg", "text": "\u0998\u099f\u0995\u0983 \u099b\u09c7\u09b2\u09c7\u09b0 \u09ae\u09be\u09a5\u09be\u09df \u099a\u09c1\u09b2 \u09a8\u09be\u0987, \u09ac\u09c1\u0987\u09dc\u09be , \u09ad\u09c1\u09b0\u09bf\u0993\u09df\u09be\u09b2\u09be \u0995\u09bf\u09a8\u09cd\u09a4\u09c1 \u09b8\u09c7 \u09ac\u09bf\u09b8\u09bf\u098f\u09b8 \u0995\u09cd\u09af\u09be\u09a1\u09be\u09b0 \u0964 \u09ae\u09be\u09b8\u09c7 \u098f\u0995 \u09b2\u09be\u0996 \u0995\u09be\u09ae\u09be\u09df \u0964    *\u09b2\u09c7 \u09ab\u099c\u09bf\u09b2\u09be\u09a4\u09c1\u09a8\u09cd\u09a8\u09c7\u099b\u09be\u09b0 \u09ae\u09c7\u09df\u09c7\u0983", "label": 1}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The image is a meme that is not hateful, it is just a funny picture of a group of girls. The meme is not hateful, it is just a funny picture of a group of girls.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/chintashil (801).jpg", "text": "\u09ae\u09be\u099d\u09c7\u09ae\u09a7\u09cd\u09af\u09c7 Ex \u098f\u09b0 \u09ae\u09be\u09df\u09c7\u09b0 \u0995\u09a5\u09be \u09ad\u09be\u09ac\u09bf      \u0995\u09bf \u099c\u09bf\u09a8\u09bf\u09b8 \u099c\u09a8\u09cd\u09ae \u09a6\u09bf\u09df\u09c7\u099b\u09c7\u09a8 \u0986\u09a8\u09cd\u099f\u09bf ", "label": 1}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The meme is a quote from a movie, and it is not hateful.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/ovodro_img (311).jpg", "text": "\u09ac\u099b\u09b0\u09c7\u09b0 \u0996\u09be\u09b0\u09be\u09aa \u0995\u09bf\u099b\u09c1 \u09b8\u09bf\u09a8\u09c7\u09ae\u09be   \u09aa\u09cd\u09b0\u09a5\u09ae\u09c7 \u0986\u09b8\u09c7 RACE 3  \u09a4\u09be\u09b0\u09aa\u09b0 \u0986\u09b8\u09c7 Thugs of Hindustan  \u0986\u09b0 \u09b8\u09ac \u09b6\u09c7\u09b7\u09c7 \u0986\u09b8\u09c7 Zero ", "label": 1}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The meme is a comic strip that is not hateful, but it is a comic strip that is not hateful.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/Bangla Thug Life (396).jpg", "text": "\u09ac\u09bf\u09df\u09c7\u09b0 \u09e7 \u09ae\u09be\u09b8 \u09aa\u09b0 \u09b8\u09cd\u09ac\u09be\u09ae\u09c0 \u09af\u0996\u09a8 \u09ac\u09bf\u09a6\u09c7\u09b6 \u099a\u09b2\u09c7 \u09af\u09be\u09df*   \u09b9\u09b0\u09cd\u09a8\u09bf \u09ac\u0989\u0983 \u09ab\u09c1\u099f\u09cb\u09b0 \u09ae\u09a7\u09cd\u09af\u09c7 \u099c\u09cd\u09ac\u09b2\u099b\u09c7 \u0986\u0997\u09c1\u09a8, \u09a2\u09c1\u0995\u09be\u09a4\u09c7 \u09b9\u09ac\u09c7 \u09ae\u09c2\u09b2\u09cb-\u09ac\u09c7\u0997\u09c1\u09a8 ", "label": 1}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The meme is not hateful, it is just a cartoon with a woman sitting in a pot. The cartoon is not hateful, it is just a comical representation of a woman sitting in a pot. The cartoon is not hateful, it is just a comical representation of a woman sitting in a pot. The cartoon is not hateful, it is just a comical representation of a woman sitting in a pot.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/ovodro_img (472).jpg", "text": "Breakup \u09b9\u0993\u09df\u09be\u09b0 \u09aa\u09b0\u09c7 \u09ac\u09a8\u09cd\u09a7\u09c1 \u09af\u0996\u09a8 \u0995\u09be\u09a8\u09cd\u09a8\u09be\u0995\u09be\u099f\u09bf \u0995\u09b0\u09c7 !  \u09a4\u0996\u09a8 \u0986\u09ae\u09bf\u0983-   \u098f\u0987 \u09a4\u09cb\u09b0 \u09ac\u09cd\u09b0\u09be \u098f\u09b0 \u09b8\u09be\u0987\u099c \u0995\u09a4\u09cb \u09b0\u09c7 ?  \u09ae\u09c7\u09df\u09c7\u09a6\u09c7\u09b0 \u09ae\u09a4\u09cb \u0995\u09be\u09a8\u09cd\u09a8\u09be \u0995\u09b0\u09bf\u09b8 \u0995\u09c7\u09a8\u09cb \u09b0\u09c7 \u09ac\u09be\u09b2 !", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The meme is a picture of a man with a cigarette in his mouth, and the text is in a foreign language. The meme is not hateful, but it is not hateful either.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/netflix (180).jpg", "text": "\u09b8\u09be\u09b0\u09ae\u09b0\u09cd\u09ae   why waste time say lot word when few word do trick ?   \u09ad\u09be\u09ac-\u09b8\u09ae\u09cd\u09aa\u09cd\u09b0\u09b8\u09be\u09b0\u09a3-      I request elaboration. ", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The meme is a comparison between a hateful and not-hateful meme. The meme is a comparison between a hateful and not-hateful meme. The meme is a comparison between a hateful and not-hateful meme.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/ovodro_img (1225).jpg", "text": "\u09af\u0996\u09a8 \u09a6\u09be\u09a6\u09be \u09ac\u09b2\u09c7 \u098f\u09ae\u09be\u09b8\u09c7 \u09b6\u09aa\u09bf\u0982 \u098f\u09b0 \u0996\u09b0\u099a \u09a6\u09bf\u09a4\u09c7 \u09aa\u09be\u09b0\u09ac\u09c7 \u09a8\u09be    \u09a4\u0996\u09a8 \u09ac\u09cc\u09a6\u09bf : ", "label": 1}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The meme is a picture of a woman in a red sari and a man in a yellow shirt. The caption is in a foreign language, but the words are translated as "hateful" and "not-hateful."
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/Halal Memes (269).jpg", "text": "\u09af\u0996\u09a8 \u0986\u09aa\u09a8\u09be\u09b0 \u09ac\u09a8\u09cd\u09a7\u09c1 \u09ae\u09c7\u09df\u09c7\u09a6\u09c7\u09b0 \u09b8\u09be\u09ae\u09a8\u09c7 \u0986\u09aa\u09a8\u09be\u09b0 \u09ac\u09bf\u099a\u09bf\u09a4\u09c7 \u099f\u09cb\u0995\u09be \u09a6\u09c7\u09df    *\u09b2\u09c7 \u0986\u09aa\u09a8\u09bf  ", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The meme is a picture of a man with a caption that is written in a foreign language. The caption is not hateful, but it is not hateful either.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/tangaila (195).jpg", "text": "\u0987\u099e\u09cd\u099c\u09bf\u09a8\u09bf\u09df\u09be\u09b0\u09bf\u0982 \u0995\u09b0\u09be\u09b0 \u099c\u09a8\u09cd\u09af \u09af\u0996\u09a8 \u09a8\u09bf\u0989 \u098f\u09a1\u09ae\u09bf\u09b6\u09a8 \u09a8\u09c7\u0987    \u09af\u0996\u09a8 \u0987\u099e\u09cd\u099c\u09bf\u09a8\u09bf\u09df\u09be\u09b0\u09bf\u0982 \u09b6\u09c7\u09b7 \u0995\u09b0\u09c7 \u09ac\u09c7\u09b0 \u09b9\u0987     ", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The image is a meme that is not hateful, it is a picture of two men with different skin colors and one of them is wearing sunglasses. The meme is not hateful, it is just a funny picture.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/Halal Memes (237).jpg", "text": "\u09ae\u09be\u099f\u09bf\u09b0 \u09ac\u09cd\u09af\u09be\u0982\u0995\u09c7 \u09aa\u09cd\u09b0\u09a4\u09bf\u09a6\u09bf\u09a8 \u09e7\u09e6 \u099f\u09be\u0995\u09be \u09b0\u09c7\u0996\u09c7 \u09e8 \u09ac\u099b\u09b0 \u09aa\u09b0 \u09ac\u09cd\u09af\u09be\u0982\u0995 \u09ad\u09c7\u0999\u09cd\u0997\u09c7 \u09af\u0996\u09a8 \u09eb\u09e6 \u099f\u09be\u0995\u09be \u09aa\u09be\u0993\u09df\u09be \u09af\u09be\u09df    \u0986\u09ae\u09cd\u09ae\u09c1\u0983    \u0986\u09ae\u09bf \u0995\u09bf\u09a4\u09be\u09b0 \u09ae\u09a7\u09cd\u09af\u09c7 \u099f\u09be\u0995\u09be \u09a2\u09be\u09b2\u09a4\u09be\u099b\u09bf  ", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The image is a meme that is not hateful, it is a sports team photo with a caption that is not hateful.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/ovodro_img (1206).jpg", "text": "\u0996\u09be\u09dc\u09be \u09a6\u09c7\u0996\u0995\u09c7 \u09b9\u09be\u09b8\u09b2\u09bf\u09df\u09be    \u0995\u09c1\u099b \u09a6\u09c7\u09b0 \u09ac\u09be\u09a6 \u0986\u09a8\u09cd\u09a6\u09be\u09b0 \u0998\u09c1\u099a\u09be\u09b2\u09bf\u09df\u09be    \u09ac\u09be\u09b9\u09be\u09b0 \u0995\u09be\u09b0\u0995\u09c7 \u09ac\u09cd\u09af\u09be\u09a0\u09be\u09b2\u09bf\u09df\u09be     \u09ae\u09c1 \u09ae\u09c7 \u09b2\u09c7\u09b2\u09bf\u09df\u09be ", "label": 1}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The image is a meme that is not hateful, it is a woman with her mouth open and a man is trying to kiss her. The meme is not hateful, it is just a funny image.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/chintashil (469).jpg", "text": "\u09b9\u09c7 \u09aa\u09b0\u09ae \u0995\u09b0\u09c1\u09a3\u09be\u09ae\u09df ; \u09a6\u09df\u09be \u0995\u09b0\u09c1\u09a8     \u0986\u09ae\u09bf \u09af\u09c7\u09a8\u09cb \u09aa\u09b0\u09c7\u09b0 \u099c\u09a8\u09cd\u09ae\u09c7 \u09b6\u0999\u09cd\u0996\u099a\u09bf\u09b2 \u0995\u09bf\u0982\u09ac\u09be \u09b6\u09be\u09b2\u09bf\u0995\u09c7\u09b0 \u09ac\u09c7\u09b6\u09c7 \u09ac\u09be\u0982\u09b2\u09be\u09df \u09ab\u09bf\u09b0\u09c7 \u0986\u09b8\u09a4\u09c7 \u09aa\u09be\u09b0\u09bf ", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The image is a meme that is not hateful, it is a political statement that is not hateful.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/tangaila (235).jpg", "text": "\u09af\u0996\u09a8 \u0998\u09be\u099f\u09be\u0987\u09b2\u09c7\u09b0 \u09ae\u09c7\u09df\u09c7 \u099c\u09be\u09a8\u09a4\u09c7 \u09aa\u09be\u09b0\u09c7 \u09a4\u09be\u09b0 \u098f\u0995\u09cd\u09b8 \u098f\u0996\u09a8 \u0985\u09a8\u09c7\u0995 \u099f\u09be\u0995\u09be\u09b0 \u09ae\u09be\u09b2\u09bf\u0995\u0983-    \u09a4\u09be\u09b0 \u098f\u0995\u09cd\u09b8   \u0998\u09be\u099f\u09be\u0987\u09b2\u09c7\u09b0 \u09ae\u09c7\u09df\u09c7* ", "label": 1}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The meme is not hateful, it is a political cartoon that is not hateful.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/TR (127).jpg", "text": "\u09af\u0996\u09a8 \u09b6\u09c1\u09a8\u09bf \u0986\u099c \u098f\u0995\u09cd\u09b8\u09be\u09ae\u09c7\u09b0 \u0996\u09be\u09a4\u09be  \u09a6\u09c7\u0996\u09be\u09ac\u09c7 ...", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The image is a meme that is not hateful, it is a picture of a woman with a caption that is not hateful.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/CM (266).jpg", "text": "\u0986\u09ae\u09cd\u09ae\u09c1\u0983  \u0995\u09bf\u09b0\u09c7 \u0995\u09cb\u09df\u09be\u09b0\u09c7\u09a8\u09cd\u099f\u09be\u0987\u09a8 \u09a6\u09c7\u0996\u09c7 \u0995\u09bf \u09b8\u09be\u09b0\u09be\u09a6\u09bf\u09a8 \u09b6\u09c1\u09df\u09c7 \u09a5\u09be\u0995\u09ac\u09bf \u09a8\u09be\u0995\u09bf \u0989\u09a0\u09c7 \u0985\u09a8\u09cd\u09af \u0995\u09bf\u099b\u09c1 \u0995\u09b0    \u0986\u09ae\u09bf\u0983  I can do this all day ", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The meme is a picture of Captain America with the caption "I can do it on my own." The meme is not hateful, but it is not hateful either.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/Memeholics (40).jpg", "text": "Pulsar Double Dick     \u09ac\u09be\u09ac\u09be, \u0986\u09ae\u09bf \u09b0\u09be\u099c\u09bf ... ", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The meme is not hateful, it is just a funny picture of a woman on a motorcycle with a man in the background.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/chintashil (260).jpg", "text": "*\u09b6\u09c0\u09a4\u09c7\u09b0 Season \u098f \u09b9\u09c1\u09a1\u09bf \u09ac\u09cd\u09af\u09ac\u09b8\u09be \u09b6\u09c1\u09b0\u09c1 \u0995\u09b0\u09be\u09b0 \u09aa\u09b0*  And that's when the big bucks start rolling in      ", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: A man in a yellow shirt is holding a piece of food, and the caption reads "Season 1, Episode 1 and that's when the big boss starts rolling in." The meme is not hateful, but it is a humorous commentary on the show.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/tangaila (344).jpg", "text": "\u09ac\u09a8\u09cd\u09a7\u09c1\u09b0 \u099c\u09a8\u09cd\u09ae\u09a6\u09bf\u09a8\u09c7 \u09af\u0996\u09a8 \u09a1\u09bf\u09b8\u09bf\u09b2\u09c7\u0995\u09c7 , \u098f\u09b8\u09aa\u09bf \u09aa\u09be\u09b0\u09cd\u0995\u09c7 \u0997\u09be\u09b0\u09cd\u09b2\u09b8\u09c7\u09b0 \u0998\u09be\u099f\u09aa\u09be\u09dc\u09c7 \u09ac\u09a8\u09cd\u09a7\u09c1\u09b0 \u09ae\u09be\u09a5\u09be\u09df \u09a1\u09bf\u09ae \u09ab\u09be\u099f\u09be\u0987   \u0986\u09b6\u09c7\u09aa\u09be\u09b6\u09c7\u09b0 \u09b2\u09cb\u0995\u099c\u09a8 -    \u09ac\u09be\u09b9 \u0995\u09c0  smart ! ", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The image is a meme that is not hateful, it is a funny picture of a man with a caption that says "Smart" in a foreign language.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/chintashil (679).jpg", "text": "Boys who are good at    Biology", "label": 1}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The meme is not hateful, it is just a funny picture of a man with a caption that says 'boys who are good at biology'.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/KAM (30).png", "text": "\u098f\u0987 \u09e7 \u09b9\u09be\u09b2\u09bf \u09ac\u09dc \u0987\u09b2\u09bf\u09b6\u09c7\u09b0 \u09a6\u09be\u09ae \u0995\u09a4? \u09e8\u09ea\u09e6\u09e6\u09e6 \u099f\u09be\u0995\u09be \u09ab\u0987\u09a8\u09cd\u09a8\u09bf\u09b0 \u0998\u09b0\u09c7\u09b0 \u09ab\u0987\u09a8\u09cd\u09a8\u09bf \u09a4\u09c1\u0987 \u09ae\u09be\u099b \u09ac\u09c7\u099a\u09a4\u09c7 \u0986\u0987\u099b\u09b8 \u09a8\u09be \u099c\u09c1\u09df\u09c7\u09b2\u09be\u09b0\u09bf?", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The image is a meme that is not hateful, but it is a joke that is meant to be funny.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/TR (220).jpg", "text": "\u0996\u09be\u099f\u09bf \u09ab\u09b0\u09bf\u09a6\u09aa\u09c1\u09c1\u0987\u09b0\u200d\u09cd\u09af\u09be      \u09ab\u09b0\u09bf\u09a6\u09aa\u09c1\u09b0\u09c7\u09b0 \u09b9\u09c7\u099f\u09be\u09b0  ", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The image is a meme that is not hateful, it is just a funny image of two cricket players lighting a candle on the field.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/tangaila (68).jpg", "text": "Guy who made the joke    Guy who said it louder in front of the whole class ", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: A man is sitting in front of a microphone, and the caption reads 'guy who made the joke'. The meme is not hateful, but it is not hateful either.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/Bangla Thug Life (305).jpg", "text": "\u09ac\u09bf\u09df\u09c7\u09b0 \u09aa\u09b0 \u09af\u0996\u09a8 \u09ac\u09be\u09b8\u09b0 \u09b0\u09be\u09a4 \u09b8\u09ae\u09cd\u09aa\u09b0\u09cd\u0995\u09c7 \u099c\u09cd\u099e\u09be\u09a8 \u09a6\u09bf\u09a4\u09c7 \u0986\u09b8\u09c7 \u0986\u09a4\u09cd\u09ae\u09c0\u09df\u09b0\u09be    \u0986\u09ae\u09bf\u0983 \u0986\u09b0\u09c7 \u0995\u09be\u0995\u09c7 \u0996\u09c7\u09b2\u09be \u09b6\u09bf\u0996\u09be\u09a8 ?", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The image is a meme that is not hateful, it is a political speech by a man in India.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/bamboo-vaiya (99).jpg", "text": "Awami league   Haji selim    Manik bhai ", "label": 1}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The meme is a comparison between a hateful and not-hateful meme. The meme is not hateful, but it is still a meme.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/TR (24).jpg", "text": " \u0986\u09ae\u09bf \u0993\u0995\u09c7 \u0986\u09ae\u09be\u09b0 \u09ad\u09be\u09b2\u09cb\u09ac\u09be\u09b8\u09be \u09a6\u09bf\u09df\u09c7 \u09ac\u09a6\u09b2\u09c7 \u09ab\u09c7\u09b2\u09ac ", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The meme is a picture of a man and woman sitting at a table, with the man holding a drink and the woman smiling. The meme is not hateful, but it is not hateful either.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/chintashil (166).jpg", "text": "\u099a\u09be    \u099a\u09be\u09a8\u0995\u09bf     \u09a1\u09a8    \u09a1\u09a8\u0995\u09bf     \u0996\u09be\u09a8     *", "label": 1}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The image is a collage of four different people, including a donkey, a man, a woman, and a coffee cup. The caption reads "Hateful if it explicitly intends to denigrate, vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status."
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/tangaila (269).jpg", "text": "\u098f\u0995\u09cd\u09b8\u09be\u09ae \u09b9\u09b2\u09c7 \u09ab\u09be\u09b0\u09cd\u09b8\u09cd\u099f\u09ac\u09df    \u0986\u09ae\u09bf* ", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The image is a meme that is not hateful, it is a sports meme that is not intended to denigrate, vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/ovodro_img (1190).jpg", "text": "\u0986\u09ae\u09be\u09b0 \u09aa\u09cb\u09b8\u09cd\u099f\u09c7 \u09af\u0996\u09a8 \u0995\u09c7\u0989 Binod \u0995\u09ae\u09c7\u09a8\u09cd\u099f \u0995\u09b0\u09c7    \u09b2\u09c7 \u0986\u09ae\u09bf -    \u098f\u0987 \u09ac\u09c7\u09b6\u09bf  Binod \u099a\u09c1\u09a6\u09bf\u0993 \u09a8\u09be\u09a4\u09cb , \u09ac\u09bf\u09b0\u0995\u09cd\u09a4 \u09b2\u09be\u0997\u09c7  ", "label": 1}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The meme is a picture of a man and woman in a car, with the caption "Binod" in the bottom right corner. The caption is in a foreign language, which is likely to be Bengali.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/TR (418).jpg", "text": "\u09a7\u09b2\u09be\u09b0 \u09ae\u09cb\u09dc\u09c7 \u09ac\u09be\u09a8\u09cd\u09a7\u09ac\u09c0 \u09af\u0996\u09a8 \u0986\u09ae\u09be\u0995\u09c7 \u099c\u09dc\u09bf\u09df\u09c7 \u09a7\u09b0\u09c7    \u09ac\u09be\u09a8\u09cd\u09a7\u09ac\u09c0\u0983-   \u0995\u09bf\u09b0\u09c7 \u09a4\u09cb\u09b0 \u09aa\u09be \u09a4\u09bf\u09a8\u099f\u09be \u09a8\u09be\u0995\u09bf ? ", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The image is a meme that is not hateful, but it is a meme that is hateful. The meme is a picture of two people hugging, and the caption is in a foreign language.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/ovodro_img (829).jpg", "text": "\u0986\u09b0 \u09b8\u09c7\u0987 \u09a6\u09bf\u09a8 \u09ac\u09c7\u09b6\u09c0 \u09a6\u09c2\u09b0\u09c7 \u09a8\u09c7\u0987, \u09af\u0996\u09a8 \u09a0\u09be\u09a8\u09cd\u09a1\u09be \u099c\u09cd\u09ac\u09b2\u09c7 \u09b8\u09cd\u09a8\u09be\u09a8 \u0995\u09b0\u09be\u09b0 \u09b8\u09ae\u09df \u098f\u09b0\u09ae \u0985\u09ac\u09b8\u09cd\u09a5\u09be \u09b9\u09ac\u09c7 ", "label": 1}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The meme is not hateful, it is just a funny picture of three women making funny faces.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/bamboo-vaiya (33).jpg", "text": "THIS DOESN'T CONCERN YOU     JUST KEEP SCROLLING", "label": 1}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The meme is not hateful, it is just a funny cat picture with a caption that is meant to be humorous.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/ovodro_img (1037).jpg", "text": "According to Govt.  \u09b0\u09c7\u09b6\u09a8 \u09a6\u09c7\u0993\u09df\u09be\u09b0 \u09aa\u09b0\u09bf\u09ae\u09be\u09a8 \u09ac\u09c3\u09a6\u09cd\u09a7\u09bf \u0995\u09b0\u09be     \u09b2\u0995\u09a1\u09be\u0989\u09a8\u09c7\u09b0 \u09a6\u09bf\u09a8 \u09ac\u09be\u09dc\u09bf\u09df\u09c7 \u09a6\u09c7\u0993\u09df\u09be   Perfectly balanced    .. As all things should be  ", "label": 1}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The meme is a comic strip that is not hateful, but it is a comic strip that is hateful. The meme is a comic strip that is not hateful, but it is a comic strip that is hateful.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/Halal Memes (10).jpg", "text": "\u09af\u09cc\u09a4\u09c1\u0995 \u09a8\u09c7\u09df\u09be \u09a8\u09bf\u09b7\u09c7\u09a7' \u09ac\u09b2\u09a4\u09c7 \u09a5\u09be\u0995\u09be \u09b9\u09c7\u09a1\u09b8\u09cd\u09af\u09be\u09b0\u0983    \u09af\u09cc\u09a4\u09c1\u0995\u09c7 \u09aa\u09be\u0993\u09df\u09be \u09ae\u09cb\u099f\u09b0\u09b8\u09be\u0987\u0995\u09c7\u09b2 \u09a8\u09bf\u09df\u09c7 \u09b8\u09cd\u0995\u09c1\u09b2\u09c7 \u0986\u09b8\u09be \u0995\u09cd\u09b2\u09be\u09b8\u099f\u09bf\u099a\u09be\u09b0\u0983  ", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The meme is a picture of two women, one of whom is holding a cat, and the caption is in a foreign language. The caption is a meme that is not hateful, but it is not hateful either.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/bangla-gag (28).jpg", "text": "\u0997\u09be\u09a8 \u09ac\u09be\u0982\u09b2\u09be \u099a\u09cd\u09af\u09be\u09a8\u09c7\u09b2 \u0986\u09df\u09cb\u099c\u09bf\u09a4  \u09b8\u09c7\u09b9\u09c7\u09b0\u09bf\u09b0 \u09b0\u09be\u09a4\u09c7 \u09b2\u09be\u0987\u09ad \u0997\u09be\u09a8\u09c7\u09b0 \u0985\u09a8\u09c1\u09b7\u09cd\u09a0\u09be\u09a8 !   THIS IS WHY I BOMB PEOPLE ", "label": 1}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The image is a meme that is not hateful, it is a joke. The meme is a picture of Osama Bin Laden and a group of musicians, with the caption "This is why I bombed people."
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/bangla-memes (107).jpg", "text": "Domino's pizza right now :", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: A man is lying on a bed of money with the words "domino's pizza right now" on the screen. The man is wearing a blue jacket and is surrounded by money.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/Halal Memes (184).jpg", "text": "\u09aa\u09b0\u09c0\u0995\u09cd\u09b7\u09be\u09df \u09ab\u09c7\u09b2 \u0995\u09b0\u09be\u09b0 \u09aa\u09b0     Girls*     Boys*", "label": 1}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The meme is a picture of a woman with a green vehicle in the background. The meme is not hateful, but it is not hateful either.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/Memeholics (255).jpg", "text": "\u0986\u0997\u09c7 \u09af\u0996\u09a8 \u09ac\u09be\u0982\u09b2\u09be\u09a6\u09c7\u09b6 \u0995\u09cd\u09b0\u09bf\u0995\u09c7\u099f \u09ae\u09cd\u09af\u09be\u099a \u099c\u09bf\u09a4\u09a4\u09cb     \u098f\u0996\u09a8 \u09af\u0996\u09a8 \u09ac\u09be\u0982\u09b2\u09be\u09a6\u09c7\u09b6 \u0995\u09cd\u09b0\u09bf\u0995\u09c7\u099f \u09ae\u09cd\u09af\u09be\u099a \u099c\u09bf\u09a4\u09c7 ", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The meme is a picture of a man with a green shirt and glasses, and the caption is in a foreign language. The caption is a quote from a movie, and it is not hateful.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/Halal Memes (143).jpg", "text": "Ammu- \u09ac\u0987 \u0996\u09cb\u09b2\u09be \u09b0\u09be\u0996\u09a4\u09c7 \u09a8\u09c7\u0987   \u09b6\u09df\u09a4\u09be\u09a8\u09c7 \u09aa\u09dc\u09c7 \u09ab\u09c7\u09b2\u09ac\u09c7 !  Sir- \u09ac\u09bf\u09a6\u09cd\u09af\u09be \u0985\u09b0\u09cd\u099c\u09a8 \u0995\u09b0\u09be \u09ab\u09b0\u09af    Nice Me -  I Am Inspired By Mom And Teacher... Now Peace   ", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The meme is not hateful, it is just a funny picture of a person sleeping on a pile of books. The meme is not hateful, it is just a funny picture of a person sleeping on a pile of books.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/ovodro_img (527).jpg", "text": "\u0986\u0997\u09c7 \u0986\u09ae\u09bf \u09b0\u09cb\u099c \u09b0\u09cb\u099c \u09b8\u09cb\u09a8\u09be\u0997\u09be\u099b\u09bf \u09af\u09c7\u09a4\u09be\u09ae   \u09ab\u09bf\u09b0 \u09ae\u09cb\u09b8\u09bf\u09a8\u09c7 \u09ac\u09cb\u09b2\u09be \u09ac\u09bf\u09df\u09c7 \u0995\u09b0\u09a4\u09c7 \u0995\u09be\u09b0\u09a8 \u09b0\u09cb\u099c \u09ab\u09cd\u09b0\u09bf\u09a4\u09c7 \u09aa\u09be\u09ac\u09cb !   \u09ac\u09cc \u098f\u09b0 \u0985\u09ad\u09cd\u09af\u09be\u09b8 \u0985\u09a8\u09c1\u09af\u09be\u09df\u09c0 \u09ac\u09cc \u0995\u09be\u0993\u0995\u09c7\u0987 \u09ab\u09cd\u09b0\u09bf\u09a4\u09c7 \u09a6\u09c7\u09df \u09a8\u09be !  \u09a4\u09be\u0987 \u098f\u0996\u09a8 \u09ae\u09be\u09b8\u09bf\u0987 \u09aa\u09cd\u09b0\u09c7\u0997\u09a8\u09cd\u09af\u09be\u09a8\u09cd\u099f ", "label": 1}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The image is a meme that is not hateful, it is a funny and lighthearted joke.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/chintashil (414).jpg", "text": "\u0995\u09cb\u09a5\u09be\u0993 \u0986\u09ae\u09be\u09b0 \u09b9\u09be\u09b0\u09bf\u09df\u09c7 \u09af\u09be\u0993\u09df\u09be\u09b0 \u09a8\u09c7\u0987 \u09ae\u09be\u09a8\u09be    \u09ae\u09a8\u09c7 \u09ae\u09a8\u09c7 ", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The image is a meme that is not hateful, it is a funny and lighthearted moment between two men.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/ovodro_img (957).jpg", "text": "\u0986\u09ae\u09be\u09b0 \u09a7\u09cb\u09a8 \u099f\u09be \u0995\u09c7\u09ae\u09a8 \u099a\u0995\u099a\u0995 \u0995\u09b0\u099b\u09bf\u09b2 \u09a6\u09c7\u0996\u09c7\u099b\u09cb ?  \u0993\u099f\u09be \u099a\u0995\u099a\u0995 \u0995\u09b0\u099b\u09c7 \u0995\u09be\u09b0\u09a3 \u0993\u09a4\u09c7 ' nerolac paint '  \u0995\u09b0\u09be \u0986\u099b\u09c7     \u0986\u09ae\u09be\u09b0 \u09a7\u09cb\u0993\u0993\u0993\u09a8\u09c7 ' nerolac ' .. ???", "label": 1}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The image is a meme that is not hateful, but it is a meme that is not hateful.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/ovodro_img (578).jpg", "text": "\u0995\u09c0\u09b0\u09c7 \u0995\u09be\u0981\u09a6\u099b\u09bf\u09b8 \u0995\u09c7\u09a8 ??   \u09a0\u09be\u0995\u09c1\u09ae\u09be \u099a\u09c7\u099f\u09c7 \u099a\u09c7\u099f\u09c7 \u09b9\u09b0\u09b2\u09bf\u0995\u09cd\u09b8 \u0996\u09c7\u09a4\u09c7 \u09a6\u09c7\u09df\u09a8\u09bf ", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The meme is not hateful, it is just a picture of a man and a woman with a caption that is not hateful.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/ovodro_img (28).jpg", "text": " \u09ae\u09c7\u09df\u099f\u09be \u0995\u09c0 \u09b8\u09c1\u09a8\u09cd\u09a6\u09b0 \u0964 \u099c\u09be\u09b8\u09cd\u099f \u0985\u09b8\u09be\u09a7\u09be\u09b0\u09a3    \u09ae\u09c1\u0996\u09c7 \u09ae\u09df\u09a6\u09be \u09ae\u09be\u0996\u09be\u09b0 \u09aa\u09b0 \u09b8\u09ac \u09ae\u09c7\u09df\u09c7\u0995\u09c7\u0987 \u09b8\u09c1\u09a8\u09cd\u09a6\u09b0 \u09b2\u09be\u0997\u09c7", "label": 1}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The meme is a comic strip with a man driving a car and a woman in the passenger seat. The caption is in a foreign language, possibly Chinese.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/chintashil (615).jpg", "text": "They said its  \"Aesthetic\"    But it's not the correct spelling of \"Autistic\"", "label": 1}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The image is a meme that is not hateful, but it is not hateful either. It is a meme that is not hateful, but it is not hateful either.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/chintashil (381).jpg", "text": "\u09b9\u09c7 \u0986\u09ae\u09be\u09b0 \u09aa\u09cd\u09b0\u09a4\u09bf\u09aa\u09be\u09b2\u0995 , \u0986\u09ae\u09be\u09df \u0995\u09cd\u09b7\u09ae\u09be \u0995\u09b0\u09c7 \u09a6\u09bf\u09a8     \u09b0\u09cb\u09af\u09be\u09b0 \u09a6\u09bf\u09a8\u09c7 \u09ad\u09c1\u09b2\u09c7 Instagram \u098f \u09a2\u09c1\u0995\u09c7\u099b\u09bf ", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The man in the picture is wearing a red shirt and is sitting in front of a laptop computer. The image is a meme that is not hateful, but it is a meme that is not hateful.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/chintashil (232).jpg", "text": "Me after saying \u09ae\u09be\u09ae \u09b8\u09be\u09ae\u09a8\u09c7 \u0986\u09b0\u09c7\u0995\u099f\u09c1 \u099b\u09cb\u099f \u0995\u09b0\u09c7\u09a8 to the \u09a8\u09be\u09aa\u09bf\u09a4      Shouldn't have said that     I should NOT have said that ", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The meme is a picture of a man with a long beard and a caption that says 'me after saying hateful things to the person to the left.' The caption is a joke, as the person to the left is not actually present. The meme is a funny way to express the idea that the person in the picture is saying something hateful to someone. The meme is a joke, as the person to the left is not actually present.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/ovodro_img (1143).jpg", "text": "2020 \u098f\u09b0 HS \u09b8\u09cd\u099f\u09c1\u09a1\u09c7\u09a8\u09cd\u099f\u09a6\u09c7\u09b0 \u09af\u0996\u09a8 \u09ac\u09b2\u09be \u09b9\u09df \u09a4\u09c1\u0987 \u09a4\u09cb \u0997\u09dc \u09ae\u09be\u09b0\u09cd\u0995\u09b8 \u09aa\u09c7\u09df\u09c7\u099b\u09bf\u09b8   HS candidate :     \u09ae\u09c1\u0996\u09c7\u09b0 \u0989\u09aa\u09b0 \u09b8\u09a4\u09cd\u09af\u09bf \u0995\u09c7\u09a8 \u09ac\u09b2\u09bf\u09b8 \u09ac\u09be\u0981\u09dc\u09be ? ", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The meme is a picture of a group of children, with one of them being a candidate for the upcoming election. The caption is in Bengali, which is a language spoken in Bangladesh. The meme is not hateful, but it is a political statement.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/Bangla Thug Life (360).jpg", "text": "\u09b0\u09c1\u09ae\u09a1\u09c7\u099f \u09a5\u09c7\u0995\u09c7 \u09aa\u09cd\u09b0\u09a5\u09ae\u09ac\u09be\u09b0 Anal \u0995\u09b0\u09c7 \u09ab\u09bf\u09b0\u09c7 \u0986\u09b8\u09be \u09ac\u09bf\u09a6\u09cd\u09af\u09ae\u09be\u09a8  \u09a8\u09bf\u09ac\u09cd\u09ac\u09bf\u0983 ", "label": 1}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The image is a cartoon of a dog looking at himself in a mirror, with the caption "Hateful" in Bengali.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/bangla-gag (112).jpg", "text": "\u0985\u0995\u09be\u09b2\u09c7 \u09aa\u0995\u09c7\u099b\u09c7 \u09af\u09c7 = \u0985\u0995\u09be\u09b2\u09aa\u0995\u09cd\u0995  ", "label": 1}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The image is a meme that is not hateful, it is not intended to denigrate, vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/bangla-troll (28).jpg", "text": "BANGLADESH ! \u09af\u09c7\u0996\u09be\u09a8\u09c7 \u09aa\u09c1\u09b2\u09bf\u09b6\u09c7\u09b0 \u0986\u0997\u09c7 \u09b8\u09be\u0982\u09ac\u09be\u09a6\u09bf\u0995\u09b0\u09be \u0996\u09ac\u09b0 \u09aa\u09c7\u09df\u09c7 \u099a\u09b2\u09c7 \u0986\u09b8\u09c7 !", "label": 1}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The image is a meme that is not hateful, it is a political statement that is not hateful.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/ovodro_img (25).jpg", "text": " \u0995\u09cb\u09a5\u09be\u09df \u09af\u09be\u099a\u09cd\u099b\u09cb ?    \u09b9\u09b8\u09aa\u09bf\u099f\u09be\u09b2\u09c7 \u09aa\u09c7\u09b8\u09c7\u09a8\u09cd\u099f \u09a6\u09c7\u0996\u09a4\u09c7    \u09aa\u09cd\u09b2\u09bf\u099c \u09b9\u09b8\u09aa\u09bf\u099f\u09be\u09b2\u09c7 \u09af\u09c7\u09df\u09c7 \u099d\u0997\u09dc\u09be \u0995\u09b0\u09a8\u09be   sorry,  \u099d\u0997\u09dc\u09be \u0995\u09b0\u09be\u099f\u09be \u098f\u0996\u09a8 \u0985\u09ad\u09cd\u09af\u09be\u09b8 ", "label": 1}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The image is a meme that is not hateful, but it is a meme that is not hateful.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/KAM (103).jpg", "text": "\u0995\u09bf\u09b0\u09c7 \u099c\u09b2\u09bf\u09b2 \u0995\u09be\u09b2 \u09a8\u09be\u0995\u09bf \u09aa\u09be\u09ac\u09b2\u09bf\u0995 \u09a4\u09cb\u0995\u09c7 \u0997\u09a8 \u09a7\u09cb\u09b2\u09be\u0987 \u09a6\u09bf\u099b\u09c7 \u09b9\u09c1\u09ae...\u0995\u09bf \u0985\u09aa\u09b0\u09be\u09a7 \u0995\u09b0\u09b2\u09bf \u0986\u09ac\u09be\u09b0 \u0986\u09b0 \u09ac\u09b2\u09bf\u09b8\u09a8\u09be \u098f\u0995 \u09ae\u09b9\u09bf\u09b2\u09be\u09b0 \u09aa\u09be\u09df\u09c7\u09b0 \u09a8\u09bf\u099b\u09c7 \u0986\u09ae\u09be\u09b0 \u098f\u0995\u099f\u09be \u09ab\u099f\u09cb \u09aa\u09b0\u099b\u09bf\u09b2 \u09a4\u09cb...\u09ae\u09be\u0987\u09b0 \u09a6\u09bf\u09b2 \u0995\u09c7\u09a8? \u0986\u09ae\u09bf \u09b6\u09c1\u09a7\u09c1 \u0995\u0987\u099b\u09bf \u0986\u09ab\u09be \u09b6\u09be\u09dc\u09c0\u099f\u09be \u0989\u09aa\u09b0\u09c7 \u09a4\u09c1\u09b2\u09c7\u09a8 \u09ab\u099f\u09cb \u09a4\u09cb\u09b2\u09ac", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The meme is not hateful, it is just a funny picture of two men with a caption that is not meant to be offensive.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/ovodro_img (1180).jpg", "text": "\u09a4\u09cb\u09b0 \u0993\u099f\u09be \u0995\u09bf \u09aa\u09b6\u09cd\u099a\u09bf\u09ae\u09ac\u0999\u09cd\u0997\u09c7\u09b0 \u09b2\u0995\u09a1\u09be\u0989\u09a8 ?      \u0995\u09c7\u09a8 ?     \u0995\u0996\u09a8 \u09a5\u09c7\u0995\u09c7 \u09b6\u09c1\u09b0\u09c1 \u0995\u09b0\u09c7\u099b\u09bf\u09b8 , \u09b6\u09c7\u09b7\u0987 \u09b9\u099a\u09cd\u099b\u09c7 \u09a8\u09be ! ", "label": 1}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The meme is a collage of four different images, each with a different caption. The captions are in a foreign language, but the images themselves are not hateful or not-hateful.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/tangaila (9).jpg", "text": "BIOLOGY THEORY IS IMPORTANT BUT, BIOLOGY PRACTICAL IS LIFE   ME    MEDICAL \u098f\u09b0 \u09ad\u09be\u0987\u09df\u09be   BIOLOGY BOOK   ", "label": 1}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The meme is a joke, and it is not meant to be taken seriously. It is a meme that is meant to be funny and lighthearted.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/bamboo-vaiya (209).jpg", "text": "*\u09a4\u09be\u09b9\u09b8\u09bf\u09a8\u0983 \u09ae\u09be\u09a8\u09c1\u09b7\u09c7\u09b0 \u09a6\u09c1\u09a7 \u099f\u09bf\u09aa\u09c7  \u09ad\u09a8\u09cd\u09a1\u09be\u09ae\u09bf \u0995\u09b0\u09be\u0987 \u09a6\u09c7\u0993\u09df\u09be\u09a8\u09ad\u09be\u0997\u09c0\u09b0 \u0995\u09be\u099c    \u09a6\u09c7\u0993\u09df\u09be\u09a8\u09ad\u09be\u0997\u09c0*   * \u09a4\u09be\u09b0 \u09ad\u0995\u09cd\u09a4", "label": 1}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The image is a meme that is not hateful, it is not intended to denigrate, vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/chintashil (926).jpg", "text": "\u0997\u09be\u09b0\u09cb\u09dc\u09be     \u09aa\u09be\u09b6\u09be\u09dc\u09be ", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The meme is a comparison between two men, one with a beard and the other without, with the caption "Hateful if it intends to denigrate, vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status." The meme is not hateful, it is just a comparison between two men.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/Memeholics (44).jpg", "text": "Goru's after realising there will be less people in gorur-hut due to coronavirus hence less people will be slapping their pacha:    \u0996\u09c1\u09ac \u0989\u09aa\u0995\u09be\u09b0 \u09b9\u0987\u09b2\u09cb ", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The meme is not hateful, it is just a funny picture of a cow with a man sitting on it. The caption is in Bengali, which is a language spoken in India.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/nurani-memes (218).jpg", "text": "Geenie : What's your wish ?    Assface : I wanna commit crime without being punished     Geenie : *makes him a member of Chatroleague*   Assface : ", "label": 1}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The meme is a hateful one, as it is mocking a person's gender and race.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/ovodro_img (498).jpg", "text": "Jhonny Depp \u09a8\u09be Tom Cruise   \u09a6\u09c7\u09ac   \u09ac\u09c7\u09b0\u09ac\u09be\u09b0 \u09b0\u09be\u09b8\u09cd\u09a4\u09be \u0993\u0987 \u09a6\u09bf\u0995\u09c7    ", "label": 1}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: A man and a woman are shown in a comic strip, with the man saying something to the woman. The comic strip is a meme, and the caption is in French.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/ovodro_img (1110).jpg", "text": "\u09b2\u09cd\u09af\u09be\u09ac\u09c7 \u099b\u09be\u09a4\u09cd\u09b0\u09c0\u09b0 \u09b8\u0999\u09cd\u0997\u09c7 \u09b8\u09cd\u09af\u09be\u09b0\u09c7\u09b0 \u09ac\u09be\u09df\u09cb\u09b2\u099c\u09bf \u09aa\u09cd\u09b0\u09be\u0995\u09cd\u099f\u09bf\u0995\u09cd\u09af\u09be\u09b2 \u0995\u09cd\u09b2\u09be\u09b6\u09c7\u09b0 \u098f\u09b0 \u098f\u0995\u099f\u09bf \u09a6\u09c1\u09b0\u09cd\u09b2\u09ad \u099a\u09bf\u09a4\u09cd\u09b0 ", "label": 1}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The meme is not hateful, it is just a sexual image with a caption that is not hateful.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/ovodro_img (1243).jpg", "text": "  \u09b8\u09cd\u099f\u09c1\u09a1\u09c7\u09a8\u09cd\u099f\u09b8 :    \u098f\u09a4\u09cb \u09a6\u09bf\u09a8 \u09af\u0996\u09a8 \u09aa\u09b0\u09c0\u0995\u09cd\u09b7\u09be \u09b9\u09df\u09a8\u09bf \u098f\u09a4\u09cb \u09ae\u09be\u09b8 \u09aa\u09b0\u09c7 \u09aa\u09b0\u09c0\u0995\u09cd\u09b7\u09be \u09b9\u09ac\u09c7 \u09a8\u09be \u0964   UGC :-    \u09a4\u09c1\u0987 \u09ac\u09c7\u09b6\u09bf \u099c\u09be\u09a8\u09bf\u09b8 ? ", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The meme is a picture of a man with a beard, and the text is in Bengali. The text is a quote from a Bengali movie, and it is not hateful.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/chintashil (849).jpg", "text": "\u09ae\u09a8\u099f\u09be \u0985\u09a4\u09bf \u09ac\u09c7\u099c\u09be\u09b0   \u0985\u09a4\u09bf \u09b8\u09cc\u09a8\u09cd\u09a6\u09b0\u09cd\u09af ", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The image is a collage of different pictures, including a man with a mustache and a shirt. The image is not hateful, but it is not hateful either.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/Bangla Thug Life (49).jpg", "text": "\"\u09a4\u09cb\u09b0\u09be \u0995\u09bf \u0986\u09ae\u09be\u09df \u0996\u09c1\u09ac \u09ae\u09bf\u09b8 \u0995\u09b0\u09bf\u09b8 ?\"", "label": 1}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The meme is not hateful, it is not intended to denigrate, vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/Halal Memes (345).jpg", "text": "\u09b0\u09c7\u09b8\u09cd\u099f\u09c1\u09b0\u09c7\u09a8\u09cd\u099f\u09c7 \u098f\u0995\u09a6\u09bf\u09a8 \u0996\u09c7\u09df\u09c7 \u09ac\u09be\u09b0\u09ac\u09be\u09b0 \u09ab\u09c7\u09b8\u09ac\u09c1\u0995\u09c7 \u099b\u09ac\u09bf \u0986\u09aa\u09b2\u09cb\u09a1 \u0995\u09b0\u09be\u09b0 \u09aa\u09b0\u09c7\u0983    \u0995\u09cb\u099f\u09bf\u09aa\u09a4\u09bf\u09b0 \u09aa\u09cb\u09b2\u09be \u0986\u09ae\u09bf \u0995\u09cb\u099f\u09bf\u09aa\u09a4\u09bf\u09b0 \u09aa\u09cb\u09b2\u09be  ", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The meme is a picture of a man wearing a crown and holding a microphone. The caption is in a foreign language, but the image is not hateful.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/ovodro_img (986).jpg", "text": "\u09af\u0996\u09a8 \u09a4\u09c1\u09ae\u09bf \u09b8\u09cd\u09ae\u09be\u09a8 \u0995\u09b0\u09a4\u09c7 \u09af\u09be\u0993 \u0986\u09b0 \u09a6\u09c7\u0996\u09cb \u09a4\u09cb\u09ae\u09be\u09b0 \u09b6\u09b6\u09c1\u09dc \u09ae\u09cb\u099f\u09be \u09b2\u09ae\u09cd\u09ac\u09be \u09ae\u09be\u09b2\u099f\u09be \u09a8\u09bf\u09df\u09c7 \u09a4\u09cb\u09ae\u09be\u09b0 \u09a6\u09bf\u0995\u09c7 \u098f\u0997\u09bf\u09df\u09c7 \u0986\u09b8\u099b\u09c7 ", "label": 1}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The image is a meme that is not hateful, it is a woman in a bathtub with a red bowl in front of her. The meme is not hateful, it is just a funny image.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/Bangla Thug Life (312).jpg", "text": "\u0986\u09ae\u09bf \u09ae\u09a7\u09cd\u09af\u09b0\u09be\u09a4\u09c7 \u09ab\u09be\u09b0\u09cd\u09ae\u09c7\u09b8\u09c0\u09a4\u09c7 \u09a8\u09be\u09aa\u09be \u0995\u09bf\u09a8\u09a4\u09c7 \u09af\u09be\u0993\u09df\u09be\u09b0 \u09aa\u09b0   \u09a6\u09cb\u0995\u09be\u09a8\u09a6\u09be\u09b0\u0983 \u09a4\u09cb\u09b0 \u0995\u09bf \u09ac\u09c7\u09b2\u09c1\u09a8 \u09b2\u09be\u0997\u09ac\u09cb ?", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The meme is not hateful, it is just a funny picture of two men with a caption that is in a foreign language.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/tangaila (300).jpg", "text": "\u0986\u09ae\u09be\u09b0 \u09b2\u09c1\u099a\u09c1 \u09ac\u09a8\u09cd\u09a7\u09c1 \u09ac\u09c7\u09ac\u09bf\u09b8\u09cd\u099f\u09cd\u09af\u09be\u09a8\u09cd\u09a1\u09c7\u09b0 \u09a6\u09bf\u0995\u09c7 \u09b0\u0993\u09a8\u09be \u09a6\u09c7\u0993\u09df\u09be\u09b0 \u0986\u0997\u09c7 -    \u0986\u099c\u0995\u09c7 \u09b0\u09c7\u099f \u0995\u09a4 \u0995\u0987\u09b0\u09be ? ", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The image is a meme that is not hateful, it is a car driving through a busy street with a man in the driver's seat. The meme is not hateful, it is just a funny image of a man driving a car.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/bangla-gag (45).jpg", "text": "ICC      BCCI     ICC HA TYAHAAR     ISMEIN HAI DILON KA PYAAR   YEH HAI   ", "label": 1}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The image is a meme that is not hateful, it is a meme that is not hateful.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/Memeholics (53).jpg", "text": "Girls :    \u09a8\u09be, \u0986\u0999\u09c1\u09b2 \u09a6\u09bf\u09a4\u09c7 \u09aa\u09be\u09b0\u09ac\u09cb \u09a8\u09be       Also them : ", "label": 1}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The meme is a picture of a woman holding a lit candle, with the caption "Girls, jhij fih ghes also them." The caption is in a foreign language, but the meaning is clear.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/CM (605).jpg", "text": "\u09b8\u09c7\u09b2\u09c1\u09a8\u09c7\u09b0 \u09a8\u09be\u09aa\u09bf\u09a4\u0983 \u09ae\u09be\u09ae\u09be \u099a\u09c1\u09b2\u09a4\u09cb \u0995\u09c7\u09ae\u09a8 \u099c\u09be\u09a8\u09bf \u09b2\u09be\u0997\u09a4\u09c7\u099b\u09c7 \u099a\u09c1\u09b2\u099f\u09be \u098f\u0995\u099f\u09c1 \u09b6\u09be\u0987\u09a8\u09bf\u0982 \u0995\u0987\u09b0\u09be \u09a6\u09c7\u0987 ?    \u0986\u09ae\u09bf\u0983    I'm gonna stop you right there  ", "label": 1}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The meme is a picture of a man with a hat on, and the caption is in a foreign language. The caption is asking if the man is going to stop where he is right now. The meme is not hateful, but it is not hateful either.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/Bangla Thug Life (37).jpg", "text": "\u09af\u0996\u09a8 \u0986\u09ae\u09bf \u0995\u09be\u09b0\u09cb \u0995\u09b2 \u09b0\u09bf\u09b8\u09bf\u09ad \u0995\u09b0\u09c7 \u0985\u09a8\u09cd\u09af \u09b0\u09c1\u09ae\u09c7\u09b0 \u09a6\u09bf\u0995\u09c7 \u09af\u09be\u0987,  \u0986\u09ae\u09cd\u09ae\u09c1\u0983", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The meme is a picture of a cat with a caption that is not hateful.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/TR (340).jpg", "text": "\u09a2\u09be\u0995\u09be \u09af\u09be\u0993\u09df\u09be\u09b0 \u099c\u09a8\u09cd\u09af \u09b8\u09be\u0989\u09a5 \u09b2\u09be\u0987\u09a8 \u09aa\u09b0\u09bf\u09ac\u09b9\u09a8\u09c7 \u0993\u09a0\u09be\u09b0 \u09aa\u09b0\u0983-     \u09b2\u09c7\u0995\u09cd\u09b8\u09be\u09b8 \u09ac\u09bf\u09b8\u09cd\u0995\u09c1\u099f \u09aa\u09be\u09a8\u09bf     \u0986\u09ae\u09bf \u099a\u09b2\u09c7 \u098f\u09b8\u09c7\u099b\u09bf ", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The meme is not hateful, it is just a funny picture of two men talking.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/KAM (164).png", "text": "NEW YEAR CELEBRATION \u09b8\u09ac\u09be\u0987 \u0986\u09ae\u09bf", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The image is a comic strip that is both hateful and not-hateful.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/chintashil (222).jpg", "text": "when girls see a  \u0986\u099a\u09be\u09b0 \u0993\u09df\u09be\u09b2\u09be   when girls see a  \u09ab\u09c1\u09b8\u0995\u09be \u0993\u09df\u09be\u09b2\u09be ", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The meme is a picture of two women with the caption 'when girls see a girl' and 'when girls see a boy'. The meme is not hateful, but it is a play on words.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/Halal Memes (201).jpg", "text": "\u09aa\u0995\u09c7\u099f \u09a5\u09c7\u0995\u09c7 \u099c\u09c0\u09ac\u09a8\u09c7 \u09e7\u09e6 \u099f\u09be\u0995\u09be \u09ac\u09c7\u09b0 \u09a8\u09be \u0995\u09b0\u09be \u09ac\u09a8\u09cd\u09a7\u09c1\u099f\u09bf \u09af\u0996\u09a8 \u0997\u09ab \u09a8\u09bf\u09df\u09c7 \u09b0\u09c7\u09b8\u09cd\u099f\u09c1\u09b0\u09c7\u09a8\u09cd\u099f\u09c7 \u09af\u09be\u09df !     \u09b2\u09c7 \u0986\u09ae\u09bf\u0983    \u09a4\u09c1\u0987 \u09a4\u09be\u09b9\u09b2\u09c7 \u09ab\u0995\u09bf\u09b0 \u09a8\u09be ?", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The meme is a picture of a man with a caption that is written in a foreign language. The caption is not hateful, but it is not hateful either.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/Memeholics (156).jpg", "text": "\u0995\u09c7 \u098f\u0987 \u09b6\u09a4\u09be\u09ac\u09cd\u09a6\u09c0  \u09b0\u09be\u09df ?     \u098f\u0987\u099a\u098f\u09b8\u09b8\u09bf\u09a4\u09c7 \u0985\u099f\u09cb\u09aa\u09cd\u09b0\u09ae\u09cb\u09b6\u09a8\u09c7\u09b0 \u09ac\u09bf\u09b0\u09c1\u09a6\u09cd\u09a7\u09c7 \u09b6\u09bf\u0995\u09cd\u09b7\u09be \u09ae\u09a8\u09cd\u09a4\u09cd\u09b0\u09a3\u09be\u09b2\u09df\u0995\u09c7 \u0986\u0987\u09a8\u09bf \u09a8\u09cb\u099f\u09bf\u09b6   \u0964\u0964   #HSC Legal notice     \u0986\u09aa\u09a8\u09be\u09b0 \u09b8\u09be\u09a5\u09c7 \u09aa\u09c7\u09b0\u09be\u0987\u09ad\u09c7\u099f \u0995\u09a5\u09be \u0986\u099b\u09c7   ", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The image is a meme that is not hateful, it is a political cartoon that is not intended to harm or mock any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/Halal Memes (9).jpg", "text": "*\u0986\u09ae\u09cd\u09ae\u09c1  \u098f\u0995\u09cd\u09b8\u099f\u09cd\u09b0\u09be \u0995\u09cd\u09b2\u09be\u09b8 \u09a8\u09be\u0995\u09bf \u09aa\u09b9\u09c7\u09b2\u09be \u09ab\u09be\u09b2\u09cd\u0997\u09c1\u09a8\u09c7\u09b0 \u09ae\u09c7\u09b2\u09be ?  \u0986\u09ae\u09bf*   \u09ac\u09a8\u09cd\u09a7\u09c1\u09b0 \u09ac\u09be\u09b8\u09be\u09df \u09ae\u09bf\u09b2\u09be\u09a6  ", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The meme is not hateful, it is just a funny joke between two men.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/chintashil (289).jpg", "text": "\u09af\u09a4\u099f\u09be \u0996\u09be\u09b0\u09be\u09aa \u0986\u09aa\u09a8\u09be\u09b0\u09c7 \u09ad\u09be\u09ac\u099b\u09bf\u09b2\u09be\u09ae , \u09a4\u09a4\u099f\u09be \u0996\u09be\u09b0\u09be\u09aa \u0986\u09aa\u09a8\u09c7 \u09a8\u09be    ", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The meme is not hateful, it is just a funny picture of two men with a caption that is not meant to be taken seriously.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/Bangla Thug Life (413).jpg", "text": "If \"\u09ac\u09be\u09ac\u09c1 \u09ad\u09bf\u09a4\u09b0\u09c7 \u09a8\u09be \u09ae\u09c1\u0996\u09c7 \u09ab\u09c7\u09b2\u09cb \" had a face :", "label": 1}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The meme is a picture of a woman with glasses and a caption that says "if it explicitly intends to denigrate, vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status." The meme is not hateful, but it is a cautionary message about the use of language and the potential consequences of using it in a harmful way.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/TR (156).jpg", "text": "\u09aa\u09b0\u09c0\u0995\u09cd\u09b7\u09be\u09b0 \u09b9\u09b2\u09c7 \u09af\u0996\u09a8 \u0986\u09aa\u09a8\u09bf \u09b8\u09ac\u09be\u09b0 \u0986\u0997\u09c7 \u098f\u0995\u09cd\u09b8\u099f\u09cd\u09b0\u09be \u09aa\u09c7\u0987\u099c \u09a8\u09c7\u09a8  ", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The image is a meme that is not hateful, it is a political advertisement with a man pointing at a bus.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/CM (23).jpg", "text": "\u09af\u0996\u09a8  \u09a4\u09c1\u09ae\u09bf \u09ac\u09c1\u099c\u09a4\u09c7 \u09aa\u09be\u09b0\u09cb \u09af\u09c7 \u0986\u09b0 \u0995\u09df\u09c7\u0995\u09a6\u09bf\u09a8 \u09aa\u09b0\u09c7 \u09a4\u09cb\u09ae\u09be\u09b0 SSC \u09b0\u09c7\u099c\u09be\u09b2\u09cd\u099f \u09a6\u09bf\u09ac\u09c7 ", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The meme is not hateful, it is just a picture of a man in a park with a caption that is in a foreign language.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/ovodro_img (823).jpg", "text": "Neutral    1st Gear   Top Gear", "label": 1}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The meme is a comparison between a hateful and not-hateful meme. The meme is not hateful, but it is still a meme.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/chintashil (614).jpg", "text": "Psychopath    serial killer    \u099c\u09c8\u09ac \u09af\u09cc\u0997 \u09aa\u09be\u09b0\u09be \u09b6\u09bf\u0995\u09cd\u09b7\u09be\u09b0\u09cd\u09a5\u09c0 ", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The meme is not hateful, it is just a funny picture of two kids with a bunny. The caption is in a foreign language, but the image is not hateful.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/KAM (169).png", "text": "\u099b\u09df\u09a6\u09bf\u09a8 \u09a7\u09b0\u09c7 \u0985\u09ac\u09b0\u09cb\u09a7 \u0995\u09b0\u09a4\u09c7\u099b\u09c7\u09a8 \u0986\u09b0 \u0995\u09a4\u09cb??\u098f\u09ac\u09be\u09b0 \u098f\u0995\u099f\u09c1 \u09a5\u09be\u09ae\u09c7\u09a8!!\u0986\u09aa\u09a8\u09bf \u09a4\u09cb \u099b\u09df \u09ac\u099b\u09b0 \u09a7\u09b0\u09c7 \u09b0\u09be\u099c\u09a4\u09cd\u09ac \u0995\u09b0\u09a4\u09c7\u099b\u09c7\u09a8 \u098f\u0987\u09ac\u09be\u09b0 \u0986\u09aa\u09a8\u09c7 \u098f\u0995\u099f\u09c1 \u09a5\u09be\u09ae\u09c7\u09a8!!", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The meme is not hateful, it is not intended to denigrate, vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/bamboo-vaiya (97).jpg", "text": "Iktu modhu dao chete chete khai ", "label": 1}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The image is a meme that is not hateful, but it is a meme that is hateful.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/ovodro_img (158).jpg", "text": "\u0986\u09aa\u09a8\u09bf \u098f\u09a4 \u09a6\u09bf\u09a8 \u09aa\u09b0\u09c7 \u09a8\u09be\u09a8\u09be \u09aa\u09be\u099f\u09c7\u0995\u09be\u09b0 \u098f\u09b0 \u09a8\u09be\u09ae\u09c7 \u09b0\u09c7\u09aa \u0995\u09c7\u09b8 \u09a6\u09bf\u09a4\u09c7 \u0997\u09c7\u09b2\u09c7\u09a8 \u0995\u09c7\u09a8?  \u0986\u09b8\u09b2\u09c7 \u0985\u09a8\u09c7\u0995 \u09a6\u09bf\u09a8 \u09a7\u09b0\u09c7\u0987 \u0995\u09cb\u09a8 \u0996\u09ac\u09b0\u09c7\u09b0 \u099a\u09cd\u09af\u09be\u09a8\u09c7\u09b2 \u09a5\u09c7\u0995\u09c7 \u09ab\u09c1\u099f\u09c7\u099c \u09aa\u09be\u099a\u09cd\u099b\u09bf\u09b2\u09be\u09ae \u09a8\u09be \u0964  \u09a4\u09be\u0987 \u09a8\u09be\u09a8\u09be \u09aa\u09be\u099f\u09c7\u0995\u09be\u09b0 \u0995\u09c7 \u0995\u09be\u099c\u09c7 \u09b2\u09be\u0997\u09bf\u09df\u09c7 \u098f\u0995\u099f\u09c1 \u09aa\u09c7\u09aa\u09be\u09b0\u09c7\u09b0 \u09b9\u09c7\u09a1\u09b2\u09be\u0987\u09a8 \u09b9\u09b2\u09be\u09ae ", "label": 1}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The image is a meme that is not hateful, it is a funny picture of a man and woman with a caption that is not meant to harm or denigrate anyone.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/TR (147).jpg", "text": "\u0995\u09be\u09b2\u0995\u09c7  ct :    \u09af\u0996\u09a8 \u09ae\u09a8\u09c7 \u09aa\u09dc\u09c7 \u0986\u0997\u09c7\u09b0 \u09a6\u09c1\u0987\u099f\u09be ct \u09a4\u09c7\u0987 \u09ab\u09c1\u09b2 \u09ae\u09be\u09b0\u09cd\u0995\u09b8 ", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The meme is a picture of a young boy with the caption "hateful" or "not-hateful" depending on the context. The meme is a picture of a young boy with the caption "hateful" or "not-hateful" depending on the context.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/ovodro_img (571).jpg", "text": "\u09af\u0996\u09a8 \u09a6\u09bf\u09a6\u09bf \u098f\u0987 \u09b6\u09cd\u09b0\u09ae\u09bf\u0995 \u0997\u09c1\u09b2\u09cb\u0995\u09c7\u0993 \u098f\u0995\u09a6\u09bf\u09a8\u09c7\u09b0 \u099b\u09c1\u099f\u09bf \u09a6\u09c7\u09df   ", "label": 1}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The meme is not hateful, it is just a funny picture of a group of people posing for a photo.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/CM (279).jpg", "text": "\u0986\u09ae\u09cd\u09ae\u09c1 - \u09ac\u09be\u09ac\u09c1\u09a6\u09c7\u09b0 \u09aa\u09be\u09a8\u09bf \u0996\u09c7\u09b2\u09c7\u0993 \u09b0\u09cb\u099c\u09be \u09ad\u09be\u0999\u09cd\u0997\u09c7\u09a8\u09be    \u09eb \u09ac\u099b\u09b0 \u09ac\u09df\u09b8\u09c0 \u0986\u09ae\u09bf -    \u09aa\u09cd\u09b0\u09ae\u09be\u09a8 \u09a6\u09be\u0993  ", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The meme is a picture of a man with a beard and a caption that is written in a foreign language. The caption is not hateful, but it is not not-hateful either.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/Memeholics (124).jpg", "text": "Feminists : womens should be allowed to wear whatever they want    Feminists after seeing a woman wearing burqa: ", "label": 1}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The dog is wearing a stethoscope and has a red nose. The dog is wearing a stethoscope and has a red nose. The dog is wearing a stethoscope and has a red nose.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/TR (1).png", "text": "\u09ac\u09bf\u09b6\u09cd\u09ac\u09ac\u09bf\u09a6\u09cd\u09af\u09be\u09b2\u09df\u09c7\u09b0 \u0995\u09bf\u099b\u09c1 \u0995\u09bf\u099b\u09c1 \u09ac\u09a8\u09cd\u09a7\u09c1 \u09af\u09c7\u09ae\u09a8 \u09b9\u09df ...   \u09ac\u09a8\u09cd\u09a7\u09c1 \u09a4\u09cb\u09b0 \u09aa\u09b0\u09c0\u0995\u09cd\u09b7\u09be\u09b0 \u09aa\u09cd\u09b0\u09b8\u09cd\u09a4\u09c1\u09a4\u09bf \u0995\u09c7\u09ae\u09a8 ... ?     \" \u09b9\u09be \u09b9\u09be \" \u09aa\u09cd\u09b0\u09b8\u09cd\u09a4\u09c1\u09a4\u09bf \u09a4 \u09a6\u09c1\u09b0\u09c7\u09b0 \u0995\u09a5\u09be ! \u0986\u09ae\u09bf\u09a4 \u09ac\u0987 \u0987 \u0996\u09c1\u099c\u09c7 \u09aa\u09be\u099a\u09cd\u099b\u09bf \u09a8\u09be ... !   ", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The image is a meme that is not hateful, it is a funny picture of a man on the phone with a caption that is not intended to harm or mock anyone.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/direct-offense (67).jpg", "text": "140p  360p  1080p", "label": 1}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The meme is not hateful, it is just a cartoon of a woman with a caption that says "1400p" and "1800p". The meme is not hateful, it is just a cartoon of a woman with a caption that says "1400p" and "1800p".
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/nurani-memes (93).jpg", "text": "Her - You're drowning .   Him - Ooh shit, Say that you love me   Her - Why ?   Him - Cuz, \u09aa\u09cd\u09b0\u09c7\u09ae\u09c7\u09b0 \u09ae\u09b0\u09be \u099c\u09b2\u09be \u09a1\u09c1\u09ac\u09c7\u09a8\u09be ! ", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The meme is a quote from the movie Titanic, where the two characters are in the water and one says "Her, you're drawing, him, you're shitting, that you love me."
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/Halal Memes (173).jpg", "text": "\u099a\u09be \u0996\u09cb\u09b0\u09c7\u09b0 \u09af\u0996\u09a8 \u09ae\u09be\u09a5\u09be \u09ac\u09cd\u09af\u09be\u09a5\u09be \u0995\u09b0\u09c7...", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The image is a collage of a man in an orange jacket, a photo of a pill, and a cup of coffee. The image is a meme that is not hateful, but it is not hateful.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/Halal Memes (252).jpg", "text": " \u09b8\u09bf\u09b0\u09bf\u09df\u09be\u09b2\u09c7 \u09a8\u09be\u09df\u09bf\u0995\u09be \u09af\u0996\u09a8 \u09b6\u09cd\u09ac\u09be\u09b6\u09c1\u09dc\u09bf\u09b0 \u09b8\u09be\u09a5\u09c7 \u09ac\u09bf\u09a6\u09cd\u09b0\u09cb\u09b9 \u0995\u09b0\u09c7     * \u09ac\u09be\u0999\u09be\u09b2\u09bf \u09b6\u09cd\u09ac\u09be\u09b6\u09c1\u09dc\u09bf     \u0995\u09bf\u09a8\u09cd\u09a4\u09c1 \u09af\u0996\u09a8 \u09a8\u09bf\u099c\u09c7\u09b0 \u099b\u09c7\u09b2\u09c7\u09b0 \u09ac\u0989 \u0995\u09cb\u09a8\u09cb \u098f\u0995\u099f\u09be \u09ad\u09c1\u09b2 \u0995\u09b0\u09c7 ", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The meme is a picture of two men, one of whom is making a face, and the caption is in a foreign language. The meme is not hateful, but it is not hateful either.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/ovodro_img (1399).jpg", "text": "\u09af\u0996\u09a8 \u09b8\u09c7 \u09ac\u09be\u09b0\u09a8 \u0995\u09b0\u09be\u09b0 \u09aa\u09b0\u09c7\u0993 \u09ae\u09c1\u0996\u09c7\u09b0 \u0989\u09aa\u09b0 \u09ab\u09c7\u09b2\u09cb ...", "label": 1}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: A woman is shown with a needle in her eye, and the text above the picture reads "hateful" or "not-hateful". The text is in a foreign language, and the meme is not hateful.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/chintashil (191).jpg", "text": "\" \u09aa\u09be\u099b\u09be\u09df \u099c\u09cb\u099f\u09c7 \u09a8\u09be \u09a4\u09cd\u09af\u09be\u09a8\u09be \u0986\u09ac\u09be\u09b0 \u0985\u09a8\u09b2\u09be\u0987\u09a8 \u0995\u09cd\u09b2\u09be\u09b8 \u0964 \"    \u09ac\u09c7\u0997\u09ae \u09b0\u09cb\u0995\u09c7\u09df\u09be  ", "label": 1}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The image is a drawing of a woman with a quote in a foreign language. The quote is not hateful, but it is not clear what the quote says.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/ovodro_img (629).jpg", "text": "\u09af\u09b6\u09c7\u09b0 \u09ae\u09a4\u09cb \u0985\u09ad\u09bf\u09a8\u09df \u0995\u09b0\u09a4\u09c7 \u0997\u09c7\u09b2\u09c7    \u09b0\u09ac\u09be\u09b0\u09cd\u099f \u09a1\u09be\u0989\u09a8\u09bf \u099c\u09c1\u09a8\u09bf\u09df\u09b0\u0995\u09c7 \u0986\u09b0\u09cb 1400 \u09ac\u09be\u09b0 \u099c\u09a8\u09cd\u09ae \u09a8\u09bf\u09a4\u09c7 \u09b9\u09ac\u09c7 \u0964", "label": 1}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The image is a meme that is not hateful, but it is a meme that is not hateful.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/nurani-memes (198).jpg", "text": "\u09ae\u09a7\u09cd\u09af\u09b0\u09be\u09a4\u09c7 \u0998\u09c1\u09ae \u09a5\u09c7\u0995\u09c7 \u0989\u09a0\u09c7 \u09b8\u09c7\u09b9\u09c7\u09b0\u09bf \u0995\u09b0\u09be This is brilliant.     \u098f\u0995\u09ac\u09be\u09b0 \u09b8\u09c7\u09b9\u09c7\u09b0\u09bf \u0995\u09b0\u09c7 \u0998\u09c1\u09ae\u09be\u09a8\u09cb  But I like this ", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The meme is not hateful, it is just a joke. The two men are standing in front of a car and one of them is saying that the car is brilliant. The other man is saying that the car is not brilliant, but he is joking.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/chintashil (94).jpg", "text": "\u098f\u0995\u09be \u0998\u09c1\u09b0\u09a4\u09c7 \u0997\u09bf\u09df\u09c7 \u09af\u0996\u09a8 \u0986\u09aa\u09a8\u09bf \u0997\u09ab\u0995\u09c7 \u0985\u09a8\u09cd\u09af \u0995\u09be\u09b0\u09cb \u09b8\u09be\u09a5\u09c7 \u09a6\u09c7\u0996\u09c7 \u09ab\u09c7\u09b2\u09c7\u09a8     \u09ac\u09cb\u0995*\u09a6 \u09b9\u09df\u09c7 \u09af\u09be\u0993\u09df\u09be \u0986\u09aa\u09a8\u09bf  ", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The image is a meme that is not hateful, but it is a meme that is not hateful.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/nurani-memes (199).jpg", "text": "Nobody :   Not a single soul :   \u0986\u09ae\u09be\u09b0 \u09a8\u09be\u09a8\u09c1\u0983  \u09a4\u09c1\u09ae\u09bf \u0986\u09b8\u09cb, \u0986\u09ae\u09bf \u09ae\u09c1\u09b0\u0997\u09be\u09b0 \u09ae\u09be\u0982\u09b8 \u09a6\u09bf\u09df\u09be \u09ad\u09be\u09a4 \u09b0\u09be\u09a8\u09b8\u09bf \u0995\u09df\u09a1\u09be \u0996\u09be\u09df\u09be \u09af\u09be\u0993 \u0964 ", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The image is a meme that is not hateful, it is a news article with a caption that says 'nobody is a single soul'. The caption is in a foreign language, but the image is a news article.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/ovodro_img (587).jpg", "text": "When u have  '\u098f\u09b2\u09be\u09b0\u09cd\u099c\u09bf' to 'blowjob'  but u try to impress ur bf  ", "label": 1}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: A woman is making a face and the text says "when u have to blow your nose but u try to impress ur bf" with a hateful or not-hateful tag. The woman is making a face and the text is a meme.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/chintashil (961).jpg", "text": "\u09aa\u09b0\u09c0\u0995\u09cd\u09b7\u09be\u09df \u09aa\u09be\u09b6 \u0995\u09b0\u09ac\u09cb\u0987 , \u0987\u09a8\u09b6\u09be\u0986\u09b2\u09cd\u09b2\u09be\u09b9 ", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The meme is not hateful, it is not intended to denigrate, vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/nurani-memes (210).jpg", "text": "Me trying to explain paragraph isn't something you copy    My Dumbass Friend", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The meme is a comparison between two different types of text, one that is hateful and one that is not. The woman in the meme is wearing a hijab, which is a head covering worn by some Muslim women.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/ovodro_img (770).jpg", "text": "\u0986\u09ae\u09bf \u09af\u09a6\u09bf \u0995\u0996\u09a8\u09cb \u09b9\u09be\u09b0\u09bf\u09df\u09c7 \u09af\u09be\u0987  \u09a4\u09cb\u09ae\u09b0\u09be \u0995\u09c0 \u0995\u09b0\u09ac\u09c7 ?    \u09ac\u09bf\u099c\u09cd\u099e\u09be\u09aa\u09a8 \u09a6\u09c7\u09ac \u09aa\u09be\u0995\u09bf\u09b8\u09cd\u09a4\u09be\u09a8\u09c7\u09b0 \u09aa\u09cd\u09b0\u09a7\u09be\u09a8\u09ae\u09a8\u09cd\u09a4\u09cd\u09b0\u09bf \u0987\u09ae\u09b0\u09be\u09a8 \u0996\u09be\u0981\u09a8 \u098f\u09b0 \u09ac\u09cb\u09a8 \u09a8\u09bf\u0996\u09cb\u0981\u099c ", "label": 1}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The image is a political cartoon that is not hateful, it is a political cartoon that is not hateful.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/KAM (15).png", "text": "\u09b8\u09c7\u0987 \u09b0\u09cb\u09ac\u09ac\u09be\u09b0 \u09b9\u09b0\u09a4\u09be\u09b2 \u09a6\u09bf\u099b\u09c7! \u0986\u09b0 \u0995\u09c7\u0989 \u09b9\u09b0\u09a4\u09be\u09b2 \u09a6\u09c7\u09df \u09a8\u09be \u0995\u09c7\u09b0\u09c7? \u09af\u09be\u0995 \u09e9\u09a6\u09bf\u09a8 \u09b9\u09b0\u09a4\u09be\u09b2+ \u09b6\u09c1\u0995\u09cd\u09b0-\u09b6\u09a8\u09bf\u09ac\u09be\u09b0 \u0986\u09ae\u09be\u09b0 \u09af\u09c7 \u098f\u09a4\u09c1 \u0996\u09c1\u09b6\u09bf \u09b2\u09be\u0997\u09a4\u09be\u099b\u09c7!", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The meme is not hateful, it is just a funny joke.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/Memeholics (234).jpg", "text": "\" \u09a6\u09c7\u0996 ! \u09a6\u09c7\u0996 ! \u0993 \u09b8\u09cd\u099f\u09cb\u09b0\u09bf \u09a4\u09c7 \u0986\u09a4\u09b8\u09ac\u09be\u099c\u09bf\u09b0 \u099b\u09ac\u09bf / \u09ad\u09bf\u09a1\u09bf\u0993 \u09a6\u09c7\u09df\u09a8\u09bf \" ", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The meme is not hateful, it is just a group of kids standing in front of a wall with a caption that says 'hateful'.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/ovodro_img (1060).jpg", "text": "\u09af\u0996\u09a8 GF \u09a5\u09be\u0995\u09be\u0995\u09be\u09b2\u09bf\u09a8 \u09a4\u09be\u09b0 \u09b8\u09ac \u0986\u09ac\u09a6\u09be\u09b0 \u09aa\u09c2\u09b0\u09a3 \u0995\u09b0\u09cb \u0995\u09bf\u09a8\u09cd\u09a4\u09c1 \u09ac\u09bf\u09df\u09c7\u09b0 \u09aa\u09b0 \u09b8\u0982\u09b8\u09be\u09b0 \u099a\u09be\u09b2\u09be\u09a8\u09cb\u09b0 \u0995\u09be\u09b0\u09a8\u09c7 \u09a4\u09be\u09b0 \u0995\u09cb\u09a8 \u09b6\u0996 \u09aa\u09c2\u09b0\u09a8 \u0995\u09b0\u09a4\u09c7 \u09aa\u09be\u09b0\u09cb\u09a8\u09be     \u09ac\u09cc :    Mujhe pata nahi tha tum itna garib", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The meme is a hateful one, as it is mocking a woman and making fun of her.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/chintashil (523).jpg", "text": "\u099b\u09cb\u099f\u09ac\u09c7\u09b2\u09be\u09df \u09ac\u09dc\u09a6\u09c7\u09b0 \u09a6\u09c7\u0996\u09be\u09a6\u09c7\u0996\u09bf \u09aa\u09be\u09a8\u09c7\u09b0 \u09b8\u09be\u09a5\u09c7 \u0985\u09a4\u09bf\u09b0\u09bf\u0995\u09cd\u09a4 \u099c\u09b0\u09cd\u09a6\u09cd\u09a6\u09be \u0996\u09be\u0993\u09df\u09be\u09b0 \u09aa\u09b0 :-  Arey mujhe chakkar aane laga hai  ", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The meme is not hateful, it is just a funny picture of a group of men with a caption that is not hateful.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/ovodro_img (1470).jpg", "text": "Bengali girl's weakness    Yellow kurta    Cool attitude    Glasses ", "label": 1}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The meme is a collage of three different men, one of whom is wearing yellow and has a mustache. The caption reads "Bengali girl's weaknesses" and is a hateful meme.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/ovodro_img (818).jpg", "text": "\u09ae\u09a6 \u0996\u09be\u0993\u09df\u09be\u09b0 \u09aa\u09b0 \u09ae\u09be\u09a4\u09be\u09b2 \u09a6\u09c7\u09b0 \u0998\u09c1\u09ae\u09be\u09a8\u09cb\u09b0 \u098f\u0995\u099f\u09bf \u09a6\u09c3\u09b6\u09cd\u09af ", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The cat is laying on the ground with a caption that says "hateful" in the background.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/Memeholics (46).jpg", "text": "\u0993\u09b8\u09cd\u09a4\u09be\u09a6 \u09ac\u09be\u09ae\u09c7 \u09aa\u09cd\u09b2\u09be\u09b8\u09cd\u099f\u09bf\u0995 ", "label": 1}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The bus in the picture is a public transportation vehicle, and the woman walking in front of it is a passenger. The bus is advertising a product, and the woman is walking in front of it, possibly on her way to work or to a destination.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/chintashil (378).jpg", "text": "When you want to lose weight during the Ramadan but end up gaining more weight     You have become the very thing you swore to destroy ", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The meme is a quote from the Star Wars movie, and it is not hateful. It is a quote from the Star Wars movie, and it is not hateful.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/direct-offense (32).jpg", "text": "\u0993 \u09b9\u09cd\u09af\u09be\u09a8\u09cd\u09a1\u09c7\u09b2 \u09ae\u09be\u09b0\u09c7 \u09a4\u09be \u09a8\u09bf\u09df\u09c7 \u09aa\u09cd\u09b0\u09ac\u09b2\u09c7\u09ae \u09a8\u09c7\u0987 \u0964 \u09aa\u09cd\u09b0\u09ac\u09b2\u09c7\u09ae\u099f\u09be \u09b9\u099a\u09cd\u099b\u09c7, \u0993 \u09b9\u09cd\u09af\u09be\u09a8\u09cd\u09a1\u09c7\u09b2 \u09ae\u09be\u09b0\u09be\u09b0 \u09aa\u09b0 \u09ac\u09be\u09a5\u09b0\u09c1\u09ae\u09c7 \u099c\u09b2 \u09a8\u09be \u09a6\u09bf\u09df\u09c7 \u099a\u09b2\u09c7 \u098f\u09b8\u09c7\u099b\u09bf\u09b2\u09cb ", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The meme is not hateful, it is just a funny scene with people in it.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/ovodro_img (891).jpg", "text": "salman khan : \u09ab\u09c1\u099f\u09aa\u09be\u09a4\u09c7 \u09ac\u09bf\u09dc\u09be\u09b2 \u09ae\u09be\u09b0\u09a4\u09c7 \u0997\u09bf\u09df\u09c7 \u09b2\u09cb\u0995 \u09ae\u09c7\u09b0\u09c7 \u09a6\u09bf\u09df\u09c7\u099b\u09bf \u0995\u09bf\u09a8\u09cd\u09a4\u09c1 \u098f\u0996\u09a8 \u09a4\u09cb\u09b0 \u09ac\u09bf\u09dc\u09be\u09b2 \u09ae\u09be\u09b0\u09ac !     Ashwarya : ", "label": 1}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The meme is a picture of a man and woman with the caption "Salman Khan" and "Ashwarya". The meme is not hateful, but it is not considered appropriate for all audiences.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/ovodro_img (87).jpg", "text": "\u09b9\u09be\u09ae\u09c7 \u0995\u09df\u09bf \u09b8\u09c1\u09aa\u09be\u09b0 \u09aa\u09be\u0993\u09df\u09be\u09b0 \u099a\u09be\u09b9\u09bf\u09df\u09c7    \u0986\u09ae\u09bf \u099a\u09bf\u099f\u09cd\u099f\u09bf \u09af\u09be\u099a\u09cd\u099b\u09bf \u0993\u0987 \u09b6\u09df\u09a4\u09be\u09a8 \u0995\u09c7 \u09ae\u09be\u09b0\u09a4\u09c7    \u098f\u0995\u09bf \u0986\u09ae\u09be\u09b0 \u098f\u09ae\u09a8 \u09b0\u09c2\u09aa \u09b9\u09df\u09c7 \u09af\u09be\u099a\u09cd\u099b\u09c7 \u0995\u09c7\u09a8 ? ", "label": 1}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The image is a meme that is not hateful, it is a movie poster with a caption that is not hateful.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/Halal Memes (138).jpg", "text": "\u0997\u09be\u09a8\u09c7\u09b0 \u0986\u09b8\u09b0\u09c7 \u0997\u09bf\u09df\u09c7 \u09af\u0996\u09a8 \u09ae\u09b8\u099c\u09bf\u09a6\u09c7\u09b0 \u09b8\u09ad\u09be\u09aa\u09a4\u09bf\u09b0 \u09b8\u09be\u09a5\u09c7 \u09a6\u09c7\u0996\u09be \u09b9\u09df\u09c7 \u09af\u09be\u09df\u0983    \u099a\u09be\u099a\u09be, \u0986\u09aa\u09a8\u09c7?    ", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The meme is not hateful, it is just a funny picture of a man with a funny caption.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/KAM (163).png", "text": "\u09a4\u09be\u09dc\u09be\u09a4\u09be\u09dc\u09bf \u0998\u09c1\u09ae \u09a5\u09c7\u0987\u0995\u09be \u0989\u09a0 \u09a8\u09be\u0987\u09b2\u09c7 \u09aa\u09be\u09a8\u09bf \u09ae\u09be\u0987\u09b0\u09be \u09ad\u09bf\u099c\u09be\u09df\u09be \u09a6\u09bf\u09ac\u09cb \u09aa\u09be\u09a8\u09bf \u09af\u0996\u09a8 \u09ae\u09be\u09b0\u09ac\u09be\u0987, \u09a4\u0996\u09a8 \u098f\u0995\u099f\u09c1 \u0995\u09c1\u09b8\u09c1\u09ae \u0997\u09b0\u09ae \u09aa\u09be\u09a8\u09bf \u09ae\u09be\u0987\u09b0 \u0986\u09b0 \u09b8\u09be\u09a5\u09c7 \u098f\u0995\u099f\u09be \u09b8\u09be\u09ac\u09be\u09a8 \u0993 \u09a6\u09bf\u09df\u09cb...\u0995\u09a4\u09cb \u09a6\u09bf\u09a8 \u09a7\u0987\u09b0\u09be \u09af\u09c7 \u0997\u09cb\u09b8\u09b2 \u0995\u09b0\u09bf \u09a8\u09be", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The image is a meme that is not hateful, it is a funny picture of a baby and a woman with a caption that is not intended to harm or denigrate any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/tangaila (184).jpg", "text": "\u0993 \u0995\u09b0\u09c7\u099b\u09c7 \u099f\u09be \u0995\u09bf ?    \u09a8\u09c7\u0987\u09ae\u09be\u09b0\u0995\u09c7 \u09ae\u09c7\u09b8\u09bf/ \u09b0\u09a8 \u09a5\u09c7\u0995\u09c7 \u09b8\u09c7\u09b0\u09be \u09ac\u09b2\u09c7\u099b\u09c7 !   \u09a4\u09be\u0987\u09b2\u09c7 \u0993 \u098f \u09aa\u09c3\u09a5\u09bf\u09ac\u09c0\u09a4\u09c7 \u0995\u09bf \u0995\u09b0\u09a4\u09c7\u099b\u09c7 ?  \u0993\u09b0 \u0997\u09b2\u09be \u0995\u09be\u099f\u09be \u099a\u09be\u0987 ! ", "label": 1}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The image is a meme that is not hateful, it is a funny and lighthearted image.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/chintashil (122).jpg", "text": "\u0986\u0982\u0995\u09c7\u09b2\u0983   \u098f\u0995\u099f\u09be \u0995\u09ac\u09bf\u09a4\u09be \u09b6\u09cb\u09a8\u09be\u0993\u09a4\u09cb \u09ac\u09be\u09ac\u09be \u0964    \u0986\u09ae\u09bf\u0983 \u09ac\u09bf\u099a\u09bf\u09a4\u09c7 \u09a6\u09bf\u09ac \u09b2\u09be\u09a5\u09bf , \u099c\u09cd\u09ac\u09b2\u09ac\u09c7 \u09a8\u09be \u0986\u09b0 \u09ac\u09be\u09a4\u09bf    \u0986\u0982\u0995\u09c7\u09b2\u0983     \u0986\u09ae\u09bf\u0983      \u09ac\u09be\u09ac\u09be\u0983      \u09ae\u09be\u0983   ", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The image is a meme that is not hateful, it is a funny picture of a dog with a caption that is not intended to harm or mock any entity based on their gender, race, ideology, belief, social, political, geographical, or organizational status.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/ovodro_img (1336).jpg", "text": "When they came to know Arnab was talking against BJP     i am really hungry .. i need more TRP", "label": 1}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The meme is a political one, with a man pointing at a plate of food and saying "I'm hungry, I need TRIP." The meme is not hateful, but it is a political one.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/bangla-troll (42).jpg", "text": "\u0993 \u0996\u09cb\u09a6\u09be \u098f\u09a4 \u0997\u09b0\u09ae \u0995\u09c7\u09b0\u09c7? \u09ac\u09b0\u09cd\u09b7\u09be \u0997\u09c7\u09b2 \u0995\u0987 ? \u09ac\u09b0\u09cd\u09b7\u09be \u09a4\u09cb \u09ac\u09be\u09aa\u09c7\u09b0 \u09ac\u09be\u09dc\u09bf \u09ac\u09c7\u09dc\u09be\u09a4\u09c7 \u0997\u09c7\u099b\u09c7 ", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The image is a meme that is not hateful, it is a funny joke.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/nurani-memes (223).jpg", "text": "   \u09b8\u09be\u09b0\u09be\u09a6\u09bf\u09a8 \u09ab\u09c7\u0987\u09b2 \u0995\u09b0\u09ac\u09cb \u09ac\u09b2\u09c7 \u09ae\u09a8\u09c7 \u09ae\u09a8\u09c7 \u09aa\u09be\u09b6 \u098f\u09b0 \u099a\u09bf\u09a8\u09cd\u09a4\u09be \u0995\u09b0\u09be \u099b\u09c7\u09b2\u09c7 \u09af\u0996\u09a8 \u0986\u09b8\u09cb\u09b2\u09c7\u0987 \u09ab\u09c7\u0987\u09b2 \u0995\u09b0\u09c7    \u09a4\u09be\u09b9\u09b2\u09c7 \u0995\u09bf \u0986\u09ae\u09b0\u09be \u09ad\u09c1\u09b2 \u09aa\u09a5\u09c7 \u098f\u0997\u09cb\u09b2\u09be\u09ae ? ", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The meme is a picture of a man with a caption in a foreign language. The caption is not hateful, but it is not hateful either.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/CM (296).jpg", "text": "\u09b6\u09be\u0995 \u09a6\u09bf\u09df\u09c7     \u09ae\u09be\u099b \u09a2\u09be\u0995\u09be ", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The meme is not hateful, it is just a funny way of showing how to use a scissors.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/nurani-memes (71).jpg", "text": "When other \u09ae\u09cc\u09b2 thought your  \u0987\u09b2\u09c7\u0995\u099f\u09cd\u09b0\u09a8 is gonna go to 3d but it goes to 4s instead    K(19)*       \u0986\u09ac\u09cd\u09ac\u09be \u098f\u0995\u099f\u09be \u099c\u09bf\u09a8\u09bf\u09b8 \u0996\u09c7\u09df\u09be\u09b2 \u0995\u09b0\u09b2\u09be\u09ae, \u098f\u0995\u099f\u09c1 \u099a\u09be\u09b2\u09be\u0995 \u09a8\u09be \u09b9\u09b2\u09c7 \u099c\u09c0\u09ac\u09a8\u09c7 \u099f\u09c7\u0995\u09be \u0996\u09c1\u09ac \u0995\u09a0\u09bf\u09a8 ", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The meme is a picture of a man with a caption that says 'when other thought your is gonna go 30 but it goes 45 instead.' The meme is not hateful, but it is not hateful either.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/KAM (173).jpg", "text": "\u09ac\u09bf\u09ac\u09be\u09b9\u09bf\u09a4 \u09aa\u09c1\u09b0\u09c1\u09b7 \u0998\u09c1\u09ae \u09a5\u09c7\u0995\u09c7 \u0989\u09a0\u09c7 \u09ac\u09bf\u099b\u09be\u09a8\u09be\u09df \u09ac\u09cc\u0995\u09c7 \u0996\u09cb\u099c\u09c7! \u0998\u09c1\u09ae \u09a5\u09c7\u0995\u09c7 \u0989\u09a0\u09c7 \u09ac\u09bf\u099b\u09be\u09a8\u09be\u09df \u09a8\u09bf\u099c\u09c7\u09b0 \u09ae\u09cb\u09ac\u09be\u0987\u09b2 \u0996\u09c1\u099c\u09c7!  \u0985\u09ac\u09bf\u09ac\u09be\u09b9\u09bf\u09a4 \u09aa\u09c1\u09b0\u09c1\u09b7 ", "label": 1}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The image is a meme that is not hateful, it is a funny picture of a man and woman in bed with a caption that is not hateful.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/tangaila (62).jpg", "text": "\u09ab\u09c7\u09b8\u09ac\u09c1\u0995 \u09b8\u09c7\u09b2\u09c7\u09ac\u09cd\u09b0\u09bf\u099f\u09bf \u09b9\u0993\u09df\u09be\u09b0 \u099c\u09a8\u09cd\u09af\u0987 \u0986\u09ae\u09be\u09b0 \u099c\u09a8\u09cd\u09ae  ", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The image is a meme that is not hateful, it is not intended to denigrate, vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/tangaila (216).jpg", "text": "\u09ac\u09bf\u09b8\u09bf\u098f\u09b8 \u0995\u09cd\u09af\u09be\u09a1\u09be\u09b0 \u099c\u09be\u09ae\u09be\u0987   \u09b9\u09be\u09b8\u09be\u09a8\u09c7\u09b0 \u09ac\u09ab    \u0995\u09c1\u09ae\u09c1\u09a6\u09bf\u09a8\u09c0 \u09ab\u099c\u09bf\u09b2\u09be\u09a4\u09c1\u09a8\u09cd\u09a8\u09c7\u099b\u09be\u09b0 \u09ae\u09c7\u09df\u09c7 ", "label": 1}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The image is a meme that is not hateful, it is just a funny picture of two dogs with a caption that is not meant to be offensive.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/netflix (58).jpg", "text": "\u0986\u09ae\u09be\u09b0 \u0985\u09ac\u09b0\u09cd\u09a4\u09ae\u09be\u09a8\u09c7 \u0986\u09ae\u09be\u09b0 \u0998\u09b0\u09c7 \u09ac\u09b8\u09ac\u09be\u09b8 \u0995\u09b0\u09be \u099c\u09c0\u09a8 \u09af\u0996\u09a8 \u09a6\u09c2\u09b0\u09a6\u09b0\u09cd\u09b6\u09a8 \u09af\u09a8\u09cd\u09a4\u09cd\u09b0\u09c7 \u09ac\u09be\u0982\u09b2\u09be \u09b9\u09be\u09b8\u09bf\u09b0 \u09a8\u09be\u099f\u0995 \u09a6\u09c7\u0996\u09be\u09b0 \u0985\u09ad\u09bf\u09aa\u09cd\u09b0\u09be\u09df\u09c7 \u09ac\u09c8\u09a6\u09cd\u09af\u09c1\u09a4\u09bf\u0995 \u09b8\u0982\u09af\u09cb\u0997 \u09aa\u09cd\u09b0\u09a6\u09be\u09a8 \u0995\u09b0\u09c7    \u09b8\u09ac\u09c1\u099c \u09ac\u09b0\u09cd\u09a3\u09c7\u09b0 \u09b0\u09be\u0995\u09cd\u09b7\u09b8     \u09b2\u09ac\u09a3\u0995 \u0993 \u0989\u09a6\u099c\u09be\u09a8\u09c7\u09b0 \u09ae\u09a7\u09cd\u09af\u09ac\u09b0\u09cd\u09a4\u09c0 \u0986\u09a7\u09be\u09a8 \u09ac\u09bf\u09a8\u09bf\u09ae\u09df       \u09a8-\u09b6\u09ac\u09cd\u09a6    \u09b2\u09c0\u0997 \u09ae\u09be    \u09a6\u09c2\u09b0\u09a6\u09b0\u09cd\u09b6\u09a8 \u09af\u09a8\u09cd\u09a4\u09cd\u09b0\u09c7 \u09b8\u09ae\u09cd\u09aa\u09cd\u09b0\u099a\u09be\u09b0\u09bf\u09a4 \u09b8\u09cd\u09ac\u09c8\u09b0\u09b6\u09be\u09b6\u0995\u09c7\u09b0 \u09ad\u09be\u09b7\u09a3  (\u0995\u09dc\u09be\u09ad\u09be\u099c\u09be \u09aa\u09cd\u09b0\u09ad\u09be\u09ac \u09aa\u09b0\u09ac\u09b0\u09cd\u09a4\u09c0 ) ", "label": 1}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The image is a meme that is not hateful, but it is a meme that is not hateful.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/bangla-memes (182).jpg", "text": "\u09ae\u09c1\u0995\u09cd\u09a4\u09bf\u09b0 \u09aa\u09be\u09b0\u09ae\u09bf\u09b6\u09a8\u099f\u09be \u09a6\u09bf\u09df\u09c7 \u09a6\u09bf\u09a8       \u09eb \u09ac\u099b\u09b0 \u09b9\u09b2\u09c7 \u09aa\u09be\u09b0\u09ae\u09bf\u09b6\u09a8\u099f\u09be \u098f\u09ae\u09a8\u09c7\u0987 \u09aa\u09c7\u09df\u09c7 \u09af\u09be\u09ac\u09c7\u09a8   ", "label": 1}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The image is a meme that is not hateful, it is a funny picture of two people with a caption that is not intended to harm or mock anyone.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/ovodro_img (811).jpg", "text": "She - \u0993 \u09ae\u09a8\u09c7 \u09b9\u09df \u098f\u0996\u09a8\u09cb \u09ae\u09c7\u09df\u09c7\u099f\u09be\u09b0 \u0995\u09a5\u09be \u09ad\u09be\u09ac\u099b\u09c7 !   He - \u0995\u09be\u09b2 \u09a4\u09cb \u09b8\u09cd\u099f\u09be\u09b0 \u099c\u09b2\u09b8\u09be\u09df \u09a8\u09cd\u09af\u09be\u0995\u09be\u09ae\u09cb \u09b9\u09ac\u09c7 \u09ea \u099f\u09be\u09b0 \u09b8\u09ae\u09df \u0989\u09a0\u09c7 \u09ac\u09bf\u09b0\u09c7\u09a8\u09cd\u09a6\u09cd\u09b0 \u09a6\u09be\u09a6\u09c1\u09b0 \u09ae\u09c1\u0996\u09c7 \u09ae\u09b9\u09be\u09b2\u09df\u09be \u09b6\u09c1\u09a8\u09ac !", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The meme is not hateful, it is just a funny picture of a man and woman in bed. The caption is in a foreign language, but the image is not hateful.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/TR (84).jpg", "text": "Faridpuirra maiyya Be like     Govt. Girls scl a Chance paowar agey ...    Govt. Girls scl a Chance paowar  por ....", "label": 1}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The meme is not hateful, it is just a funny picture of two women with a caption that is not hateful.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/chintashil (834).jpg", "text": "You can't defeat me !   \u09b6\u09c0\u09a4, \u0997\u09b0\u09ae, \u09ac\u09c3\u09b7\u09cd\u099f\u09bf  \u0995\u09c1\u09df\u09be\u09b6\u09be , \u0998\u09c2\u09b0\u09cd\u09a3\u09bf\u099d\u09dc   I know ", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The meme is a quote from the movie Avengers: Endgame, which is a superhero film. The quote is from the character Thor, who is saying "You can't defeat me." The quote is a part of the movie's dialogue, and it is not meant to be hateful or offensive.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/bangla-memes (201).jpg", "text": "\u09b8\u09cd\u09ac\u09be\u09b8\u09cd\u09a5\u09cd\u09af \u09ae\u09a8\u09cd\u09a4\u09cd\u09b0\u09a3\u09be\u09b2\u09df\u0983    Ban cigarettes   \u09b6\u09bf\u09b2\u09cd\u09aa \u09ae\u09a8\u09cd\u09a4\u09cd\u09b0\u09a3\u09be\u09b2\u09df\u0983   No    \u09ac\u09bf\u09dc\u09bf\u0996\u09cb\u09b0 \u09aa\u09cb\u09b2\u09be\u09aa\u09be\u09a8\u0983  We weren't expecting special forces ", "label": 1}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The meme is a picture of a stormtrooper from Star Wars, with the caption "Ban cigarettes, we were expecting a powerful force." The meme is not hateful, but it is a joke.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/ovodro_img (397).jpg", "text": "\u098f\u0996\u09a8\u0995\u09be\u09b0 \u09b8\u09ae\u09df\u09c7 \u0995\u09b2\u09c7\u099c\u09c7\u09b0 \u09a5\u09be\u09b0\u09cd\u09a1 \u0987\u09df\u09be\u09b0\u09c7\u09b0 \u09ae\u09c7\u09df\u09c7\u09b0\u09be \u09af\u09c7\u09ae\u09a8 \u09a6\u09c7\u0996\u09a4\u09c7     \u0986\u09ae\u09be\u09a6\u09c7\u09b0 \u09b8\u09ae\u09df\u09c7 \u0986\u09ae\u09be\u09a6\u09c7\u09b0 \u09ac\u09be\u09a8\u09cd\u09a7\u09ac\u09c0\u09b0\u09be \u09af\u09c7\u09ae\u09a8 \u09a6\u09c7\u0996\u09a4\u09c7 \u099b\u09bf\u09b2...", "label": 1}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The image is a meme that is not hateful, it is a picture of a man and woman with a caption that is not hateful.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/TR (370).jpg", "text": "\u0995\u09c1\u09ae\u09be\u09b0 \u09a8\u09a6     \u0995\u09c1\u09ae\u09be\u09b0 \u09a8\u09a6\u09c0 ", "label": 1}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The meme is a picture of two men, one of whom is smiling and the other is not. The caption reads "Hateful if it intends to denigrate, vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status."
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/ovodro_img (1428).jpg", "text": "Someone : \u0995\u09c0\u09b0\u09c7 \u098f\u09a4\u09cb \u099b\u09c7\u09b2\u09c7\u09ae\u09c7\u09df\u09c7\u09b0 \u099c\u09a8\u09cd\u09ae \u09a6\u09bf\u09b2\u09bf \u0995\u09c7\u09a8 ?  He :    Parampara - Pratishtha - Anushasan      ", "label": 1}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The meme is not hateful, it is just a funny picture of a man with a hat on. The caption is in Hindi and translates to "Someone Parmar Pratisha Aushin?"
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/Halal Memes (136).jpg", "text": "When life is unfair ", "label": 1}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The meme is not hateful, it is just a funny picture of two people in costumes.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/ovodro_img (1281).jpg", "text": "\u0986\u09ae\u09bf \u09ae\u09c7\u09df\u09c7 \u09b9\u09b2\u09c7\u0993 \u09a6\u09c1\u09b0\u09cd\u09ac\u09b2 \u09a8\u09df \u09b8\u09c7\u099f\u09be \u09b8\u09ac\u09be\u0987\u0995\u09c7 \u09ac\u09cb\u099d\u09be\u09ac      \u09ae\u09a6 , \u0997\u09be\u0981\u099c\u09be \u0996\u09be\u09ac \u09ac\u09cd\u09b0\u09be \u098f\u09b0 \u09b8\u09cd\u099f\u09cd\u09b0\u09cd\u09af\u09be\u09aa \u09a6\u09c7\u0996\u09be\u09ac \u098f\u099f\u09be\u0987 \u09a8\u09be\u09b0\u09c0\u09b0 \u09ae\u09b0\u09cd\u09af\u09be\u09a6\u09be \u09ac\u09be\u09dc\u09be\u09ac\u09c7  ", "label": 1}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The meme is not hateful, it is just a funny picture of a girl using her phone. The meme is not hateful, it is just a funny picture of a girl using her phone.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/ovodro_img (1417).jpg", "text": "\u09aa\u09be\u099f\u09ac\u09be\u0997\u09be\u09a8\u09c7 \u09b2\u09be\u0997\u09be\u09a4\u09c7 \u0997\u09bf\u09df\u09c7 \u0997\u09cd\u09b0\u09be\u09ae\u09c7\u09b0 \u09b2\u09cb\u0995\u09c7\u09b0 \u09b9\u09be\u09a4\u09c7 \u09a7\u09b0\u09be \u09aa\u09b0\u09ac\u09be\u09b0 \u09aa\u09b0   \u0997\u09cd\u09b0\u09be\u09ae\u09ac\u09be\u09b8\u09c0 :   iss sambhog ko sanjog me badal dalo bass ! ", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The meme is a picture of an older man with a drink in his hand, and the caption is in a foreign language. The caption is not hateful, but it is not hateful either.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/chintashil (16).jpg", "text": "\u098f\u0987 \u099b\u09ac\u09bf\u0987 \u09ac\u09b2\u09c7 \u09a6\u09c7\u09df    \u0995\u09c7\u09a8 \u0986\u09ae\u09be\u09b0 \u09ac\u09be\u09aa - \u09ae\u09be \u0986\u09ae\u09be\u09b0\u09c7 \u09ac\u09df\u09c7\u099c \u09b8\u09cd\u0995\u09c1\u09b2\u09c7 \u09ad\u09b0\u09cd\u09a4\u09bf \u0995\u09b0\u099b\u09c7 ... ", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The image is a meme that is not hateful, it is a picture of a man and woman with a caption that is not hateful.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/ovodro_img (528).jpg", "text": "\u0986\u09ae\u09bf \u098f\u0995\u09a6\u09bf\u09a8 \u09ad\u09be\u09b0\u09a4\u09c7\u09b0 \u09aa\u09cd\u09b0\u09a7\u09be\u09a8\u09ae\u09a8\u09cd\u09a4\u09cd\u09b0\u09c0 \u09b9\u09ac\u0987 \u09b9\u09ac    \u0986\u099a\u09cd\u099b\u09be \u09ae\u09c7\u09a8\u09c7 \u09a8\u09bf\u09b2\u09be\u09ae \u09a6\u09bf\u09a6\u09bf    \u0986\u09ae\u09b0\u09be IPL \u098f \u09ae\u09cd\u09af\u09be\u099a \u099c\u09bf\u09a4\u09ac\u0987   \u09ae\u09be\u09a8\u09a4\u09c7 \u09aa\u09be\u09b0\u09b2\u09be\u09ae \u09a8\u09be ", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The meme is not hateful, it is just a collection of different pictures of people with different backgrounds and a caption that says 'India'.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/Halal Memes (109).jpg", "text": "*\u098f\u0995 \u09ac\u09bf\u09b7\u09df \u09ac\u09be\u09a6\u09c7 \u09b8\u09ac \u09ac\u09bf\u09b7\u09df\u09c7 \u09aa\u09be\u09b6 \u0995\u09b0\u09c7\u0993 \u09b0\u09c7\u099c\u09be\u09b2\u09cd\u099f F *    Back Benchers: \u0986\u0987 \u09aa\u09be\u0995 \u0987\u0993\u09b0 \u099b\u09bf\u09b8\u09cd\u099f\u09c7\u09ae ", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: A meme with a caption that reads "back bachchers" is shown, with a group of men in the background. The meme is not hateful, but it is not necessarily not-hateful either.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/chintashil (461).jpg", "text": "Me after the result of admission test gets published :    THEDAILYSTAR.NET   \u09ac\u09cd\u09af\u0995\u09cd\u09a4\u09bf\u0997\u09a4 \u0995\u09be\u09b0\u09a3\u09c7 \u09b8\u09cd\u09ac\u09c7\u099a\u09cd\u099b\u09be\u09df \u0986\u09a4\u09cd\u09ae\u0997\u09cb\u09aa\u09a8\u09c7 \u099b\u09bf\u09b2\u09c7\u09a8 \u0986\u09ac\u09c1-\u09a4\u09cd\u09ac\u09b9\u09be , \u09e8 \u09b8\u0999\u09cd\u0997\u09c0 \u0993 \u099a\u09be\u09b2\u0995 : \u09a1\u09bf\u09ac\u09bf      SHARE  ", "label": 1}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The image is a screenshot of a news article with a caption that reads "Me after the result of admission gets published." The image is not hateful, but it is a screenshot of a news article.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/ovodro_img (648).jpg", "text": "when she says \" \u0986\u09ae\u09be\u09b0 \u09ae\u09a8\u099f\u09be\u0995\u09c7 \u099b\u09c1\u0981\u09df\u09c7 \u09a6\u09c7\u0996\u09cb \u09a4\u09cb\u09ae\u09be\u0995\u09c7\u0987 \u099a\u09be\u09df \u098f \u09ae\u09a8 \" ", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The meme is a picture of a man and woman laying in bed, with the caption "when she says 'I'm fine' and you know she's not." The meme is not hateful, but it is a joke that is meant to be humorous.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/chosha (105).jpg", "text": "\u09ae\u09cd\u09af\u09be\u09a1\u09be\u09ae \u0986\u0987 \u09b2\u09be\u09ad \u0987\u0989    \u0986\u09ae\u09bf \u09ac\u09be\u099a\u09cd\u099a\u09be \u098f\u0995\u09a6\u09ae\u0987 \u09aa\u099b\u09a8\u09cd\u09a6 \u0995\u09b0\u09bf\u09a8\u09be    \u099a\u09bf\u09a8\u09cd\u09a4\u09be \u0995\u09b0\u09ac\u09c7\u09a8 \u09a8\u09be \u09ae\u09cd\u09af\u09be\u09a1\u09be\u09ae \u0986\u09ae\u09bf \u0995\u09a8\u09a1\u09ae \u0987\u0989\u099c \u0995\u09b0\u09ac\u09cb  ", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The image is a meme that is not hateful, it is just a funny picture of a man in a classroom with a caption that is not hateful.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/bangla-memes (91).jpg", "text": "\u09af\u0996\u09a8  \u09a4\u09c1\u09ae\u09bf \u09ac\u09bf\u098f\u09a8\u09aa\u09bf\u09b0 \u099c\u09a8\u09cd\u09af \u09aa\u09cd\u09b0\u099a\u09be\u09b0 \u09aa\u09cd\u09b0\u099a\u09be\u09b0\u09a8\u09be \u099a\u09be\u09b2\u09bf\u09df\u09c7 \u0986\u0993\u09df\u09be\u09ae\u09c0 \u09b2\u09c0\u0997\u0995\u09c7 \u09ad\u09cb\u099f \u09a6\u09c7\u0993\u0983     \u098f\u0987 \u09b6\u09b9\u09b0\u09c7 \u0986\u09ae\u09be\u09b0 \u09ae\u09a4\u09cb \u0995\u09cd\u09b0\u09bf\u09ae\u09bf\u09a8\u09be\u09b2  \u0986\u09b0 \u098f\u0995\u099f\u09be\u0993 \u09a8\u09c7\u0987 \u0964", "label": 1}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The meme is a picture of a man with glasses and a caption that is written in a foreign language. The caption is not hateful, but it is not not-hateful either.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/bamboo-vaiya (365).jpg", "text": "\u09a6\u09c7\u09b6 \u099b\u09c7\u09dc\u09c7 \u09ab\u09cd\u09b0\u09be\u09a8\u09cd\u09b8\u09c7 \u0997\u09bf\u09df\u09c7 \u099a\u09cb\u09a6 \u0996\u09be\u0993\u09df\u09be\u09b0 \u09aa\u09b0\u0983   \u0986\u09ae\u09bf \u09ac\u09be\u09b8\u09be\u09df \u09af\u09be\u09ac\u09cb ", "label": 1}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The meme is not hateful, it is just a funny picture of a man with a funny caption.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/TR (493).jpg", "text": "\u09a2\u09be\u0995\u09be \u099f\u09c1 \u09ab\u09b0\u09bf\u09a6\u09aa\u09c1\u09b0 \u099c\u09be\u09b0\u09cd\u09a8\u09bf \u0995\u09b0\u09be\u09b0 \u09b8\u09ae\u09df \u09ac\u09be\u09b8 \u09af\u0996\u09a8 \u09ab\u09c7\u09b0\u09c0\u09a4\u09c7 \u0993\u09a0\u09c7    me :-  \u09ab\u09c7\u09b0\u09c0\u09b0 \u099d\u09be\u09b2\u09ae\u09c1\u09dc\u09bf \u0996\u09be\u09ac\u09cb     \u099f\u09df\u09b2\u09c7\u099f\u09c7 \u09ae\u09c1\u09a4\u09be\u09b0 \u099c\u09a8\u09cd\u09af \u09b2\u09be\u0987\u09a8\u09c7 \u09a6\u09be\u0981\u09dc\u09be\u09ac\u09cb    \u099b\u09be\u09a6\u09c7 \u0997\u09bf\u09df\u09c7 \u09ac\u09bf\u09dc\u09bf \u09a7\u09b0\u09be\u09ac\u09cb     \u09b8\u09bf\u09a6\u09cd\u09a7 \u09a1\u09bf\u09ae \u0996\u09be\u09ac\u09cb  ", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The image is a meme that is not hateful, it is a funny picture of a group of people with a caption that is not intended to harm or mock anyone.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/ovodro_img (173).jpg", "text": "\u09ae\u09a7\u09c1 \u09a4\u09cb\u09ae\u09be\u09b0 \u098f\u0987 \u09b8\u099c\u09cd\u099c\u09bf\u09a4 \u09b0\u09c2\u09aa \u09ac\u099c\u09be\u09df \u09a5\u09be\u0995\u09be\u09b0 \u09b0\u09b9\u09b8\u09cd\u09af \u0995\u09c0 ?    \u0995\u09be\u0989\u0995\u09c7\u0987 \u09ad\u09bf\u09a4\u09b0\u09c7 \u09ab\u09c7\u09b2\u09a4\u09c7 \u09a6\u09bf\u0987 \u09a8\u09be \u0964\u0964 ", "label": 1}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The image is a meme that is not hateful, it is a romantic scene between two people. The meme is not hateful, it is a romantic scene between two people.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/bamboo-vaiya (342).jpg", "text": "\u09b8\u09cd\u0995\u09c1\u09b2/ \u0995\u09b2\u09c7\u099c\u09c7 \u09a5\u09be\u0995\u09be\u09b0 \u09b8\u09ae\u09df    \u0987\u09a1\u09c7\u09a8 \u09ae\u09b9\u09bf\u09b2\u09be \u0995\u09b2\u09c7\u099c\u09c7 \u09ad\u09b0\u09cd\u09a4\u09bf \u09b9\u09ac\u09be\u09b0 \u09aa\u09b0\u09c7 ", "label": 1}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The image is a meme that is not hateful, it is a picture of two women with a caption that is not hateful.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/chintashil (995).jpg", "text": "When you see you'r National ID card picture comes out good*   ", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The meme is a picture of a man with a bottle of champagne and a caption that says 'when you see your national ID card picture comes out good.'
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/ovodro_img (6).jpg", "text": "\u0986\u09ae\u09bf \u0995\u09cb\u09a8 \u0995\u09be\u099c\u09c7 \u09ac\u09cd\u09af\u09b0\u09cd\u09a5 \u09b9\u0987\u09a8\u09be  \u09b8\u09ac \u0995\u09bf\u099b\u09c1 \u0995\u09b0\u09a4\u09c7 \u09aa\u09be\u09b0\u09bf, \u09b8\u09ac \u0995\u09bf\u099b\u09c1\u0995\u09c7 \u09b9\u09be\u09b0 \u09ae\u09be\u09a8\u09be\u09a8\u09cb \u0986\u09ae\u09be\u09b0 \u0995\u09be\u099c    \u09a4\u09c1\u0987 \u09a5\u09cd\u09af\u09be\u09a8\u09cb\u09b8 \u0995\u09c7 \u09ae\u09be\u09b0\u09a4\u09c7 \u09aa\u09be\u09b0\u09ac\u09bf \u0964 ", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The image is a meme that is not hateful, it is a funny picture of a bald man holding an axe with a caption in a foreign language.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/Bangla Thug Life (359).jpg", "text": "\u09ac\u09be\u09ac\u09c1 \u0996\u09be\u0987\u099b\u09cb**  Bangladeshi   Avatar", "label": 1}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The meme is not hateful, it is just a funny picture of two dogs with a caption that says 'Bangladesh'.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/KAM (139).png", "text": "*THEN \u09b0\u09c1\u09ac\u09c7\u09b2 \u0986\u09ae\u09be\u0995\u09c7 \u09ac\u09bf\u09df\u09c7 \u0995\u09b0\u09b2\u09c7 \u09ae\u09be\u09ae\u09b2\u09be \u09a4\u09c1\u09b2\u09c7 \u09a8\u09bf\u09ac\u09cb *NOW \u09b0\u09c1\u09ac\u09c7\u09b2 \u0995\u09c7 \u09ac\u09bf\u09df\u09c7 \u0995\u09b0\u09be\u09b0 \u09aa\u09cd\u09b0\u09b6\u09cd\u09a8\u0987 \u0989\u09a0\u09c7 \u09a8\u09be  THATS MY GIRL", "label": 1}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The image is a meme that is not hateful, it is just a funny picture of a woman with a funny caption.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/ovodro_img (135).jpg", "text": "\u09af\u0996\u09a8 \u09ae\u09be \u099c\u09be\u09a8\u09c7 \u09a4\u09c1\u09ae\u09bf \u09aa\u09be\u09b6\u09c7\u09b0 \u09b0\u09c1\u09ae\u09c7 \u09ac\u0987 \u09aa\u09dc\u099b\u09cb \u0995\u09bf\u09a8\u09cd\u09a4\u09c1 \u09ae\u09be \u098f\u09b8\u09c7\u0987 \u09a6\u09c7\u0996\u09c7 \u09a4\u09c1\u09ae\u09bf \u09ae\u09cb\u09ac\u09be\u0987\u09b2 \u099f\u09bf\u09aa\u099b\u09cb !    \u0986\u09b0\u09c7    \u0986\u09ae\u09bf\u09a4\u09cb     \u09ac\u0987\u0987    \u09aa\u09dc\u099b\u09bf\u09b2\u09be\u09ae ", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The meme is not hateful, it is just a funny picture of a man with a caption in a foreign language.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/Bangla Thug Life (223).jpg", "text": "\u09e8\u09e6\u09e6 \u099f\u09be\u0995\u09be \u09ac\u09bf\u0995\u09be\u09b6 \u0995\u09b0\u09c7 \u09af\u0996\u09a8 \u0987\u09ae\u09c1 \u09b8\u09c7\u0995\u09cd\u09b8 \u0995\u09b0\u09a4\u09c7 \u09aa\u09be\u09b0\u09bf\u09a8\u09be   paise barbaad bhench*d ", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The meme is a picture of a man with his arms up, and the caption reads "300 french words" in the background.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/CM (475).jpg", "text": "\u09ac\u09be\u09b8\u09be\u09b0 \u099b\u09cb\u099f \u099b\u09c7\u09b2\u09c7 \u0995\u09bf\u099b\u09c1 \u099a\u09be\u0993\u09df\u09be\u09b0 \u09aa\u09b0 \u09ac\u09be\u09ac\u09be - \u09ae\u09be     \u09ac\u09be\u09b8\u09be\u09b0 \u09ac\u09dc \u099b\u09c7\u09b2\u09c7 \u0995\u09bf\u099b\u09c1 \u099a\u09be\u0993\u09df\u09be\u09b0 \u09aa\u09b0 \u09ac\u09be\u09ac\u09be - \u09ae\u09be ", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The image is a meme that is not hateful, it is a picture of two men with a caption that is not hateful.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/chintashil (512).jpg", "text": "PQ<AB \u09b9\u0993\u09df\u09be\u09df PQ \u098f\u0995\u099f\u09bf \u099c\u09cd\u09af\u09be     \u0985\u09a4\u098f\u09ac, \u0986\u09ae\u09be\u09b0 \u09ae\u09a7\u09c1 \u09ac\u09cd\u09af\u09be\u09b8-\u098f \u09a8\u09df \u09b8\u09cd\u09af\u09be\u09b0 ", "label": 1}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The meme is not hateful, it is just a funny picture of a man with a circle around his head. The text is in a foreign language, but the meme is not hateful.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/KAM (70).png", "text": "\u09ac\u09cd\u09b0\u09be\u099c\u09bf\u09b2\u09c7\u09b0  \u099c\u09be\u09b0\u09cd\u09b8\u09bf \u09b9\u09b2\u09c1\u09a6, \u09a4\u09be\u0987 \u09a4\u09b0\u0995\u09be\u09b0\u09bf\u09a4\u09c7 \u09b9\u09b2\u09c1\u09a6 \u0996\u09be\u0993\u09df\u09be \u099b\u09be\u0987\u09dc\u09be \u09a6\u09bf\u09b8\u09bf! \u09ac\u09bf\u09df\u09be \u09ac\u09be\u09dc\u09bf\u09b0 \u09aa\u09cd\u09af\u09be\u09a8\u09cd\u09a1\u09c7\u09b2 \u09a8\u09c0\u09b2 \u09b8\u09be\u09a6\u09be \u09b9\u0987\u09b2\u09c7 \u0993\u0987 \u09ac\u09be\u09dc\u09bf\u09a4\u09c7 \u09a6\u09be\u0993\u09df\u09be\u09a4 \u0996\u09be\u09ae\u09c1 \u09a8\u09be!", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The meme is not hateful, it is just a funny picture of two men with a caption that is not meant to be offensive.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/Bangla Thug Life (417).jpg", "text": "\u09a6\u09c1\u0987 \u098f\u0995\u09c7 \u09a6\u09c1\u0987    \u099a\u09b2\u09cb \u0986\u09ae\u09b0\u09be \u09b6\u09c1\u0987 ", "label": 1}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The meme is a quote from a movie, and it is not hateful. It is a quote from a movie and it is not hateful.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/CM (240).jpg", "text": "\u09af\u0996\u09a8 \u0995\u09cb\u09a8 \u09ac\u09a8\u09cd\u09a7\u09c1 \u09ae\u09cb\u09b8\u09cd\u09a4\u09ab\u09be \u0997\u09c7\u09ae \u0995\u09c7   Cadillacs and Dinosaurs  \u0990 \u09a8\u09be\u099f\u0995\u09c0\u09b0 \u09aa\u09cb , \u0987\u0982\u09b0\u09c7\u099c\u09c0 \u09ae\u09be\u09b0\u09be\u09ac\u09bf\u09a8\u09be \u0964 ", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The meme is a picture of two men, one pointing at the other, with the caption "Hateful or Not Hateful?" in Bengali.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/bamboo-vaiya (273).jpg", "text": "\u0998\u09c1\u09b0\u09be\u0998\u09c1\u09b0\u09bf\u09b0  \u09aa\u09b0 \u09af\u0996\u09a8 \u09a4\u09c3\u09b7\u09cd\u09a3\u09be\u09b0\u09cd\u09a5 \u0995\u09be\u0995 \u0995\u09b2\u09b8\u09bf\u09a4\u09c7 \u09aa\u09be\u09a8\u09bf \u09a6\u09c7\u0996\u09a4\u09c7 \u09aa\u09be\u09df ", "label": 1}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The image is a meme that is not hateful, it is a picture of four women with a caption that is not hateful.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/KAM (25).png", "text": "\u099c\u09b2\u09bf\u09b2 \u09ac\u09b2\u09cb \u09a4\u09cb \u09a4\u09be\u099c\u09ae\u09b9\u09b2 \u0995\u09c7 \u09a4\u09c8\u09b0\u09bf \u0995\u09b0\u09c7\u099b\u09bf\u09b2? \u09ae\u09bf\u09b8\u09cd\u09a4\u09cd\u09b0\u09bf\u09b0\u09be", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The image is a meme that is not hateful, it is a picture of two people with a map in the background.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/KAM (163).jpg", "text": "\u09b8\u09be\u0995\u09bf\u09ac \u09af\u09a6\u09bf \u098f\u0987 \u09ac\u09bf\u09b6\u09cd\u09ac\u09c7\u09b0 \u09b8\u09c7\u09b0\u09be \u0985\u09b2\u09b0\u09be\u0989\u09a8\u09cd\u09a1\u09be\u09b0 \u09b9\u09df \u099c\u09be\u09a6\u09c7\u099c\u09be \u098f\u0987 \u09ae\u09b9\u09be\u09ac\u09bf\u09b6\u09cd\u09ac\u09c7\u09b0 \u09b8\u09c7\u09b0\u09be \u0985\u09b2\u09b0\u09be\u0989\u09a8\u09cd\u09a1\u09be\u09b0!!!\u099c\u09be\u09a6\u09c7\u099c\u09be\u09b0\u09c7 \u09a0\u09bf\u0995 \u099a\u09bf\u09a8\u09bf \u09a8\u09be \u0995\u09bf\u09a8\u09cd\u09a4\u09c1 \u0986\u09b8\u09b2 \u0995\u09a5\u09be \u09b9\u09b2 \u0985\u09a8\u09cd\u09af \u0997\u09cd\u09b0\u09b9\u09c7 \u0995\u09cd\u09b0\u09bf\u0995\u09c7\u099f\u09be\u09b0 \u0986\u09ac\u09bf\u09b7\u09cd\u0995\u09be\u09b0 \u0995\u0987\u09b0\u09be\u0993 \u09a8\u09cb\u09ac\u09c7\u09b2 \u09aa\u09be\u0987\u09b2\u09c7\u09a8 \u09a8\u09be \u0995\u09c7\u09a8???", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The image is a meme that is not hateful, it is a political joke that is not meant to harm or denigrate any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/TR (291).jpg", "text": "  \u09ac\u09bf\u09b2\u09c1\u09aa\u09cd\u09a4 \u0995\u09bf\u099b\u09c1 \u099c\u09bf\u09a8\u09bf\u09b8   \u09a1\u09be\u0987\u09a8\u09cb\u09b8\u09b0    \u09b9\u09be\u09b0\u09bf\u0995\u09c7\u09a8    \u0995\u09cd\u09af\u09be\u09b8\u09c7\u099f     \u099c\u09b8\u09bf\u09ae  \u09ae\u09c7\u09b2\u09be   ", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The image is a collage of four different pictures, including a dinosaur, a lantern, a cassette tape, and a person. The caption is written in Bengali, which is a language spoken in Bangladesh.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/ovodro_img (23).jpg", "text": "\u098f\u09a4 \u099c\u09cd\u09af\u09be\u09ae \u0964 \u0995\u09c0 \u0995\u09b0\u09ac \u09ac\u09c1\u099d\u09a4\u09c7 \u09aa\u09be\u09b0\u099b\u09bf \u09a8\u09be \u0964   \u098f\u0995\u099f\u09c1 \u09a4\u09c7\u09b2 \u09b2\u09be\u0997\u09bf\u09df\u09c7 \u09a8\u09be\u0993 ", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The meme is a comic strip with a man driving a car and a woman in the passenger seat. The caption is in a foreign language, possibly Hindi.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/tangaila (163).jpg", "text": "\u09ac\u09be\u0982\u09b2\u09be\u09a6\u09c7\u09b6\u09c7 \u0995\u09bf \u09a6\u09c7\u0996\u09b2\u09be ??  \u098f\u0996\u09be\u09a8\u09c7 \u09ae\u09be \u0995\u09c7 \u09ac\u09cd\u09b2\u0995 \u09b2\u09bf\u09b8\u09cd\u099f\u09c7 \u09b0\u09c7\u0996\u09c7 \u09aa\u09cb\u09b8\u09cd\u099f \u0995\u09b0\u09c7 \"\u09b2\u09be\u09ad\u09bf\u0993 \u09ae\u09be\" ", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The meme is a picture of a man talking on a cell phone with a woman in the background. The caption reads "hateful if it explicitly intends to denigrate, vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status."
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/TR (563).jpg", "text": "\u0985\u09ae\u09c1\u0995\u09c7\u09b0 \u09b0\u09b6\u09bf    \u09a4\u09ae\u09c1\u0995\u09c7\u09b0 \u09b0\u09b6\u09bf   \u0985\u09ae\u09c1\u0995\u09c7\u09b0 \u099a\u09b0    \u09a4\u09ae\u09c1\u0995\u09c7\u09b0 \u09a1\u09be\u0999\u09cd\u0997\u09c0   \u0985\u09ae\u09c1\u0995\u09c7\u09b0 \u09a1\u09be\u0999\u09cd\u0997\u09be    \u09b8\u09a6\u09b0\u09aa\u09c1\u09b0 ", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The image is a meme that is not hateful, it is a group of people celebrating a birthday.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/chintashil (956).jpg", "text": "Imagine doing Mehjabin cosplay    at a court trial ", "label": 1}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The two meme posters are both about a court trial, one is hateful and the other is not.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/CM (109).jpg", "text": "Random guy with mic in front of mosque :    \u098f\u0987 \u09af\u09c7 \u098f\u0987 \u09ae\u09a7\u09c1 \u099f\u09be \u0996\u09c1\u09b2\u09a8\u09be\u09b0 \u098f\u0995\u09a6\u09ae \u09e7\u09e6\u09e6% \u0996\u09be\u099f\u09bf \u09ae\u09a7\u09c1 ;   \u098f\u09a4\u09c7 \u0995\u09cb\u09a8 \u09ad\u09c7\u099c\u09be\u09b2 \u09a8\u09be\u0987*    \u09a8\u09be\u09ae\u09be\u099c \u09b6\u09c7\u09b7 \u0995\u09b0\u09c7 \u0986\u09b8\u09be \u09b2\u09cb\u0995\u099c\u09a8 -    ", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The image is a meme that is not hateful, it is a movie scene with a caption in a foreign language.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/tangaila (264).jpg", "text": "\u099a\u09b2\u09c7 \u098f\u09b2\u09be\u09ae ", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The meme is not hateful, it is not intended to denigrate, vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/TR (373).jpg", "text": "\u09ab\u09be\u09a4\u09c7\u09ae\u09be\u09b0 \u09a7\u09b0\u09cd\u09b7\u09a3\u0995\u09be\u09b0\u09c0 \u099c\u09be\u09a8\u09cb\u09df\u09be\u09b0\u0995\u09c7 \u09aa\u09c1\u09b2\u09bf\u09b6 \u09ac\u09a8\u09cd\u09a6\u09c1\u0995\u09af\u09c1\u09a6\u09cd\u09a7\u09c7 \u09ae\u09c7\u09b0\u09c7 \u09ab\u09c7\u09b2\u09be\u09b0 \u09aa\u09b0     \u09ab\u09b0\u09bf\u09a6\u09aa\u09c1\u09b0\u09ac\u09be\u09b8\u09c0    \u09ab\u09b0\u09bf\u09a6\u09aa\u09c1\u09b0 \u099c\u09c7\u09b2\u09be \u09aa\u09c1\u09b2\u09bf\u09b6   \u09ab\u09b0\u09bf\u09a6\u09aa\u09c1\u09b0\u09ac\u09be\u09b8\u09c0   ", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The image is a meme that is not hateful, but it is a meme that is hateful. The meme is a picture of a man with his arms outstretched, and it is not hateful.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/direct-offense (14).jpg", "text": "I Love You \u09b0\u09be\u09a4 \u09aa\u09c7\u09b0\u09bf\u09df\u09c7 \u09b9\u09ac\u09c7 \u09ad\u09cb\u09b0 \u098f\u09ae\u09a8 \u099c\u09cb\u09b0 \u0986\u099b\u09c7 \u09a4\u09cb\u09b0 chance \u09a6\u09bf\u09df\u09c7 \u09a6\u09c7\u0996\u09cb \u09ac\u09be\u09dc\u09be \u099a\u09bf\u09ce\u0995\u09be\u09b0 \u09b6\u09c1\u09a8\u09ac\u09c7 \u09b8\u09be\u09b0\u09be \u09aa\u09be\u09dc\u09be ", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The meme is not hateful, it is just a funny comic strip with a caption that says "if it love you."
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/ovodro_img (1380).jpg", "text": "\u0995\u09c0 \u09a6\u09c7\u0996\u099b\u09bf\u09b8 BSDK  ? \u0986\u0999\u09cd\u0997\u09c1\u09b2 \u09ae\u09be\u09b0\u099b\u09bf \u09a8\u09be \u09ab\u09be\u0981\u0995\u09be \u09b2\u09be\u0987\u09ac\u09cd\u09b0\u09c7\u09b0\u09bf\u09a4\u09c7    Gun \u09b2\u09cb\u0995\u09be\u09a4\u09c7 \u0997\u09bf\u09df\u09c7 \u09ae\u09c7\u0987\u09a8 \u09aa\u09df\u09c7\u09a8\u09cd\u099f\u09c7 \u09a1\u09c1\u0995\u09c7 \u0997\u09cd\u09af\u09be\u099b\u09c7 ", "label": 1}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The woman in the picture is looking down and is not smiling. The text in the picture is in a foreign language, possibly Hindi.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/KAM (130).png", "text": "\"\u0986\u09ab\u0997\u09be\u09a8\u09bf\u09b8\u09cd\u09a4\u09be\u09a8\u09c7\u09b0 \u0993\u09aa\u09b0 \u0995\u09cb\u09a8\u09cb \u099a\u09be\u09aa \u09a8\u09c7\u0987 \u09b8\u09ac \u099a\u09be\u09aa \u09ac\u09be\u0982\u09b2\u09be\u09a6\u09c7\u09b6\u09c7\u09b0 \u0993\u09aa\u09b0\u0964 \u0995\u09c7\u09a8\u09a8\u09be, \u098f\u09b0\u0987 \u09ae\u09a7\u09cd\u09af\u09c7 \u098f\u09b6\u09bf\u09df\u09be \u0995\u09be\u09aa\u09c7 \u0986\u09ae\u09b0\u09be \u09a4\u09be\u09a6\u09c7\u09b0\u0995\u09c7 \u09b9\u09be\u09b0\u09bf\u09df\u09c7\u099b\u09bf\u0964\" \u09a6\u09c7\u0996\u09be \u09af\u09be\u09ac\u09c7!", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The meme is not hateful, it is just a funny picture of a man with a hat on.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/ovodro_img (1366).jpg", "text": "\u09ac\u09c1\u09a8\u09cb \u0993\u09b2     \u09ac\u09be\u0998\u09be \u09a4\u09c7\u0981\u09a4\u09c1\u09b2 ", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The image is a meme that is not hateful, it is just a picture of two men playing cricket with the caption 'hateful' in the background.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/TR (369).jpg", "text": "Me: pic tolar jonno vlo place kothay j pai  \u09ae\u09a8\u09cd\u09a4\u09cd\u09b0\u09c0\u09b0 \u09ac\u09be\u09dc\u09bf     \u0986\u09ae\u09bf \u099a\u09b2\u09c7 \u098f\u09b8\u09c7\u099b\u09bf  ", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The meme is not hateful, it is just a funny conversation between two men. The meme is not hateful, it is just a funny conversation between two men.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/chintashil (384).jpg", "text": "*\u09b6\u09ac\u09cd\u09a6 \u09aa\u09c7\u09df\u09c7 \u09a8\u09bf\u099c\u09c7 \u09a8\u09bf\u099c\u09c7 \u0989\u09a0\u09c7 \u09af\u09be\u0993\u09df\u09be \u09e7\u09e6\u09ac/\u09ac \u0986\u09ae\u09bf    *\u0986\u09ae\u09be\u0995\u09c7 \u09a8\u09be \u09a1\u09c7\u0995\u09c7 \u09b8\u09c7\u09b9\u09b0\u09bf \u0995\u09b0\u09a4\u09c7 \u09a5\u09be\u0995\u09be \u09aa\u09b0\u09bf\u09ac\u09be\u09b0\u09c7\u09b0 \u09b2\u09cb\u0995\u099c\u09a8 ", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The image is a meme that is not hateful, it is a quote from a movie. The quote is from the movie The Undertaker, and it is not hateful.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/TR (226).jpg", "text": "\u09ac\u09a8\u09cd\u09a7\u09c1\u09b0 \u0996\u09be\u09a4\u09be \u09a6\u09c7\u0996\u09c7 \u09a6\u09c7\u0996\u09c7 \u09e8 \u09aa\u09c3\u09b7\u09cd\u09a0\u09be\u09b0 \u09ac\u09bf\u09b6\u09be\u09b2 \u0985\u0982\u0995 \u0995\u09b0\u09be\u09b0 \u09aa\u09b0 \u09ac\u09a8\u09cd\u09a7\u09c1 \u09ac\u09b2\u09c7 \" \u09ae\u09be\u09ae\u09cd\u09ae\u09be \u0995\u09be\u0987\u099f\u09cd\u099f\u09be \u09a6\u09c7 \u09ad\u09c1\u09b2 \u09b9\u0987\u099b\u09c7 \"      ", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The image is a meme that is not hateful, it is a picture of a woman with a caption that is not hateful.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/ovodro_img (817).jpg", "text": "\u09af\u0996\u09a8 \u09b8\u09ac\u09be\u09b0 \u0998\u09b0\u09c7 \u09b0\u09c7\u09a1\u09bf\u0993 \u09a8\u09be \u09a5\u09be\u0995\u09b2\u09c7\u0993 \u09ac\u09bf\u09b0\u09c7\u09a8\u09cd\u09a6\u09cd\u09b0 \u09a6\u09be\u09a6\u09c1\u09b0 \u09ae\u09c1\u0996\u09c7\u09b0 \u09ae\u09b9\u09be\u09b2\u09df\u09be \u09a0\u09bf\u0995\u0987 \u09b6\u09c1\u09a8\u09c7 \u09a8\u09c7\u09df    \u09ac\u09bf\u09b0\u09c7\u09a8\u09cd\u09a6\u09cd\u09b0 \u09a6\u09be\u09a6\u09c1 :   I'm still worthy !", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The meme is a picture of a man with a hammer, and the caption is in a foreign language. The meme is not hateful, but it is not hateful either.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/ovodro_img (1039).jpg", "text": "\u0986\u09ae\u09bf \u09ab\u09be\u0995\u09ac\u09df    \u0986\u099c\u0995\u09c7 \u0986\u09ae\u09be\u09b0 \u09ac\u09cd\u09b0\u09c7\u0995\u0986\u09aa \u09b9\u09df\u09c7\u099b\u09c7    \u0986\u09ae\u09bf \u09a4\u09cb \u09a4\u09cb\u09b0 \u09ac\u09c7\u09b8\u09cd\u099f\u09ab\u09cd\u09b0\u09c7\u09a8\u09cd\u09a1 \u09ac\u09b2 ", "label": 1}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The meme is not hateful, it is just a funny picture of a woman with a funny caption.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/ovodro_img (140).jpg", "text": "Don't compare these legend    with these ultra legend ", "label": 1}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The two women in the picture are both wearing glasses, and the caption reads 'don't compare this legend with with this legend.' The two women are not the same person, but the caption is suggesting that they are similar in some way.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/chintashil (957).jpg", "text": "\u09ae\u09b8\u099c\u09bf\u09a6\u09c7 \u0995\u09be\u09b2 \u09b6\u09bf\u09b0\u09a8\u09bf \u0986\u099b\u09bf\u09b2 , \u0985\u09a2\u09c7\u09b2 \u0997\u09cb\u09b8\u09cd\u09a4 \u09b0\u09c1\u099f\u09bf - \u09ac\u09be\u099a\u09bf\u09df\u09be \u0997\u09bf\u09df\u09be\u099b\u09c7 , \u09ae\u09cb\u09b2\u09cd\u09b2\u09be \u09b8\u09be\u09b9\u09c7\u09ac \u09b9\u09c7\u09b8\u09c7 \u09a4\u09be\u0987 \u0995\u09c1\u099f\u09bf \u0995\u09c1\u099f\u09bf    \u09ae\u09cb\u09b2\u09cd\u09b2\u09be :-  ", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The meme is not hateful, it is just a funny picture of an old man with a green hat on.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/chintashil (686).jpg", "text": "Cameraman after realising they won't be able to capture the Pakistani fangirls anymore", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The meme is not hateful, it is just a joke. The person in the picture is wearing headphones and is listening to music while using a camera to capture the Pakistani fans. The caption is a reference to the fact that the person is not actually filming the Pakistani fans, but is pretending to do so.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/bamboo-vaiya (280).jpg", "text": "Gonna tell my kids that he is a  \u09b8\u09be\u09aa\u09cb\u099c\u09bf\u099f\u09be\u09b0 (\u09a1\u09cb\u099c)  ", "label": 1}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The meme is a picture of a man with a beard and a caption that says 'Gonna tell my kids that he is a hateful person.' The meme is not hateful, but it is a joke.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/KAM (51).jpg", "text": "\u098f\u09a4\u09cb \u0995\u09b7\u09cd\u099f \u0995\u09c7\u09a8 \u09ad\u09be\u09b2\u09ac\u09be\u09b8\u09be? \u09ad\u09be\u09b2\u09ac\u09be\u09b8\u09a4\u09c7 \u0995\u0987\u099b\u09c7 \u0995\u09c7\u09a1\u09be? ", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The image is a meme that is not hateful, it is a funny picture of a man singing into a microphone with a caption that is not hateful.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/Bangla Thug Life (100).jpg", "text": "Before being \u09ac\u0989\u09a6\u09bf    After being \u09ac\u0989\u09a6\u09bf ", "label": 1}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The image is a meme that is not hateful, it is just a before and after picture of a woman. The meme is not hateful, it is just a funny joke.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/KAM (167).jpg", "text": "YOU R MY GOOD-HOUSE \u09ae\u09be\u09a8\u09c7!!!\u098f\u099f\u09be \u0986\u09ac\u09be\u09b0 \u0995\u09bf\u09b0\u0995\u09ae \u0995\u09a5\u09be???\u09ae\u09be\u09a8\u09c7 \u09a4\u09c1\u09ae\u09bf \u0986\u09ae\u09be\u09b0 \u09ad\u09be\u09b2\u09cb\u09ac\u09be\u09b8\u09be", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The image is a meme that is not hateful, it is a funny and lighthearted image.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/ovodro_img (1238).jpg", "text": "Not a meme , just a picture of Ashutosh College's Freshers' Party ", "label": 1}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The meme is a picture of a woman in a dance pose, with the caption "not a meme, just a picture of Ashu's college freshers' party." The meme is not hateful, but it is not hateful either.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/TR (546).jpg", "text": "\u09aa\u09c2\u09b0\u09cd\u09ac\u09c7\u09b0 \u09ad\u09be\u0999\u09cd\u0997\u09be \u0997\u09cb\u09b2 \u099a\u09a4\u09cd\u09ac\u09b0        \u09ac\u09b0\u09cd\u09a4\u09ae\u09be\u09a8\u09c7 \u09ad\u09be\u0999\u09cd\u0997\u09be \u0997\u09cb\u09b2 \u099a\u09a4\u09cd\u09ac\u09b0  ", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The meme is a picture of a man with a sad face, and the caption is in a foreign language. The meme is not hateful, but it is not hateful either.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/Bangla Thug Life (286).jpg", "text": "\u09b9\u09be\u09b2\u0995\u09be \u09ac\u09c3\u09b7\u09cd\u099f\u09bf \u09b6\u09c1\u09b0\u09c1 \u09b9\u0993\u09df\u09be \u09ac\u09bf\u09a6\u09cd\u09af\u09ae\u09be\u09a8   Horny bhabi to her husband:", "label": 1}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The meme is a picture of a woman with a caption that is not hateful. It is a meme that is not hateful.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/ovodro_img (755).jpg", "text": "\u098f\u0995\u099c\u09a8 \u09ae\u09c7\u09df\u09c7 \u09ac\u09b0\u09be\u09ac\u09b0\u0987 \u09a4\u09be\u09b0 \u09ac\u09be\u09a8\u09cd\u09a7\u09ac\u09c0\u09b0 \u09b8\u09be\u09a5\u09c7 ICE CREAM  \u09ad\u09be\u0997 \u0995\u09b0\u09c7 \u0996\u09c7\u09a4\u09c7 \u09ad\u09be\u09b2\u09ac\u09be\u09b8\u09cb ! ", "label": 1}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The image is a meme that is not hateful, it is a picture of two women kissing and eating ice cream.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/ovodro_img (1408).jpg", "text": "\u09ac\u09dc \u0995\u09bf\u099b\u09c1 \u09a6\u09c7\u0996\u09be\u09b0 \u09b9\u09be\u09b8\u09bf \u09b2\u09c1\u0995\u09bf\u09df\u09c7 \u09b0\u09be\u0996\u09be \u09af\u09be\u09df \u09a8\u09be ***  ", "label": 1}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The image is a meme that is not hateful, it is a woman smiling in the ocean with a caption that says 'hateful'.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/ovodro_img (478).jpg", "text": "\u098f\u0995\u09bf \u099f\u09a8\u09bf \u09b8\u09cd\u099f\u09be\u09b0\u09cd\u0995 \u09a4\u09c1\u0987 \u09ac\u09c7\u0981\u099a\u09c7 \u0986\u099b\u09bf\u09b8 !  \u09a4\u09be\u09b9\u09b2\u09c7 \u09a4\u09c3\u09a8\u09ae\u09c1\u09b2\u09c7\u09b0 \u09b9\u09df\u09c7 \u09ad\u09cb\u099f\u09c7 \u09a6\u09be\u09dc\u09be\u09ac\u09bf \u09a4\u09c1\u0987\u0993    \u098f\u09ac\u09be\u09b0 \u0986\u09b0 \u09ac\u09be\u0981\u099a\u09a4\u09c7 \u099a\u09be\u0987 \u09a8\u09be ", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The image is a meme that is not hateful, it is a comic strip with a caption in Hindi.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/Bangla Thug Life (198).jpg", "text": "\u098f\u0987 \u09a4\u09c1\u09ae\u09bf \u0995\u09bf \u0997\u09be\u0981\u099c\u09be ?    \u0995\u09be\u09b0\u09a3 \u0986\u09ae\u09bf \u09a4\u09cb\u09ae\u09be\u0995\u09c7 \u0996\u09c7\u09a4\u09c7 \u099a\u09be\u0987 ", "label": 1}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The meme is not hateful, it is just a funny picture of a dog with a caption in a foreign language.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/Bangla Thug Life (97).jpg", "text": "\u09af\u0996\u09a8 \u0995\u09cb\u09a8\u09cb \u09b8\u09c1\u09a8\u09cd\u09a6\u09b0\u09c0 \u09ae\u09c7\u09df\u09c7 \u09aa\u09bf\u0995 \u098f \u09b2\u09be\u09ad \u09a6\u09c7\u09df   \u098f\u0987 \u09ae\u09c7\u09df\u09c7\u099f\u09be\u0995\u09c7 \u0986\u09ae\u09be\u09b0 \u09ac\u09bf\u09df\u09c7 \u0995\u09b0\u09a4\u09c7\u0987 \u09b9\u09ac\u09c7", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The image is a meme that is not hateful, it is a funny picture of a man in an orange shirt with a caption in a foreign language.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/bamboo-vaiya (336).jpg", "text": "Nibba: \u0998\u09c1\u09ae\u09a8\u09cd\u09a4 \u0985\u09ac\u09b8\u09cd\u09a5\u09be\u09df \u09a4\u09cb\u09ae\u09be\u0995\u09c7 \u09b8\u09ac\u09a5\u09c7\u0995\u09c7 \u09ac\u09c7\u09b6\u09bf \u09b8\u09c1\u09a8\u09cd\u09a6\u09b0 \u09b2\u09be\u0997\u09c7 \u0964  Nibbi :    ", "label": 1}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: A woman is laying in bed with a pillow and a caption that says "nibi" in the background. The caption is a meme that is not hateful.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/bamboo-vaiya (429).jpg", "text": "~he \u09af\u09a6\u09bf him \u09b9\u09df,, She \u0995\u09c7\u09a8\u09cb Shim \u09b9\u09df \u09a8\u09be ? ~\u09b6\u09bf\u09ae\u09c7\u09b0 \u09a4\u09cb \u09ac\u09bf\u099a\u09bf \u09a5\u09be\u0995\u09c7,", "label": 1}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The meme is a quote from a movie, and it is not hateful.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/bamboo-vaiya (525).jpg", "text": "*Anushka and Kohli*   *Kid inside*", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The image is a meme that is not hateful, it is a funny and lighthearted moment between two people.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/Halal Memes (164).jpg", "text": "\u09ac\u09bf\u09df\u09c7-\u09b6\u09be\u09a6\u09bf\u09b0 \u09b8\u09bf\u099c\u09a8\u09c7 \u09af\u0996\u09a8 \u09b0\u09c1\u09ae \u09b6\u09c7\u09df\u09be\u09b0 \u0995\u09b0\u09a4\u09c7 \u09b9\u09df      \u0986\u09ae\u09bf    \u09ae\u09c7\u09b9\u09ae\u09be\u09a8 ", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The meme is not hateful, it is just a funny picture of two cats.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/tangaila (109).jpg", "text": "\u09af\u0996\u09a8 \u0985\u099f\u09cb\u09a4\u09c7 \u0995\u09cb\u09a8\u09cb \u09ae\u09c7\u09df\u09c7 \u0989\u09a0\u09c7 \u0986\u09b0 \u0986\u09ae\u09be\u0995\u09c7 \u09b8\u09be\u09ae\u09a8\u09c7 \u099a\u09b2\u09c7 \u09af\u09c7\u09a4\u09c7 \u09b9\u09df    Me:-", "label": 1}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The meme is a picture of a man with a sad face and the caption "me" in a foreign language. The meme is not hateful, but it is not hateful either.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/Memeholics (179).jpg", "text": "\u09ac\u09bf\u09df\u09c7\u09a4\u09c7 \u09ae\u09c7\u09b9\u09ae\u09be\u09a8\u0997\u09a8 :  \u0996\u09be\u09ac\u09be\u09b0 \u098f\u0995\u099f\u09c1 \u0993 \u09ad\u09be\u09b2\u09cb \u09b9\u09df \u09a8\u09be\u0987     Also them: ", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The meme is not hateful, it is just a group of people eating together.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/Memeholics (103).jpg", "text": "\u09af\u0996\u09a8 \u09a4\u09c1\u09ae\u09bf \u09ab\u09c7\u09b8\u09ac\u09c1\u0995\u09c7 \u09aa\u09cb\u09b8\u09cd\u099f \u09a6\u09bf\u09df\u09c7 , \u09b2\u0997\u0986\u0989\u099f \u09b9\u09df\u09c7 \u09b8\u09c1\u0987\u09b8\u09be\u0987\u09a1 \u0995\u09b0\u09cb \u0995\u09bf\u09a8\u09cd\u09a4\u09c1 \u09aa\u09cd\u09b0\u09be\u0987\u09ad\u09c7\u09b8\u09bf \u0985\u09a8\u09b2\u09bf \u09ae\u09bf \u09a5\u09c7\u0995\u09c7 \u09aa\u09be\u09ac\u09b2\u09bf\u0995 \u0995\u09b0\u09a4\u09c7 \u09ad\u09c1\u09b2\u09c7 \u09af\u09be\u0993 : ", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The image is a meme that is not hateful, it is a cartoon of a man with a mustache and a fire behind him. The caption is in a foreign language, but the image itself is not hateful.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/Memeholics (157).jpg", "text": "\u0986\u09aa\u09a8\u09c7 \u09a4\u09cb \u099a\u09c7\u09b2\u099a\u09c7\u09b2\u09be\u09df\u09be \u09ac\u09c7\u09b9\u09c7\u09b8\u09cd\u09a4\u09c7 \u09af\u09be\u0987\u09ac\u09c7\u09a8 !! ", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The meme is not hateful, it is just a funny picture of two men sitting together.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/bamboo-vaiya (287).jpg", "text": "Kids are now a days :    When I was a Kid : ", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The meme is not hateful, it is just a funny picture of kids with balloons.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/KAM (127).png", "text": "\u09b6\u09c1\u09a7\u09c1 \u09b6\u09c1\u09a7\u09c1 \u0995\u09cb\u099a\u09c7\u09b0 \u09b8\u09be\u09a5\u09c7 \u099d\u09dc\u0997\u09be \u0995\u09b0\u09c7 \u09ec \u09ae\u09be\u09b8 \u098f\u09b0 \u09ac\u09cd\u09af\u09be\u09a8 \u098f\u09b0 \u09a5\u09c7\u0995\u09c7 \u09ad\u09be\u09b2\u09cb \u098f\u0995\u099f\u09be \u09a6\u09bf\u09df\u09c7 \u09ea \u09ae\u09be\u09b8\u09c7\u09b0 \u09ac\u09be\u09a8 \u0996\u09c7\u09a4\u09be\u09ae", "label": 1}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The image is a meme that is not hateful, it is a sports poster with a man in it.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/tangaila (345).jpg", "text": "\u09ac\u09be\u09a8\u09bf\u099c\u09cd\u09af \u09ae\u09c7\u09b2\u09be   \u099f\u09be\u0982\u0997\u09be\u0987\u09b2\u09be \u09aa\u09bf\u09aa\u09b2\u09b8 ", "label": 1}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The image is a meme that is not hateful, but it is a meme that is not hateful.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/ovodro_img (885).jpg", "text": "\u09af\u0996\u09a8 \u09b8\u09c7 \u09ae\u09b8\u09cd\u09a4\u09be\u09a8 \u09a5\u09be\u0995\u09c7 **  \u09e8\u09e6 \u09ac\u099b\u09b0 \u09aa\u09b0 \u09af\u0996\u09a8 \u09b0\u09be\u099c\u09a8\u09c0\u09a4\u09bf \u0995\u09b0\u09a4\u09c7 \u09b6\u09c1\u09b0\u09c1 \u0995\u09b0\u09c7 ", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The meme is not hateful, it is just a funny picture of two men with different facial expressions.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/bamboo-vaiya (66).jpg", "text": "\u0995\u09cb\u09b0\u09ac\u09be\u09a8\u09bf\u09b0 \u09b9\u09be\u099f \u09a5\u09c7\u0995\u09c7 \u099c\u09c7\u09ac\u09cd\u09b0\u09be \u0995\u09bf\u09a8\u09c7 \u0986\u09a8\u09b2\u09c7\u09a8 \u09b6\u09cd\u09b0\u09a6\u09cd\u09a7\u09c7\u09df \u0987\u09b2\u09bf\u09df\u09be\u09b8 \u0995\u09be\u099e\u09cd\u099a\u09a8 \u0964", "label": 1}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The image is a meme that is not hateful, it is a picture of a man and a woman posing for a picture.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/TR (519).jpg", "text": "\u09ad\u09be\u0987 CSE \u09a4\u09c7 \u09aa\u09b0\u09c7\u09a8 ?     \u09b9\u09c1\u09ae \u0995\u09c7\u09a8 !     \u0997\u09b0\u09c1 \u09ac\u09c7\u09aa\u09be\u09b0\u09c0\u09b0 \u09ac\u09cd\u09af\u09be\u0982\u0995 \u098f\u0995\u09be\u0989\u09a8\u09cd\u099f \u09b9\u09cd\u09af\u09be\u0995 \u0995\u09b0\u09be\u09a4\u09be\u09ae   ", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The meme is a collage of several different images, including a group of men and a man with a shirt that says "hateful". The meme is not hateful, but it is a humorous and lighthearted way to express a point.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/netflix (39).jpg", "text": "\u0986\u09ae\u09bf \u0995\u09cd\u09b0\u09be\u09b6\u09c7\u09b0 \u09b8\u09ac \u09aa\u09cb\u09b8\u09cd\u099f\u09c7 \u09b2\u09be\u09ad \u09b0\u09bf\u09df\u09cd\u09af\u09be\u0995\u09cd\u099f \u09a6\u09c7\u0987     \u09a4\u09be\u0995\u09c7 Wholesome Meme  \u09aa\u09be\u09a0\u09be\u0987    If being cute was a crime you would've been the criminal     \u09ac\u09bf\u09ad\u09bf\u09a8\u09cd\u09a8\u09ad\u09be\u09ac\u09c7 \u09ab\u09cd\u09b2\u09be\u09b0\u09cd\u099f \u0995\u09b0\u09be\u09b0 \u099a\u09c7\u09b7\u09cd\u099f\u09be \u0995\u09b0\u09bf  Khankirpola ar knock dibina kokhono    \u09b9 \u09ad\u09be\u0987 \u09a0\u09bf\u0995\u09bf \u09a7\u09b0\u09b8\u09c7\u09a8 \u0964  \u098f\u09b0\u09aa\u09b0\u0993 \u09b8\u09c7 \u0986\u09ae\u09be\u0995\u09c7 \u09aa\u09be\u09a4\u09cd\u09a4\u09be \u09a6\u09c7\u09df \u09a8\u09be ", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The image is a collage of four different meme images, each with a different caption. The captions are all different, and the meme is not hateful.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/CM (33).jpg", "text": "\u09af\u0996\u09a8 \u09aa\u09cd\u09b0\u09a4\u09bf \u0998\u09a8\u09cd\u099f\u09be\u09df \u09a8\u09bf\u09b6\u09cd\u099a\u09bf\u09a4 \u09ab\u09cb\u09a8 \u099c\u09bf\u09a4\u09be\u09b0 \u099c\u09a8\u09cd\u09af \u0995\u09cb\u0995 \u0996\u09be\u0993 \u0995\u09bf\u09a8\u09cd\u09a4\u09c1 \u0995\u09bf\u099a\u09cd\u099b\u09c1 \u09aa\u09be\u0993\u09a8\u09be   Those bastards lied to me ", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The meme is a picture of a man in a suit standing next to a car. The caption is in a foreign language, but the man is speaking in English. The meme is not hateful, but it is not hateful either.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/chintashil (932).jpg", "text": "\u09b0\u09be\u099c\u09c7\u09a8\u09cd\u09a6\u09cd\u09b0 \u09a6\u09c7\u09b6\u09be\u0987    \u09b0\u09ac\u09c0\u09a8\u09cd\u09a6\u09cd\u09b0 \u09b9\u09be\u09ac\u09c1\u09ad\u09be\u0987 ", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The meme is a comparison between two men, one with a beard and the other without a beard. The caption reads "Hateful or Not Hateful" and the two men are shown side by side.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/chintashil (1028).jpg", "text": "BD Women's football team*   \u0986\u09ae\u09bf \u099c\u09bf\u09a4\u09b2\u09c7 \u099c\u09bf\u09a4\u09c7 \u09af\u09be\u09df \u09ae\u09be   ", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The image is a meme that is not hateful, it is a picture of a woman and a man on a double decker bus with a sign that says 'Bd Women's Football Team'.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/netflix (138).jpg", "text": "He's online    She's online    Nobody talks     Mark Zuckerberg and FBI       Ego:   i've won ", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The meme is not hateful, it is just a funny picture of two baseball players with a caption that says 'he's online, she's nobody talks.'
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/TR (324).jpg", "text": "\u09af\u0996\u09a8 \u0986\u09ae\u09bf \u0985\u09ae\u09cd\u09ac\u09bf\u0995\u09be\u09df \u09af\u09be\u0987 ", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The meme is a picture of a group of people, including a man in a blue shirt, walking down a pathway. The caption is written in Bengali, which is a language spoken in Bangladesh and India. The caption is a quote from a famous Bengali poet, and it is not hateful.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/ovodro_img (223).jpg", "text": "\u09af\u0996\u09a8 \u09ae\u09be \u09b6\u09c0\u09a4\u09c7\u09b0 \u09b8\u09ae\u09df\u09c7\u0993   \u09a0\u09be\u09a8\u09cd\u09a1\u09be \u099c\u09cd\u09ac\u09b2 \u09a6\u09bf\u09df\u09c7 \u09b8\u09cd\u09a8\u09be\u09a8 \u0995\u09b0\u09a4\u09c7 \u09ac\u09b2\u09c7", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: A man in a suit with a red background, with the words 'hateful' and 'not-hateful' in the same image.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/TR (461).jpg", "text": "\u0995\u09bf\u09b0\u09c7 \u099b\u09be\u09a4\u09be\u09b0 \u0987\u099e\u09cd\u099c\u09bf\u09a8\u09bf\u09df\u09be\u09b0    \u09ac\u09b0\u09bf\u09b6\u09be\u0987\u09b2\u09cd\u09b2\u09cd\u09af\u09be    \u09b9\u09c7\u0987 \u0996\u09cd\u09af\u09be\u09a4\u09be\u09b0 \u0997\u09be\u099f\u09cd\u099f\u09bf    \u09ab\u09b0\u09bf\u09a6\u09aa\u09c1\u0987\u09b0\u200d\u09cd\u09af\u09be ", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The image is a meme that is not hateful, it is a comical scene with two men pointing guns at each other.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/bangla-troll (30).jpg", "text": "\u099b\u09cb\u099f\u09ac\u09c7\u09b2\u09be\u09df \u09ac\u09a8\u09cd\u09a7\u09c1\u09a6\u09c7\u09b0 \u09b8\u09ac\u099a\u09c7\u09df\u09c7 \u09ad\u09df\u0999\u09cd\u0995\u09b0 \u09a1\u09be\u09df\u09be\u09b2\u0997  \u09a4\u09c1\u0987 \u0996\u09c7\u09b2\u09be \u09a5\u09c7\u0995\u09c7 \u09ac\u09be\u09a6 ", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The meme is not hateful, it is just a funny picture of a man with a sad face.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/ovodro_img (298).jpg", "text": "Pati fauj mein.. biwi mauj mein ", "label": 1}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The meme is a movie poster with a woman kissing a man, and the caption is a quote from the movie. The quote is a statement about the movie's plot, and it is not hateful or offensive.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/ovodro_img (286).jpg", "text": "\u0996\u09c1\u09c1\u09b6\u09bf\u09b0 \u09b8\u0982\u09ac\u09be\u09a6 \u099f\u09be \u09b6\u09c1\u09a8\u09b2\u09bf \u0964 \u09b0\u09a8\u09ac\u09c0\u09b0 \u0986\u09b0 \u09a6\u09c0\u09aa\u09bf\u0995\u09be\u09b0 \u09ac\u09bf\u09df\u09c7\u099f\u09be \u09b9\u09df\u09c7 \u0997\u09c7\u09b2 \u0964\u0964   \u09a4\u09c1\u0987 \u09a4\u09cb \u098f\u09ae\u09a8 \u09ad\u09be\u09ac\u09c7 \u0996\u09c1\u09b6\u09bf \u09b9\u09df\u09c7\u099b\u09bf\u09b8 \u09af\u09c7\u09a8 \u09a4\u09cb\u09b0 \u09b8\u09be\u09a5\u09c7\u0987 \u09ac\u09bf\u09df\u09c7\u099f\u09be \u09b9\u09df\u09c7\u099b\u09c7    \u0986\u09b0\u09c7 \u0997\u09be\u09a8\u09cd\u09a1\u09c1 \u0993 \u098f\u09a4 \u09a6\u09bf\u09a8 \u09aa\u09c1\u09b0\u09cb \u09ad\u09be\u09b0\u09a4\u09c7\u09b0 \u0995\u09cd\u09b0\u09be\u09b6 \u099b\u09bf\u09b2 \u0964 \u098f\u0996\u09a8 \u09ac\u09bf\u09df\u09c7 \u09b9\u09df\u09c7\u099b\u09c7 \u0985\u09b0\u09cd\u09a5\u09be\u09ce \u09ac\u09cc\u09a6\u09bf \u0964 \u09a4\u09be\u0987 \u0993 \u098f\u0996\u09a8 \u09b6\u09c1\u09a7\u09c1 \u09ac\u09be\u0999\u09be\u09b2\u09c0 \u099b\u09c7\u09b2\u09c7\u09a6\u09c7\u09b0 \u0995\u09cd\u09b0\u09be\u09b6 \u09b9\u09bf\u09b8\u09c7\u09ac\u09c7\u0987 \u09a5\u09be\u0995\u09ac\u09c7 ", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The image is a meme that is not hateful, it is a quote from a movie. The quote is from a movie and is not intended to be hateful.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/bangla-memes (148).jpg", "text": "Work hard untill you don't need to introduce yourself        Brie Larson  Actor/ Mushrrom Forager/ SCUBA / Certified Diver/ Scientific American Subscriber/ Dog MOM / Captain Marvel/ Generally Stoked         Prova  you know who I am.   ", "label": 1}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The meme is a comparison between two women, one of whom is hateful and the other is not. The meme is not hateful, but it is a comparison between two women.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/Memeholics (33).jpg", "text": "Others : Okay thanks, I'll try to change myself.   Me   \u0986\u09ae\u09bf \u098f\u09b0\u0995\u09ae \u0987 ", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The meme is a picture of a woman with glasses and a caption that says 'others, okay, try to change myself.' The meme is not hateful, but it is not hateful either.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/chintashil (236).jpg", "text": "\u09b8\u09cd\u09af\u09be\u09b0 - \u09ac\u09c1\u09b6\u09b0\u09be\u09b0 \u0995\u09be\u099b\u09c7 \u098f\u0995\u099f\u09be \u0995\u09b2\u09be \u0986\u099b\u09c7   Trans named \u09ac\u09c1\u09b6\u09b0\u09be -    \u0995\u09bf \u0986\u09b6\u09cd\u099a\u09b0\u09cd\u09af ! \u0986\u09aa\u09a8\u09bf \u099c\u09be\u09a8\u09b2\u09c7\u09a8 \u0995\u09bf \u0995\u09b0\u09c7 ? ", "label": 1}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The meme is a picture of a woman and a man, with the woman saying something to the man. The meme is not hateful, but it is not hateful either.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/chintashil (457).jpg", "text": "\u09e7\u09eb\u09e6\u09e6 \u099f\u09be\u0995\u09be\u09b0 \u099c\u09be\u09ae\u09be \u09e9\u09e6\u09e6 \u099f\u09be\u0995\u09be\u09df \u09ac\u09bf\u0995\u09cd\u09b0\u09bf \u0995\u09b0\u09a4\u09c7 \u09b0\u09be\u099c\u09bf \u09b9\u09df\u09c7 \u09af\u09be\u0993\u09df\u09be \u09a6\u09cb\u0995\u09be\u09a8\u09a6\u09be\u09b0     \u0986\u09ae\u09cd\u09ae\u09c1     \u09ad\u09cd\u09af\u09be\u09ac\u09be\u099a\u09cd\u09af\u09be\u0995\u09be \u0996\u09c7\u09df\u09c7 \u09af\u09be\u0993\u09df\u09be \u0986\u09ae\u09bf ", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The meme is not hateful, it is just a funny picture of people in a store.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/chintashil (91).jpg", "text": "\u09ae\u09bf\u09a5\u09bf\u09b2\u09be proposed me     My REACTION :  \u0985\u09cd\u09af\u09be ... ", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: A person is shown in a meme with a caption that says "my reaction" and a speech bubble with a hateful message.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/ovodro_img (1021).jpg", "text": "\u09ac\u09b2\u09be \u0986\u099b\u09c7 \" \u0997\u09c1\u09b0\u09c1\u09b0 \u0995\u09c3\u09aa\u09be \u09a5\u09be\u0995\u09b2\u09c7 \u09b8\u09ae\u09b8\u09cd\u09a4 \u09ae\u09a8\u09cb\u09b0\u09a5 \u09ac\u09bf\u09a8\u09be \u099a\u09c7\u09b7\u09cd\u099f\u09be\u09df \u09b8\u09ab\u09b2 \u09b9\u09df\u09c7 \u09af\u09be\u09df \"    - \u0986\u09ac\u09be\u09b0 \u0997\u09c1\u09b0\u09c1\u09b0 \u099a\u09cb\u0996\u09c7\u0987 \u0986\u09ae\u09bf ", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The meme is not hateful, it is just a political statement.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/CM (48).jpg", "text": "\u09ee \u09ac\u099b\u09b0\u09c7\u09b0 \u0986\u09ae\u09bf \u09b9\u09be\u09a5\u09c7 \u09ae\u09c7\u09b9\u09c7\u09a6\u09c0 \u09a6\u09c7\u0993\u09df\u09be\u09b0 \u09aa\u09b0 -     \u0986\u09ae\u09be\u09b0 \u09b9\u09be\u09a4 \u09ab\u09cd\u09b0\u09bf \u09a5\u09be\u0995\u09b2\u09c7 \u0986\u09aa\u09a8\u09c7\u09b0 \u09b8\u09be\u09a5\u09c7 \u09b9\u09cd\u09af\u09be\u09a8\u09cd\u09a1\u09b6\u09c7\u0995 \u0995\u09b0\u09a4\u09be\u09ae ", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The meme is a picture of a man being helped by another man. The caption is in a foreign language, but the image is not hateful.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/bamboo-vaiya (40).jpg", "text": "On The Way to Chittagong    10 Minute \u09aa\u09b0 \u0995\u09c1\u09ae\u09bf\u09b2\u09cd\u09b2\u09be\u09df \u09ac\u09be\u09b8 \u09a5\u09be\u09ae\u09ac\u09c7     Finally \u09ac\u09be\u09b8 \u0995\u09c1\u09ae\u09bf\u09b2\u09cd\u09b2\u09be\u09df  ", "label": 1}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The meme is a cartoon of a sponge, with the words 'on the way to chittagong' and 'finally bangladesh' written above it. The meme is not hateful, but it is a joke that is not meant to be taken seriously.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/ovodro_img (1114).jpg", "text": "\u09af\u09a6\u09bf \u0995\u09c7\u099f\u09c7 \u09af\u09be\u09df \u09ae\u09c3\u09a4\u09cd\u09af\u09c1 \u09ad\u09be\u09df   \u09af\u09a6\u09bf \u09b8\u09c7\u09b0\u09c7 \u0993\u09a0\u09c7 \u09b6\u09b9\u09b0     \u09ae\u09a8\u09c7 \u09b0\u09c7\u0996\u09cb \u0986\u09ae\u09b0\u09be \u09b6\u09c1\u09a7\u09c1 \u09a8\u09be\u09ae\u09c7\u09b0 \u09b8\u09be\u0982\u09b8\u09a6 \u0995\u09be\u099c \u09ac\u09be \u0989\u09aa\u0995\u09be\u09b0 \u0995\u09bf\u099b\u09c1\u0987 \u0995\u09b0\u09bf\u09a8\u09bf \u0986\u09ae\u09b0\u09be  ", "label": 1}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The image is a meme that is not hateful, it is not intended to denigrate, vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/ovodro_img (1215).jpg", "text": "\u0987\u09a8\u09b8\u09cd\u099f\u09be\u0997\u09cd\u09b0\u09be\u09ae\u09c7 \u09b6\u09be\u09b9\u09b0\u09c1\u0996 \u0996\u09be\u09a8\u09c7\u09b0 ' \u09aa\u09be\u09a0\u09be\u09a8 ' \u09ae\u09c1\u09ad\u09bf \u09ac\u09df\u0995\u099f \u0995\u09b0\u09be\u09b0 \u0995\u09a5\u09be \u09ac\u09b2\u09be\u09b0 \u09aa\u09b0 , \u09af\u0996\u09a8 \u09a4\u09be\u09b0 \u09ab\u09cd\u09af\u09be\u09a8 \u09b0\u09be \u09b0\u09bf\u09aa\u09cb\u09b0\u09cd\u099f \u09ae\u09c7\u09b0\u09c7 \u09a4\u09cb\u09ae\u09be\u09b0 \u0987\u09a8\u09b8\u09cd\u099f\u09be\u0997\u09cd\u09b0\u09be\u09ae \u0986\u0987\u09a1\u09bf\u0987 \u0989\u09dc\u09bf\u09df\u09c7 \u09a6\u09c7\u09df     Hindustani vau be like :     \u099a\u09c1\u09a6\u09c7 \u099a\u09be\u099f\u09a8\u09bf , \u09ac\u09c7\u0995\u09be\u09b0 \u0996\u09be\u099f\u09a8\u09bf \u0964 ", "label": 1}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The meme is a cartoon of a man with a yellow shirt and a green hat. The cartoon is in a foreign language, but the caption is in English. The caption is a quote from a famous person, and it is not hateful.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/netflix (144).jpg", "text": "what i want to do with Crush's boyfriend    What i really do ", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The image is a meme that is not hateful, it is just a funny picture of two people doing something together. The meme is not hateful, it is just a funny picture of two people doing something together.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/ovodro_img (1199).jpg", "text": "\u0995\u09c0\u09b0\u09cd\u09a4\u09a8\u09c0\u09df\u09be    \u09ac\u09b2\u09cb \u0997\u09cc\u09b0 \u09aa\u09cd\u09b0\u09c7\u09ae\u09be\u09a8\u09cd\u09a6\u09c7\u09b0 \u09b9\u09b0\u09bf \u09b9\u09b0\u09bf  ...    \u09a6\u09b6\u09ac\u099b\u09b0 \u09ac\u09df\u09b8\u09c0 \u0986\u09ae\u09bf   ", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: A meme with a man in a blue shirt, raising his arms in celebration, with the caption "India vs Pakistan" in a foreign language.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/TR (111).jpg", "text": "\u0985\u09a8\u09c7\u0995  \u09b8\u09be\u09a7\u09a8\u09be \u0995\u09b0\u09c7 \u099c\u09bf\u09b2\u09be \u09b8\u09cd\u0995\u09c1\u09b2\u09c7 \u099a\u09be\u09a8\u09cd\u09b8 \u09aa\u09be\u0993\u09df\u09be\u09b0 \u09aa\u09b0 ...    \u099a\u09be\u09a8\u09cd\u09b8 \u09a8\u09be \u09aa\u09be\u0993\u09df\u09be \u099b\u09c7\u09b2\u09c7     \u0986\u09ae\u09bf    \u0986\u09ae\u09be\u09b0\u09c7 \u09b8\u09cd\u09af\u09be\u09b0 \u09a1\u09be\u0995\u09ac\u09be ", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The meme is not hateful, it is just a funny picture of two men with a caption that is not meant to be taken seriously.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/bamboo-vaiya (390).jpg", "text": "\u0995\u09bf \u09a6\u09c7\u0996\u09cb\u09b8 ?  \u09b2\u09be\u0987\u099f \u09a8\u09bf\u09ad\u09be\u0987\u09b2\u09c7 \u09b8\u09ac \u09b8\u09ae\u09be\u09a8 ", "label": 1}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The image is a meme that is not hateful, but it is a meme that is not hateful. The woman in the image is standing in a bathroom, and the text is in a foreign language.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/CM (444).jpg", "text": "\u0995\u09be\u099c\u09c0:   \u09ac\u09be\u09ac\u09be ,  \u09ac\u09b2\u09cb \u0995\u09ac\u09c1\u09b2 \u0964      \u09ac\u09be\u09ac\u09be:   \u0995\u09ac\u09c1\u09b2 \u0964    \u099b\u09c7\u09b2\u09c7 ", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The meme is a picture of a man with his mouth open, and the caption is in a foreign language. The caption is not hateful, but it is not hateful.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/CM (357).jpg", "text": "\u099b\u09cb\u099f\u09ac\u09c7\u09b2\u09be\u09df \u09ac\u09be\u09b9\u09bf\u09b0\u09c7 \u0996\u09c7\u09b2\u09be\u09b0 \u09b8\u09ae\u09df \u09af\u0996\u09a8 \u09ae\u09be\u0997\u09b0\u09bf\u09ac\u09c7\u09b0 \u0986\u09af\u09be\u09a8 \u09a6\u09bf\u09df\u09c7 \u09a6\u09c7\u09df*      \u0986\u09ae\u09bf \u0986\u09b0 \u0986\u09ae\u09be\u09b0 \u09ac\u09a8\u09cd\u09a7\u09c1\u09b0\u09be\u0983     On your feet soldier , we're leaving ", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The meme is a hateful one, as it is mocking a soldier who is in the military.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/bangla-troll (17).jpg", "text": "\u0986\u09aa\u09c1 \u09a5\u09be\u09ae\u09c7\u09a8 ! \u098f\u09a4 MAKEUP \u09a6\u09bf\u09b8\u09c7\u09a8 !! \u09a6\u09c7\u0996\u09a4\u09c7 \u09aa\u09c1\u09b0\u09be \u09b8\u09be\u09b9\u09be\u09b0\u09be \u0996\u09be\u09a4\u09c1\u09a8\u09c7\u09b0 \u09ae\u09a4 \u09b2\u09be\u0997\u09a4\u09c7\u09b8\u09c7", "label": 1}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: A lemur is shown in a yoga pose, with the words "hateful" and "not-hateful" written in the background.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/Halal Memes (273).jpg", "text": "\u09a4\u09c7.\u09ae.\u09a8 \u0995\u09bf\u099b\u09c1 \u09a8\u09be\u09b9, HSC \u09aa\u09b0\u09bf\u0995\u09cd\u09b7\u09be \u09b9\u09ac\u09c7 \u09a8\u09be\u09b9 \u09b6\u09cb\u09a8\u09be\u09b0 \u09aa\u09b0\u09c7, \u09b8\u09ae\u09be\u09b2\u09cb\u099a\u09a8\u09be \u0993 \u0995\u09c1\u099f\u09a8\u09be\u09ae\u09bf \u0995\u09b0\u09a4\u09c7 \u09aa\u09be\u09b0\u09ac\u09c7 \u09a8\u09be\u09b9 \u09ac\u09c1\u099d\u09a4\u09c7 \u09aa\u09be\u09b0\u09be \u09aa\u09be\u09b6\u09c7\u09b0 \u09ac\u09be\u09b8\u09be\u09b0 \u0986\u09a8\u09cd\u099f\u09bf      ", "label": 1}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The meme is not hateful, it is just a picture of two women with a caption that is not hateful.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/bangla-memes (40).jpg", "text": "\u09af\u0996\u09a8 \u09a8\u09be\u09ae\u09be\u099c\u09c7\u09b0 \u09b6\u09c7\u09b7\u09c7 \u099c\u09bf\u09b2\u09be\u09aa\u09bf \u09a6\u09c7\u0993\u09df\u09be \u09b9\u09df \u09a8\u09be  ", "label": 1}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The image is a meme that is not hateful, it is a picture of a man being helped by a soldier.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/chintashil (515).jpg", "text": "We are looking for good batsman     Variations of this guys ", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The meme is not hateful, it is just a sports meme.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/KAM (2).png", "text": "\u0986\u09ae\u09bf \u09a8\u09a4\u09c1\u09a8 \u0995\u09b0\u09c7 \u09a8\u09bf\u09b0\u09cd\u09ac\u09be\u099a\u09a8 \u09a6\u09bf\u09a4\u09c7 \u09b0\u09be\u099c\u09bf! \u0995\u09bf \u09b8\u09a4\u09cd\u09af\u09bf? \u09a4\u09be\u09b0\u09aa\u09b0 \u0986\u09ac\u09be\u09b0 \u09ad\u09cb\u099f \u099b\u09be\u09dc\u09be \u09aa\u09cd\u09b0\u09a7\u09be\u09a8\u09ae\u09a8\u09cd\u09a4\u09cd\u09b0\u09c0 \u09b9\u09df\u09c7 \u09af\u09be\u09ae\u09c1! \u09ab\u0987\u09a8\u09cd\u09a8\u09bf!", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The meme is not hateful, it is not intended to denigrate, vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/KAM (103).png", "text": "\u099a\u09cd\u09af\u09be\u09ae\u09cd\u09aa\u09bf\u09df\u09a8 \u098f\u09b0 \u09aa\u09b0 \u09b2\u09c0\u0997 \u0995\u09c7\u09a8? \u0995\u09be\u09b2\u0995\u09c7 \u09b9\u09b0\u09a4\u09be\u09b2!", "label": 1}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The image is a meme that is not hateful, it is a political cartoon that is not intended to harm or mock any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/TR (444).jpg", "text": "\u0997\u09ad\u0983 \u0997\u09be\u09b0\u09cd\u09b2\u09b8 \u09b8\u09cd\u0995\u09c1\u09b2\u09c7 \u099a\u09be\u09a8\u09cd\u09b8 \u09aa\u09be\u0993\u09df\u09be\u09b0 \u0986\u0997\u09c7     \u0997\u09ad\u0983 \u0997\u09be\u09b0\u09cd\u09b2\u09b8 \u09b8\u09cd\u0995\u09c1\u09b2\u09c7 \u099a\u09be\u09a8\u09cd\u09b8 \u09aa\u09be\u0993\u09df\u09be\u09b0 \u09aa\u09b0  ", "label": 1}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The meme is not hateful, it is just a picture of two women in different poses.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/tangaila (171).jpg", "text": "\u09aa\u09cb\u09b2\u09be \u0997\u09c7\u099b\u09bf\u09b2\u09cb \u09b8\u0996\u09bf\u09aa\u09c1\u09b0 \u09ac\u09bf\u09df\u09be \u0995\u09b0\u09a4\u09c7  \u0985\u09a4\u0983\u09aa\u09b0 \u09a4\u09be\u09b0 \u0985\u09ac\u09b8\u09cd\u09a4\u09be\u0983-", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The meme is not hateful, it is just a funny picture of a car stuck in mud.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/direct-offense (31).jpg", "text": "\u0985\u09a4\u09c0\u09a4\u09c7 \u09af\u09be\u09b0\u09be \u09a6\u09c7\u09b6\u0995\u09c7 \u09b0\u09bf\u09aa\u09cd\u09b0\u09c7\u099c\u09c7\u09a8\u09cd\u099f \u0995\u09b0\u09a4\u09cb  \u09ac\u09b0\u09cd\u09a4\u09ae\u09be\u09a8\u09c7 \u09af\u09be\u09b0\u09be \u09b0\u09bf\u09aa\u09cd\u09b0\u09c7\u099c\u09c7\u09a8\u09cd\u099f \u0995\u09b0\u099b\u09c7 !", "label": 1}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The meme is not hateful, it is just a picture of a group of people with a caption that says 'happy birthday'.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/chintashil (672).jpg", "text": "\u0986\u09ae\u09be\u09b0 \u098f\u0987 \u09b9\u09c3\u09a6\u09df\u09c7\u09b0 \u09ad\u09bf\u09a4\u09b0 \u0995\u09bf \u0986\u099b\u09c7 \u09a4\u09c1\u09ae\u09bf \u09a6\u09c7\u0996\u09a4\u09c7 \u099a\u09be\u0993    \u09a6\u09c7\u0996,,,", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The meme is not hateful, it is just a funny picture of two people with a caption that is not meant to be taken seriously.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/chintashil (681).jpg", "text": "\u09b0\u09be\u0995\u09bf\u09ac\u09c7\u09b0 \u09ac\u09bf\u09df\u09c7\u09b0 \u09a6\u09bf\u09a8     \u099c\u09c7\u09b0\u09bf\u09a8*   \u09ae\u09bf\u09ae   \u09b8\u09be\u09a6\u09bf\u09df\u09be*    \u09a4\u09be\u09ae\u09be\u09a8\u09cd\u09a8\u09be   \u0986\u09a8\u09bf\u0995\u09be   \u09b8\u09c1\u09ae\u09be\u0987\u09df\u09be*  ", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The meme is not hateful, it is just a group of people making funny faces at a concert.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/chintashil (63).jpg", "text": "\u09af\u0996\u09a8 \u0986\u09ae\u09bf \u0995\u09be\u09b0\u09cb \u0995\u09b2 \u09b0\u09bf\u09b8\u09bf\u09ad \u0995\u09b0\u09c7 \u0985\u09a8\u09cd\u09af \u09b0\u09c1\u09ae\u09c7\u09b0 \u09a6\u09bf\u0995\u09c7 \u09af\u09be\u0987 , \u0986\u09ae\u09cd\u09ae\u09c1\u0983 ", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The image is a meme that is not hateful, but it is a cat with a sad face. The caption is in a foreign language, but the cat is still making a face.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/ovodro_img (597).jpg", "text": "\u09ad\u09be\u0987\u099f\u09bf \u09b0\u09cb\u099c\u09be \u09aa\u09be\u09b2\u09a8 \u0995\u09b0\u099b\u09c7 \u09a4\u09be\u0987 \u0996\u09be\u09ac\u09be\u09b0\u09c7 \u09ae\u09c1\u0996 \u09a6\u09bf\u09a4\u09c7 \u09aa\u09be\u09b0\u099b\u09c7 \u09a8\u09be ", "label": 1}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The meme is a picture of a man and woman with the caption "hateful if it explicitly intends to denigrate, vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status."
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/TR (356).jpg", "text": "\" \u09a7\u09b2\u09be\u09b0 \u09ae\u09cb\u09dc \"      \" \u09b8\u09be\u09a6\u09be\u09b0 \u09ae\u09cb\u09dc \"     \" \u09ab\u09b0\u09cd\u09b8\u09be\u09b0 \u09ae\u09cb\u09dc \" ", "label": 1}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The meme is not hateful, it is just a picture of three men with different captions. The captions are not meant to be hateful, but rather to express different opinions or personalities.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/ovodro_img (322).jpg", "text": "\u09e9\u09e6\u09e6 \u099f\u09be\u0995\u09be \u09a6\u09bf\u09df\u09c7 \u0993\u099f\u09be \u0995\u09c0 \u0995\u09bf\u09a8\u09c7\u099b\u09bf\u09b8 ?   \u0995\u09cd\u09b0\u09bf\u09ae \u0995\u09c7\u0995    \u099c\u09be\u09a8\u09bf\u09b8 \u09a8\u09be \u0993\u0987 \u09ac\u09be\u09b2\u09c7\u09b0 \u0995\u09c7\u0995 \u0986\u09ae\u09b0\u09be \u09ac\u09be\u0999\u09cd\u0997\u09be\u09b2\u09bf\u09b0\u09be \u0996\u09be\u0987 \u09a8\u09be    \u09af\u09be \u098f\u0995\u09cd\u09b7\u09c1\u09a8\u09bf \u0993\u099f\u09be \u09ab\u09c7\u09b0\u09a4 \u09a6\u09bf\u09df\u09c7 \u09ac\u09be\u09aa\u09c1\u099c\u09bf \u0995\u09c7\u0995 \u09a8\u09bf\u09df\u09c7 \u0986\u09df ", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The image is a meme that is not hateful, it is a comical and lighthearted image of two men in uniforms with a caption in a foreign language.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/Bangla Thug Life (70).jpg", "text": "* \u09af\u0996\u09a8 \u09b9\u09c1\u099c\u09c1\u09b0 \u0986\u09aa\u09a8\u09be\u0995\u09c7 \u0985\u0995\u09be\u09b0\u09a3\u09c7 \u09a4\u09be\u09b0 \u0995\u09cb\u09b2\u09c7 \u09ac\u09b8\u09a4\u09c7 \u09ac\u09b2\u09c7 ;  \u0986\u09aa\u09a8\u09bf :  Something's wrong, I can feel it ", "label": 1}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The meme is a picture of a man in sunglasses with a caption that is not hateful.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/CM (388).jpg", "text": "\u098f, \u0993    \u0990 , \u0993\u0981\u0987    \u09b8\u09ac\u09be\u09b0 \u09aa\u09be\u0996\u09be \u09ae\u09c7\u09b2\u09c7 , \u0986\u09ae\u09be\u09b0 \u09aa\u09be\u0996\u09be \u09ae\u09c7\u09b2\u09c7 \u09a8\u09be ", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The image is a meme that is not hateful, it is a funny scene with two men talking to each other. The meme is not hateful, it is just a funny scene.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/chintashil (734).jpg", "text": "No matter what is the condition, never miss the chance  of pressing your \u09ae\u09cb\u099f\u09be \u09ac\u09a8\u09cd\u09a7\u09c1\u09b0 \u09aa\u09ae \u09aa\u09ae  ", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The meme is not hateful, it is just a funny picture of people in the water.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/KAM (145).jpg", "text": "\u0995\u09b2\u0995\u09be\u09a4\u09be\u09b0 \u09aa\u09cd\u09b0\u09a4\u09bf \u09ae\u09cd\u09af\u09be\u099a\u09c7 \u09b8\u09be\u0995\u09bf\u09ac\u0995\u09c7 \u09a8\u09c7\u0993\u09df\u09be\u09b0 \u09a8\u09bf\u09b0\u09cd\u09a6\u09c7\u09b6 \u09a6\u09bf\u09b2\u09c7\u09a8 \u09b6\u09be\u09b9\u09b0\u09c1\u0996 \u0996\u09be\u09a8 \u09b6\u09bf\u09b6\u09bf\u09b0\u0983 \u0986\u09b8\u09b2\u09c7 \u0986\u09ae\u09bf \u09b6\u09be\u09b9\u09b0\u09c1\u0996\u0995 \u09b9\u09c1\u09ae\u0995\u09bf \u09a6\u09bf\u099b\u09bf \u0986\u09a8\u09bf \u09a8\u09be\u09b0\u09be\u09df\u09a3\u0997\u099e\u09cd\u099c\u09c7\u09b0 \u09ae\u09c7\u09df\u09c7, \u0986\u09ae\u09be\u09b0 \u099c\u09be\u09ae\u09be\u0987\u0995\u09c7 \u09a8\u09be \u09a8\u09bf\u09b2\u09c7 \u0997\u09c1\u09ae \u0995\u0987\u09b0\u09be \u09a6\u09bf\u09ae\u09c1", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The image is a meme that is not hateful, it is a funny picture of a man and a woman with a caption that is not intended to harm or mock anyone.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/KAM (180).jpg", "text": "\u09b6\u09c7\u09b7 \u099f\u09c7\u09b8\u09cd\u099f\u09c7 \u099c\u09df \u09a8\u09bf\u09a4\u09c7 \u0997\u09a4\u09bf\u09a4\u09c7 \u09ab\u09bf\u09b0\u09a4\u09c7 \u099a\u09be\u09df \u099c\u09bf\u09ae\u09cd\u09ac\u09be\u09ac\u09c1\u09df\u09c7! \u09b8\u09be\u0995\u09bf\u09ac \u09ad\u09be\u0987 \u09b6\u09c1\u09a8\u099b\u09c7\u09a8 \u09a8\u09be\u0995\u09bf, \u0995\u09bf \u09ac\u09b2\u099b\u09c7!  \u09b9\u09c1\u09ae \u0986\u09ac\u09be\u09b0\u0993 \u099a\u09c1\u09b2\u0995\u09c7 \u09a6\u09bf\u09ac\u09cb! ", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The image is a meme that is not hateful, it is just a funny picture of two men with a caption that is not meant to be offensive.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/chintashil (79).jpg", "text": "\u0997\u09cd\u09b0\u09be\u09ae\u09c7\u09b0 \u099a\u09be\u099a\u09be\u09a4\u09cb \u09ac\u09cb\u09a8 \u09af\u0996\u09a8 \u09b6\u09b9\u09b0\u09c7 \u09ad\u09be\u0987 \u098f\u09b0 \u09ac\u09be\u09b8\u09be\u09df \u098f\u09b8\u09c7 \u09b8\u09c7\u09b2\u09ab\u09bf \u09a4\u09c1\u09b2\u09c7  ", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The image is a meme that is not hateful, it is just a funny picture of a woman taking a selfie. The meme is not hateful, it is just a funny picture of a woman taking a selfie.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/ovodro_img (880).jpg", "text": "\u09af\u0996\u09a8 \u09b8\u09ae\u09c1\u09a6\u09cd\u09b0\u09c7\u09b0 \u0995\u09cb\u09a8 \u099c\u09be\u09b9\u09be\u099c \u099a\u09be\u09b2\u0995 \u0985\u09a8\u09c1\u09aa\u09ae \u09b0\u09be\u09df\u09c7\u09b0 \u09ab\u09cd\u09af\u09be\u09a8 \u098f\u09ac\u0982 \u0997\u09be\u09a8\u09c7\u09b0 \u09b2\u09bf\u09b0\u09bf\u0995\u09cd\u09b8\u09c7\u09b0 \u09ae\u09a7\u09cd\u09af\u09c7 \u09b6\u09cb\u09a8\u09c7 ' \u09a6\u09c1\u09b0\u09cd\u09ac\u09bf\u09a8\u09c7 \u099a\u09cb\u0996 \u09b0\u09be\u0996\u09ac \u09a8\u09be '   \u09a4\u09be\u09b9\u09b2\u09c7 \u09a6\u09c1\u09b0\u09c7\u09b0 \u099c\u09bf\u09a8\u09bf\u09b8 \u0995\u09c0 \u0995\u09b0\u09c7 \u09a6\u09c7\u0996\u09ac ?   \u09a4\u09ac\u09c7 \u0995\u09c0 \u09a6\u09c1\u09b0\u09cd\u09ac\u09bf\u09a8\u09c7 \u0995\u09be\u09a8 \u09b0\u09be\u0996\u09ac \u0986\u099c \u09a5\u09c7\u0995\u09c7 ?    \u09a4\u09ac\u09c7 \u0995\u09c0 \u09a6\u09c1\u09b0\u09cd\u09ac\u09bf\u09a8 \u099f\u09be \u09ac\u09bf\u09dc\u09bf\u09b0 \u09ae\u09a4 \u0995\u09be\u09a8\u09c7 \u0997\u09c1\u099c\u09c7 \u09b0\u09be\u0996\u09ac ? ", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The meme is in a foreign language, and it is not hateful.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/CM (14).jpg", "text": "Efftects of Weed    Effects of cocaine   Effects of passing by old school ", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The meme is a comparison between hateful and not-hateful content. The meme is a comparison between hateful and not-hateful content. The meme is a comparison between hateful and not-hateful content. The meme is a comparison between hateful and not-hateful content.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/ovodro_img (1084).jpg", "text": "\u09af\u09a6\u09bf \u0997\u09cd\u09b0\u09b9\u09a8 \u099a\u09b2\u09be\u0995\u09be\u09b2\u09c0\u09a8 \u09a4\u09c1\u09ae\u09bf \u0995\u09bf\u099b\u09c1 \u0996\u09c7\u09a4\u09c7 \u099a\u09be\u0993    \u09a4\u09cb\u09ae\u09be\u09b0 \u09ab\u09cd\u09af\u09be\u09ae\u09bf\u09b2\u09bf :", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The meme is a black and white photograph of five people, including a woman, standing in a line. The caption is written in a foreign language, which is likely to be Bengali. The caption is a quote from a movie, and it is not hateful.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/Memeholics (16).jpg", "text": "When your parents are always in front of you but you're never able to express how much you love them   \u09b8\u09bf\u09ae\u09cd\u09aa\u09b2 \u0995\u09be\u099c\u0987 \u0986\u09b8\u09b2\u09c7 \u0995\u09a0\u09bf\u09a8 \u0964 ", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The meme is a picture of a man with glasses and a caption that reads 'when your parents are always in front of you but you're never able to express how much you love them.'
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/Halal Memes (264).jpg", "text": "SSC \u09aa\u09be\u09b6 \u09a8\u09bf\u09ac\u09cd\u09ac\u09be\u0983 \u0995\u09b2\u09c7\u099c \u09b2\u09be\u0987\u09ab\u09c7 \u09b6\u09c1\u09a7\u09c1 chill \u09b9\u09ac\u09c7 chill.  2nd year- \u098f\u09b0 \u09ac\u09dc \u09ad\u09be\u0987\u0983", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The meme is a picture of a man with a beard, wearing a suit, and holding a glass of wine. The text is in Bengali and translates to "SCC FHJ Chill 2nd Year 99". The meme is not hateful, but it is a joke.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/tangaila (229).jpg", "text": "\u0990 \u09a6\u09c7\u0996\u09be \u09af\u09be\u09df \u0995\u09b2\u09c7\u099c \u0997\u09c7\u099f, \u0990 \u0986\u09ae\u09be\u09a6\u09c7\u09b0 \u0997\u09be\u0981 \u0990 \u0996\u09be\u09a8\u09c7\u09a4\u09c7 \u09ac\u09be\u09b8 \u0995\u09b0\u09c7 \u09a8\u09be\u0997\u09bf\u09a8\u09c7\u09b0 \u099b\u09be...", "label": 1}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The meme is not hateful, it is just a funny picture of a man pointing at something. The meme is not hateful, it is just a funny picture of a man pointing at something.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/KAM (39).jpg", "text": "\u09ae\u09be\u09a4\u09cd\u09b0 \u09ac\u09cd\u09b0\u09be\u099c\u09bf\u09b2-\u0986\u09b0\u09cd\u099c\u09c7\u09a8\u09cd\u099f\u09bf\u09a8\u09be  \u09af\u09c1\u09a6\u09cd\u09a7 \u09b6\u09c7\u09b7 \u09b9\u0987\u09b2 \u098f\u0996\u09a8 \u09b0\u09bf\u09df\u09be\u09b2-\u09ac\u09be\u09b0\u09cd\u09b8\u09c7\u09b2\u09cb\u09a8\u09be \u09af\u09c1\u09a8\u09cd\u09a7 \u09b6\u09c1\u09b0\u09c1 \u09b9\u09ac\u09c7", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The meme is not hateful, it is just a funny picture of the president with a caption that is not meant to be taken seriously.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/tangaila (113).jpg", "text": "\u09af\u0996\u09a8 \u0995\u09cb\u09a8\u09cb  \u09ae\u09c7\u09df\u09c7 \u09ac\u09b2\u09c7 \u09a4\u09c1\u09ae\u09bf \u09a4\u09cb \u0985\u09a8\u09c7\u0995 \u09b8\u09c1\u09a8\u09cd\u09a6\u09b0 \u0995\u09bf\u0989\u099f \u09a4\u0996\u09a8 \u0986\u09ae\u09bf\u0983-", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The meme is a picture of two men with a caption that reads "Hateful if it intends to denigrate, vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status." The caption is in a foreign language, but the words are still legible.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/KAM (9).jpg", "text": "\u0986\u09ae\u09bf, \u0986\u09ae\u09be\u09b0 \u098f\u0995 \u099b\u09c7\u09b2\u09c7\u09b0 \u09a8\u09be\u09ae \u09a6\u09c7\u09b6 \u0993 \u0986\u09b0\u09c7\u0995 \u099b\u09c7\u09b2\u09c7\u09b0 \u09a8\u09be\u09ae \u099c\u09be\u09a4\u09bf \u09b0\u09be\u0996\u099b\u09bf \u0995\u09c7\u09a8? \u0995\u09be\u09b0\u09a3 \u0986\u09ae\u09bf \u09b8\u09ac\u09be\u0987\u0995\u09c7 \u09ac\u09b2\u09a4\u09c7 \u099a\u09be\u0987 \u09a6\u09c7\u0996 '\u0986\u09ae\u09bf \u09a6\u09c7\u09b6 \u0993 \u099c\u09be\u09a4\u09bf\u09b0 \u09aa\u09bf\u09a4\u09be'", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The image is a meme that is not hateful, it is a funny picture of two men with a caption that is not intended to harm or mock anyone.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/chintashil (931).jpg", "text": "\u0986\u0995\u09be\u09b6 \u09a5\u09c7\u0995\u09c7 \u0995\u09df\u09c7\u0995 \u09ab\u09cb\u0981\u099f\u09be \u09ac\u09c3\u09b7\u09cd\u099f\u09bf \u09ac\u09b0\u09cd\u09b7\u09a3\u09c7\u09b0 \u09aa\u09b0 , \u099f\u09cd\u09b0\u09be\u09a8\u09cd\u09b8\u09ae\u09bf\u099f\u09be\u09b0 :  ", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The meme is a picture of a man with a hateful expression, and the caption is in a foreign language.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/CM (399).jpg", "text": "\u09af\u0996\u09a8 \u0995\u09c7\u0993 \" \u0986\u09b2\u09b9\u09be\u09ae\u09a6\u09c1\u09b2\u09bf\u09b2\u09cd\u09b2\u09be\u09b9 \u0997\u09b0\u09c1 \u09a1\u09be\u09a8 \u09e7 \u09b2\u09be\u0996 \u09e8\u09e6 \"  \u09b2\u09bf\u0996\u09c7 \u09aa\u09cb\u09b8\u09cd\u099f \u09a6\u09c7\u09df    I'm sorry , did anyone ask you to fucking speak ? ", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The meme is a collage of four different images of a man with the text 'hateful' or 'not-hateful' above the images. The meme is a collage of four different images of a man with the text 'hateful' or 'not-hateful' above the images. The meme is a collage of four different images of a man with the text 'hateful' or 'not-hateful' above the images.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/Bangla Thug Life (342).jpg", "text": "\u0986\u09ae\u09be\u09a6\u09c7\u09b0     \u099a\u09be\u0993\u09df\u09be   \u09aa\u09be\u0993\u09df\u09be     \u09a8\u09be \u09ac\u09c1\u099d\u09b2\u09c7 \u0995\u09be\u09b0\u09cd\u099f\u09c1\u09a8 \u09a6\u09c7\u0996", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The image is a meme that is not hateful, it is just a picture of a fruit with a caption that is not hateful.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/bangla-memes (55).jpg", "text": "*Anything bad happens*  in the country     *\u09b8\u09b0\u0995\u09be\u09b0    \u09ac\u09bf\u098f\u09a8\u09aa\u09bf-\u099c\u09be\u09ae\u09be\u09a4\u09c7\u09b0 \u099a\u0995\u09cd\u09b0\u09be\u09a8\u09cd\u09a4  ", "label": 1}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The meme is a picture of a man sitting in a chair, with the caption 'anything bad happens in the country' and the words 'hateful' and 'not-hateful' written above it. The man is sitting in a chair, and the caption is written above him. The man is wearing a suit and is sitting in a chair, with a microphone in front of him. The caption is written in a font that is similar to the font used
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/direct-offense (37).jpg", "text": "when you have a beautiful wife but your performance is so poor \u09b2\u09be\u0997\u09be\u09a4\u09c7 \u09aa\u09be\u09b0\u09bf\u09a8\u09be \u09b8\u09be\u09b0\u09be\u09b0\u09be\u09a4 \u09a7\u09b0\u09c7, \u09ac\u09c1\u0995\u09c7\u09b0 \u09ad\u09c7\u09a4\u09b0\u099f\u09be \u09b9\u09be\u09b9\u09be\u0995\u09be\u09b0 \u0995\u09b0\u09c7 ", "label": 1}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The meme is not hateful, it is just a funny picture of a man with a caption that is not meant to be taken seriously.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/chintashil (851).jpg", "text": "\u0986\u09ae\u09bf \u099c\u09bf\u09a8\u09cd\u09a8\u09be\u09b9  \"\u0989\u09b0\u09cd\u09a6\u09c1 \u0989\u09b0\u09cd\u09a6\u09c1\u0987 \u09b9\u09ac\u09c7 \u09aa\u09be\u0995\u09bf\u09b8\u09cd\u09a4\u09be\u09a8\u09c7\u09b0 \u098f\u0995\u09ae\u09be\u09a4\u09cd\u09b0 \u09b0\u09be\u09b7\u09cd\u099f\u09cd\u09b0\u09ad\u09be\u09b7\u09be\"    \u09ac\u09be\u0982\u09b2\u09be\u09b0 \u09a6\u09be\u09ae\u09be\u09b2 \u099b\u09c7\u09b2\u09c7\u09b0\u09be   \u09a4\u09cb* ** \u09a8\u09be - \u09a8\u09be , **\u099a\u09c1**, \u0996\u09be\u09dc\u09be* , \u09ae\u09be** \u0986\u09b2\u09bf \u099c\u09bf\u09a8\u09cd\u09a8\u09be\u09b9   \u0986\u09b6\u09cd\u099a\u09b0\u09cd\u09af \u099b\u09c7\u09b2\u09c7\u0997\u09c1\u09b2\u09cb \u0997\u09be\u09b2\u09bf \u09a6\u09bf\u099a\u09cd\u099b\u09c7 \u0995\u09c7\u09a8 ? ", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The meme is in a foreign language, and the man is making a gesture with his hands. The meme is not hateful, but it is not hateful either.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/ovodro_img (1016).jpg", "text": "She - \u09a4\u09cb\u09b0 Gun \u099f\u09be \u098f\u0996\u09be\u09a8\u09c7 \u09b2\u09c1\u0995\u09bf\u09df\u09c7\u099b\u09bf\u09b8 \u0995\u09c7\u09a8 ?   He - \u0986\u09ae\u09be\u09b0 Gun \u0993\u0996\u09be\u09a8\u09c7\u0987 \u09a5\u09be\u0995\u09c7    She - \u09ac\u09c7\u09b0 \u0995\u09b0 \u09a4\u09cb\u09b0 Gun \u099f\u09be \u09a8\u09bf\u09df\u09c7 \u0996\u09c7\u09b2\u09be \u0995\u09b0\u09ac  ", "label": 1}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The image is a meme that is not hateful, it is a joke. The man is pointing a gun at the woman and asking her if she has a gun. The woman is saying no, and the man is saying that she is a woman and should have a gun. The meme is not hateful, it is a joke.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/nurani-memes (131).jpg", "text": "\u0986\u09ae\u09cd\u09ae\u09c1\u0983 \u09a4\u09cb\u09b0 \u09ac\u09df\u09b8\u09c7\u09b0 \u09b8\u09ac\u09be\u0987 \u099f\u09bf\u0989\u09b6\u09a8\u09bf \u0995\u09b0\u09be\u09df\u09be \u099f\u09be\u0995\u09be \u0995\u09be\u09ae\u09be\u09df \u0986\u09b0 \u09a4\u09c1\u0987 \u098f\u0996\u09a8\u09cb \u09ac\u09be\u09aa\u09c7\u09b0 \u0989\u09aa\u09b0\u09c7 \u099a\u09b2\u09b8 ,  \u09b2\u099c\u09cd\u099c\u09be \u0995\u09b0\u09c7\u09a8\u09be ?   \u0986\u09ae\u09bf\u0983  \u09b2\u099c\u09cd\u099c\u09be ? \u09b9\u09c7\u0987\u09a1\u09be\u09a4\u09c7\u0993 \u09aa\u09cd\u09b0\u09bf\u099c\u09be\u09b0\u09ad\u09c7\u099f\u09bf\u09ad \u09a6\u09c7\u0993\u09df\u09be \u0986\u099b\u09c7 ", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The image is a meme that is not hateful, it is a funny picture of a man with a caption that is not intended to harm or mock anyone.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/ovodro_img (718).jpg", "text": "\u0996\u09be\u0981\u09dc\u09be \u09a6\u09c7\u0996\u0995\u09c7 \u09b9\u09be\u09b8\u09b2\u09bf\u09df\u09be    \u0995\u09c1\u099b \u09a6\u09c7\u09b0 \u09ac\u09be\u09a6 \u0986\u09a8\u09cd\u09a6\u09be\u09b0 \u0998\u09c1\u099a\u09be\u09b2\u09bf\u09df\u09be    \u09ac\u09be\u09b9\u09be\u09b0 \u0995\u09be\u09b0\u0995\u09c7 \u09ac\u09cd\u09af\u09be\u09a0\u09be\u09b2\u09bf\u09df\u09be     \u09ae\u09c1 \u09ae\u09c7 \u09b2\u09c7\u09b2\u09bf\u09df\u09be  ", "label": 1}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The image is a collage of four different pictures, each with a woman in them. The caption is in a foreign language, but the pictures themselves are not hateful or not-hateful.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/chosha (2).jpg", "text": "\u0986\u09ae\u09be\u09b0 \u09ac\u09a8\u09cd\u09a7\u09c1    \u0986\u09b0 \u0986\u09ae\u09bf ", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The meme is not hateful, it is just a funny picture of a man and woman in bed.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/ovodro_img (489).jpg", "text": "\u09a6\u09be\u09a6\u09be \u0995\u09cb\u09a5\u09be\u09df \u09af\u09be\u09ac\u09c7\u09a8 ?  \u09af\u09c7\u0995\u09cb\u09a8 \u098f\u0995\u099f\u09be \u09ac\u09be\u0982\u09b2\u09be \u09ae\u09a6\u09c7\u09b0 \u0995\u09be\u0989\u09a8\u09cd\u099f\u09be\u09b0\u09c7 \u09a8\u09be\u09ae\u09bf\u09df\u09c7 \u09a6\u09c7 ", "label": 1}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The image is a meme that is not hateful, but it is a meme that is hateful.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/TR (264).jpg", "text": "\u09ae\u09c7\u09df\u09c7 \u09ab\u09b0\u09bf\u09a6\u09aa\u09c1\u09b0 \u0997\u09ad\u0983 \u0997\u09be\u09b0\u09cd\u09b2\u09b8 \u09b8\u09cd\u0995\u09c1\u09b2\u09c7\u09b0 \u09ab\u09be\u09b0\u09cd\u09b8\u09cd\u099f \u0997\u09be\u09b0\u09cd\u09b2     \u09ae\u09c7\u09df\u09c7\u099f\u09be \u09ab\u09b0\u09bf\u09a6\u09aa\u09c1\u09b0\u09c7\u09b0 \u09b8\u09ae\u09b8\u09cd\u09a4 \u099b\u09c7\u09b2\u09c7\u09b0 \u0995\u09cd\u09b0\u09be\u09b6       \u09ae\u09c7\u09df\u09c7\u09b0 \u09ac\u09be\u09aa \u09aa\u09c7\u09df\u09be\u099c \u09ac\u09cd\u09af\u09ac\u09b8\u09be\u09df\u09c0   ", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The image is a meme that is not hateful, it is a funny picture of a man in a hospital with a caption that is not intended to harm or mock anyone.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/Halal Memes (202).jpg", "text": "\u0986\u09ae\u09be\u09b0 \u09aa\u09cb\u09b8\u09cd\u099f\u0997\u09c1\u09b2\u09bf \u09a6\u09c7\u0996\u09be\u09b0 \u09aa\u09b0\u09c7,      \u09b0\u09bf\u09b2\u09c7\u099f\u09bf\u09ad\u0983-", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The meme is not hateful, it is just a funny picture of a woman with a surprised look on her face.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/KAM (188).png", "text": "\u0985\u09a8\u09a8\u09cd\u09a4 \u099c\u09b2\u09bf\u09b2 \u0997\u09b0\u09ae \u09b2\u09be\u0997\u09be\u09b0 \u0995\u09be\u09b0\u09a8\u09c7 \u09ab\u09cd\u09af\u09be\u09a8 \u099b\u09be\u09b0\u09b8\u09bf\u09b2\u09cb! ...  \u09ab\u09b2\u09be\u09ab\u09b2", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The image is a meme that is not hateful, it is just a funny picture of a man with a fan in front of him.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/Bangla Thug Life (169).jpg", "text": "\u09ad\u09be\u09ac\u09bf \u09ad\u09be\u0987\u0995\u09c7 \u09ac\u09b2\u09c7\u09a8 \u0996\u09be\u099f \u099a\u09c7\u099e\u09cd\u099c \u0995\u09b0\u09a4\u09c7 \u09a8\u09be\u09b9\u09df \u0985\u09ad\u09cd\u09af\u09be\u09b8    \u0995\u09c7\u09a8 ? \u0986\u09aa\u09a8\u09be\u09b0 \u099c\u09cd\u09ac\u09b2\u09c7 \u09a8\u09be\u0995\u09bf   \u098f\u0995\u09ac\u09be\u09b0 \u0986\u09ae\u09be\u09b0 \u09b8\u09cd\u09ac\u09be\u09ae\u09c0\u09b0\u09c7 \u09ac\u09bf\u09a6\u09c7\u09b6 \u09a5\u09c7\u0995\u09c7 \u0986\u09b8\u09a4\u09c7 \u09a6\u09c7\u09a8 \u09a4\u09be\u09b0\u09aa\u09b0 \u09a6\u09c7\u0996\u09be\u0987\u09df\u09be \u09a6\u09bf\u09ae\u09c1 ", "label": 1}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The meme is not hateful, it is not intended to denigrate, vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status. It is a meme that is not hateful.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/ovodro_img (1063).jpg", "text": "\u09af\u0996\u09a8 \u09ac\u09c1\u099d\u09a4\u09c7 \u09aa\u09be\u09b0\u09c7\u09a8 Bhuvan \u09ac\u09be\u09ae \u09b9\u0993\u09df\u09be \u09b8\u09a4\u09cd\u09a4\u09cd\u09ac\u09c7\u0993 \u09a4\u09be\u09b0 17 \u09ae\u09bf\u09b2\u09bf\u09df\u09a8  Subscribers ", "label": 1}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The meme is not hateful, it is just a funny picture of three people in a cartoonish setting.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/chintashil (334).jpg", "text": "when you wanna write an application perfectly*    Teacher-     \u098f\u09ad\u09be\u09ac\u09c7 \u09a8\u09df    \u098f\u09ad\u09be\u09ac\u09c7 \u09b6\u09c1\u09b0\u09c1 \u0995\u09b0 ", "label": 1}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The meme is a picture of a woman with the words 'when you wanna write an application for a teacher' above it. The meme is not hateful, but it is not hateful either.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/ovodro_img (1144).jpg", "text": "\u09b2\u09c7\u09a8\u09bf\u09a8 \u09ac\u09cb\u099d\u09be\u09a8\u09cb\u09b0 \u099c\u09a8\u09cd\u09af \u09af\u0996\u09a8 \u09ab\u09be\u0981\u0995\u09be \u09ab\u09cd\u09b2\u09be\u099f\u09c7\u09b0 \u0985\u09ad\u09be\u09ac \u09aa\u09dc\u09c7 \u09a4\u0996\u09a8 \u09a8\u09a4\u09c1\u09a8 \u09aa\u09be\u09b0\u09cd\u099f\u09bf \u0985\u09ab\u09bf\u09b8 \u09ac\u09be\u09a8\u09be\u09a8\u09cb\u09b0 \u099c\u09a8\u09cd\u09af \u099f\u09be\u0995\u09be \u09a4\u09cb\u09b2\u09c7\u09a8 \u0995\u09be\u09b0\u09a8 \u09a4\u09be\u09a6\u09c7\u09b0 \u09aa\u09be\u09b0\u09cd\u099f\u09bf \u0985\u09ab\u09bf\u09b8 \u09b8\u09be\u09b0\u09be\u099c\u09c0\u09ac\u09a8 \u09ab\u09be\u0995\u09be\u0987 \u09a5\u09be\u0995\u09ac\u09c7  ", "label": 1}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The meme is a political one, with a man holding a red flag and a group of people in the background. The meme is not hateful, but it is a political one.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/KAM (9).png", "text": "\u09ac\u09b2\u09a4\u09cb \u09b8\u09a4\u09a4\u09be\u09b0 \u09b8\u09b0\u09cd\u09ac\u09cb\u099a\u09cd\u099a \u09b8\u09c0\u09ae\u09be \u0995\u09bf? \u09b8\u09cd\u09af\u09be\u09b0, \u09aa\u09b0\u09c0\u0995\u09cd\u09b7\u09be\u09b0 \u09b9\u09b2\u09c7 \u09ac\u09b8\u09c7 \u09a8\u0995\u09b2 \u0995\u09b0\u09be\u09b0 \u099a\u09bf\u09b0\u0995\u09c1\u099f \u0996\u09c1\u09b2\u09c7 \u09ae\u09c1\u0996\u09b8\u09cd\u09a4 \u0995\u09b0\u09c7 \u09a8\u09bf\u09df\u09c7 \u09a4\u09be\u09b0\u09aa\u09b0 \u09aa\u09b0\u09c0\u0995\u09cd\u09b7\u09be\u09b0 \u0996\u09be\u09a4\u09be\u09df \u09b2\u09c7\u0996\u09be!", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The image is a meme that is not hateful, but it is a funny and interesting image.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/tangaila (346).jpg", "text": "\u0989\u09a6\u09cd\u09af\u09be\u09a8\u09c7\u09b0 \u09aa\u09bf\u099b\u09a8\u09c7 \u09aa\u09cd\u09b0\u09b8\u09cd\u09b0\u09be\u09ac\u09c7\u09b0 \u099c\u09be\u09df\u0997\u09be\u09df \u09af\u09be\u0993\u09df\u09be \u09ac\u09bf\u09a6\u09cd\u09af\u09ae\u09be\u09a8 -   \u09ad\u09be\u0987... \u0997\u09a8\u09cd\u09a7\u09c7 \u09a5\u09be\u09b9\u09cb\u09a8 \u09af\u09be\u0987\u09a4\u09be\u09b8\u09c7 \u09a8\u09be ! ", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The image is a meme that is not hateful, it is a funny picture of two men looking at a sign. The sign is written in a foreign language, and the caption is in English. The meme is not hateful, it is just a funny picture of two men looking at a sign.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/bamboo-vaiya (302).jpg", "text": " \u09a8\u09c1\u09a8\u09c1     \u09ac\u09be\u09dc\u09be  ", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The meme is a cartoon of a cat with a red nose, and the caption is in Hindi. The caption is a statement about the cat's nose, and it is not hateful.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/ovodro_img (596).jpg", "text": "\u0986\u09ae\u09be\u09b0 \u09a8\u09cb\u09ac\u09c7\u09b2 \u099f\u09be \u09af\u09c7 \u0995\u09cb\u09a5\u09be\u09df \u09b9\u09be\u09b0\u09bf\u09df\u09c7 \u0997\u09c7\u09b2 \u0986\u09b0 \u09aa\u09c7\u09b2\u09be\u09ae \u09a8\u09be !    \u09b9\u09be\u09b0\u09bf\u09df\u09c7 \u09af\u09be\u0987\u09a8\u09bf \u09a4\u09cb \u09a6\u09be\u09a6\u09c1 \u0964   \u098f\u0987\u09a4\u09cb \u0986\u09ae\u09bf \u09a8\u09cb\u09ac\u09c7\u09b2 ", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The image is a meme that is not hateful, it is a funny picture of a man playing a guitar with a caption that is not intended to harm or denigrate any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/bamboo-vaiya (155).jpg", "text": "doing sex with boys   Doing sex with girls   Using dildo   Ami amr phone ta vibration mode kore vitore dhukay rakhbo tumi evabei msger por msg korte thako ok ", "label": 1}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The meme is not hateful, it is just a joke. It is a meme that is not hateful, it is just a joke. The meme is a joke and not meant to be taken seriously. The meme is a joke and not meant to be taken seriously.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/nurani-memes (81).jpg", "text": "Son :  Dad, Why my freinds name is ador ?  \u09b6\u09bf\u0995\u09cd\u09b7\u09be\u09ae\u09a8\u09cd\u09a4\u09cd\u09b0\u09c0\u0983 Because his father can't stop adoring him  Son: Ooh, Thanks dad !   \u09b6\u09bf\u0995\u09cd\u09b7\u09be\u09ae\u09a8\u09cd\u09a4\u09cd\u09b0\u09c0: It's okay,   \u09aa\u09cd\u09b0\u09b6\u09cd\u09a8\u09aa\u09a4\u09cd\u09b0 \u09ab\u09be\u09b8 \u0964 ", "label": 1}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The image is a meme that is not hateful, but it is a meme that is not hateful.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/tangaila (270).jpg", "text": "\u0995\u09c1\u09ae\u09c1\u09a6\u09bf\u09a8\u09c0\u09b0 \u0995\u09cb\u09a8 \u09ae\u09c7\u09df\u09c7\u09b0 \u09a8\u09c1\u09a1\u09b8 \u09ad\u09be\u0987\u09b0\u09be\u09b2 \u09b9\u0993\u09df\u09be\u09b0 \u09aa\u09b0 \u09af\u0996\u09a8 \u0985\u09a8\u09cd\u09af \u09ae\u09c7\u09df\u09c7\u09a6\u09c7\u09b0 \u09ac\u09ab\u09b0\u09be \u09a8\u09c1\u09a1\u09b8 \u099a\u09be\u09df   \u09b2\u09c7 \u0995\u09c1\u09ae\u09c1\u09a6\u09bf\u09a8\u09c0\u09df\u09be\u09a8 \u0995\u09be\u09b2\u09a8\u09be\u0997\u09bf\u09a8 -    Are you comedy me   ", "label": 1}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The meme is a picture of a man with a caption that says "Are you comedy me?" The caption is in a foreign language, and the meme is not hateful.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/Memeholics (258).jpg", "text": "\u09ad\u09be\u09b2\u09cb \u09b9\u0987\u09df\u09be \u0997\u09c7\u099b\u09bf \u09a8\u09df\u09a4\u09cb \u09ae\u09c1\u0996 \u09a6\u09bf\u09df\u09be \u0995\u09bf\u099b\u09c1 \u0986\u0987\u099b\u09bf\u09b2 ", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The meme is not hateful, it is not intended to denigrate, vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/TR (311).jpg", "text": "\u099a\u09c1\u09ae\u09be\u099a\u09c1\u09ae\u09bf \u09b8\u09b0\u0995\u09be\u09b0\u09c0 \u09ac\u09bf\u09a6\u09cd\u09af\u09be\u09b2\u09df      \u098f\u099f\u09be \u09a6\u09c7\u0996\u09be\u09b0 \u09aa\u09b0\u0983-   \u0990 \u099b\u09be\u09dc \u0986\u09ae\u09be\u09b0\u09c7    \u0986\u09ae\u09bf \u0986\u099c\u0995\u09c7\u0987 \u09ab\u09b0\u09bf\u09a6\u09aa\u09c1\u09b0 \u099b\u09c7\u09dc\u09c7 \u09b0\u09be\u0999\u09cd\u0997\u09be\u09ae\u09be\u099f\u09bf \u099a\u09b2\u09c7 \u09af\u09be\u09ac\u09cb ", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The image is a meme that is not hateful, it is just a funny picture of two men wrestling on the field.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/TR (278).jpg", "text": " \u09aa\u09c1\u09b0\u09be\u09a8 \u09b8\u09cd\u099f\u09cd\u09af\u09be\u09a8\u09cd\u09a1\u09c7\u09b0 \u09aa\u09c2\u099c\u09be\u09ae\u09a8\u09cd\u09a1\u09aa\u09c7 \u0997\u09bf\u09df\u09c7 \u09af\u0996\u09a8 \u09a4\u09c1\u09ae\u09bf \u098f\u0995\u099d\u09be\u0995 \u09b8\u09c1\u09a8\u09cd\u09a6\u09b0\u09c0 \u09b2\u09b2\u09a8\u09be \u09a6\u09c7\u0996\u09cb    \u09a4\u0996\u09a8 \u09a4\u09c1\u09ae\u09bf\u0983-     \u0993  \u0993  \u0993 ... \u0995\u09bf \u09b2\u09be\u0995\u099a\u09c7 !! ", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The meme is a picture of a man with sunglasses on, and the caption is in Bengali. The caption is a quote from a Bengali movie, and it is not hateful.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/tangaila (260).jpg", "text": "\u09a4\u09c1\u09ae\u09bf  Tangaila sarcasm \u09aa\u09c7\u099c\u09c7\u09b0 \u098f\u09a1\u09ae\u09bf\u09a8   \u09b9\u09cd\u09af\u09be\u0981    You deserve a kiss ", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The meme is not hateful, it is just a funny joke between two people. The meme is not hateful, it is just a funny joke between two people.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/CM (645).jpg", "text": "\u0986\u09ae\u09bf*    What do you want ?   \u09ac\u09be\u09b8\u09be\u09df \u09ac\u09c7\u09dc\u09be\u09a4\u09c7 \u0986\u09b8\u09be \u099b\u09cb\u099f \u09ac\u09be\u099a\u09cd\u099a\u09be *     Games actually  ", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The meme is a comic strip with a hulk character in it, and the caption is in a foreign language. The meme is not hateful, but it is not hateful either.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/CM (233).jpg", "text": "\u0986\u09aa\u09a8\u09be\u09b0\u09be \u099a\u09cb\u09b0 \u09b9\u0987\u09b2\u09c7\u0993 , \u09ae\u09be\u09a8\u09c1\u09b7 \u09ad\u09be\u09b2\u09cb ", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The image is a meme that is not hateful, it is a group of people in a forest with a caption that says 'hateful'.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/CM (264).jpg", "text": "\u09ac\u09dc\u09ad\u09be\u0987\u09a6\u09c7\u09b0 \u09b8\u09be\u09a5\u09c7 \u09af\u0996\u09a8 \u098f\u09b2\u09be\u0995\u09be\u09df \u0995\u09cd\u09b0\u09bf\u0995\u09c7\u099f \u0996\u09c7\u09b2\u09bf*     \u0993\u09ad\u09be\u09b0\u09c7\u09b0 \u09b6\u09c7\u09b7 \u09ac\u09b2\u09c7\u09b0 \u09b8\u09ae\u09df\u0983   Run.   ", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The meme is a picture of a man with a caption that says "run" in a foreign language. The caption is not hateful, but it is a meme that is meant to be funny.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/bangla-gag (10).png", "text": "\u09a4\u09cb\u09ae\u09be\u09b0 \u09a8\u09be\u09ae \u0995\u09bf ?  LUKE WRIGHT     OKAY ", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The image is a meme that is not hateful, but it is a funny picture of two men with a caption that says 'okay'.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/TR (108).jpg", "text": "We all have that one friend   \u09ae\u09be\u09ae\u09be \u0995\u09bf\u099b\u09c1 \u09aa\u09dc\u09b8\u09cb\u09b8 ??   \u098f\u0995\u099f\u09be \u09b2\u09be\u0987\u09a8\u0993 \u09aa\u09dc\u09bf\u09a8\u09be\u0987 \u09b0\u09c7 \u09ae\u09be\u09ae\u09be \u09ac\u0987\u0987 \u09a4\u09cb \u0995\u09bf\u09a8\u09bf\u09a8\u09be\u0987 !   \u0986\u09ae\u09be\u09b0\u09c7 \u09a6\u09bf\u09df\u09be \u098f\u09a1\u09bf \u09b9\u0987\u09ac\u09a8\u09be !  ", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The image is a meme that is not hateful, it is just a funny picture of two people with a caption that asks if they have that one friend. The meme is not hateful, it is just a funny picture.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/nurani-memes (113).jpg", "text": "When the examiner suddenly starts coming towards you while you were copying and takes the paper of the boy sitting beside you    I just dodged a bullet madarchod ! ", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The meme is not hateful, it is just a funny joke. The man in the picture is wearing a hat and a shirt with a funny message. The meme is not hateful, it is just a funny joke.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/TR (552).jpg", "text": "\u0986\u09ae\u09bf   \u099d\u09bf\u09b2\u099f\u09c1\u09b2\u09c0\u09b0 \u09b8\u09cd\u09a5\u09be\u09a8\u09c0\u09df   \u09ac\u09be\u09b8\u09bf\u09a8\u09cd\u09a6\u09be    \u0986\u09b8\u09b2\u09c7 \u0986\u09ae\u09be\u09b0 \u0985\u09b0\u09bf\u099c\u09bf\u09a8\u09be\u09b2 \u09ac\u09be\u09dc\u09bf \u09ad\u0997\u09ac\u09be\u09a8\u09c7\u09b0 \u099a\u09b0\u09c7  ", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The image is a meme that is not hateful, it is a funny advertisement for a product.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/KAM (63).jpg", "text": "\u098f\u0997\u09c1\u09b2\u09be\u09b0\u09c7 \u0995\u09a8\u09b8\u09be\u09b0\u09cd\u099f \u09ac\u09b2\u09c7? \u098f\u09b0 \u099a\u09c7\u09df\u09c7 \u0986\u09ae\u09be\u09b0 \u09ac\u0989 \u09ad\u09be\u09b2 \u0997\u09be\u09df \u0995\u09ae\u099b\u09c7 \u0995\u09ae \u09b9\u09be\u09b8\u09be\u0987\u09a4\u09c7 \u09a4\u09cb \u09aa\u09be\u09b0\u09a4\u09be\u09ae", "label": 1}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The image is a poster with a man and a woman in it, and the poster is advertising a news program. The poster is in a foreign language, possibly Bengali.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/ovodro_img (1053).jpg", "text": "Girl's     Girl's Lite", "label": 1}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: A group of people are shown in a meme, with the caption 'girls' life'. The meme is not hateful, but it is not hateful either.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/bamboo-vaiya (181).jpg", "text": "*\u09ac\u09bf\u09b8\u09bf\u098f\u09b8 \u0995\u09cd\u09af\u09be\u09a1\u09be\u09b0    *\u09b8\u09c1\u09a8\u09cd\u09a6\u09b0\u09c0 \u09ae\u09be\u0987\u09df\u09be  ", "label": 1}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The meme is not hateful, it is just a cute picture of two cats with a caption in Bengali.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/bamboo-vaiya (12).jpg", "text": "\u09ac\u0989 \u09af\u09cc\u09a4\u09c1\u0995 \u09a6\u09bf\u09b8\u09c7 \u098f\u09b8\u09ac \u0995\u09bf \u0995\u09b0\u099b\u09bf\u09b8 !   -\u09a4\u09cb\u09ae\u09be\u09b0 \u09ac\u0989\u09ae\u09be \u09b6\u09c7\u09ad \u0995\u09b0\u09c7 \u09a8\u09be\u0987 ", "label": 1}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The image is a meme that is not hateful, it is a black and white photo of three women with a caption in a foreign language.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/KAM (123).jpg", "text": "\u09ac\u09c3\u09b7\u09cd\u099f\u09bf \u09b9\u09df\u09a8\u09be \u0995\u09c7\u09a8? \u0995\u09bf \u0995\u09b0\u09be \u09af\u09be\u09df... \u09ae\u09cd\u09af\u09be\u09a1\u09be\u09ae \u09ae\u09c7\u0998\u0995\u09c7 \u09a8\u09be\u09dc\u09be \u09a6\u09bf\u09df\u09c7 \u09a6\u09c7\u0996\u09c7\u09a8", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The image is a political cartoon that is not hateful, it is a political statement.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/KAM (37).png", "text": "\u099c\u09bf \u0986\u09aa\u09be, \u09ac\u09b2\u09c7\u09a8 \u099c\u09bf\u09df\u09be\u09b0\u09c7 \u0995\u09bf \u09a6\u09b2\u09c7 \u09a8\u09c7\u09df\u09be\u09b0 \u09ac\u09cd\u09af\u09ac\u09b8\u09cd\u09a5\u09be \u0995\u09b0\u09be \u09af\u09be\u09df \u09a8\u09be?", "label": 1}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The meme is not hateful, it is just a picture of two women talking on their phones.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/CM (320).jpg", "text": "\u099a\u09be\u0981\u09a6\u09aa\u09c1\u09b0\u09c7\u09b0 \u09ae\u09be\u09a8\u09c1\u09b7*     \u09a6\u09c7\u09b6\u09c7\u09b0 \u09b8\u09ac\u09be\u09b0 \u09b8\u09be\u09a5\u09c7 \u0988\u09a6 \u0989\u09a6\u09af\u09be\u09aa\u09a8 \u0995\u09b0\u09be*        \u09b8\u09cc\u09a6\u09bf\u09b0 \u09b8\u09ac\u09be\u09b0 \u09b8\u09be\u09a5\u09c7 \u0988\u09a6 \u0989\u09a6\u09af\u09be\u09aa\u09a8 \u0995\u09b0\u09be*  ", "label": 1}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The meme is not hateful, it is just a funny picture of a girl with a stuffed animal on her head.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/Bangla Thug Life (11).jpg", "text": "\u09b6\u09bf\u0995\u09cd\u09b7\u09bf\u0995\u09be  Faqboi  \u09ac\u09be\u09ac\u09be", "label": 1}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The meme is not hateful, it is not intended to denigrate, vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/ovodro_img (163).jpg", "text": "\u09aa\u09c2\u099c\u09cb\u09a4\u09c7 \u0998\u09c1\u09b0\u09a4\u09c7 \u09af\u09be\u09ac\u09bf \u0986\u09ae\u09be\u09b0 \u09b8\u09be\u09a5\u09c7 ?   \u09af\u09c7\u09a4\u09c7 \u09aa\u09be\u09b0\u09bf \u09af\u09a6\u09bf \u0986\u09ae\u09be\u0995\u09c7 \u09ab\u09c1\u099a\u0995\u09be\u09b0 \u09a6\u09cb\u0995\u09be\u09a8\u09c7 \u09a8\u09bf\u09df\u09c7 \u09af\u09be\u09b8 \u0964 \u0986\u09ae\u09bf \u09af\u09a4 \u09ab\u09c1\u099a\u0995\u09be \u0996\u09be\u09ac \u09a4\u09a4 \u09ab\u09c1\u099a\u0995\u09be\u0987 \u0996\u09be\u0993\u09df\u09be\u09a4\u09c7 \u09b9\u09ac\u09c7     \u0986\u09b0\u09c7 \u09aa\u09be\u0997\u09b2\u09bf \u0986\u09ae\u09bf \u09a4\u09cb \u0987\u09df\u09be\u09b0\u09cd\u0995\u09bf \u09ae\u09be\u09b0\u099b\u09bf\u09b2\u09be\u09ae    (\u09ae\u09a8\u09c7 \u09ae\u09a8\u09c7\u0983 \u09ae\u09c7\u09df\u09c7\u09a6\u09c7\u09b0 \u09ab\u09c1\u099a\u0995\u09be\u09b0 \u09a6\u09cb\u0995\u09be\u09a8 \u0986\u09b0 \u09ac\u09be\u09a8\u09b0 \u0995\u09c7 \u0995\u09b2\u09be \u09ac\u09be\u0997\u09be\u09a8 \u09a6\u09c7\u0996\u09be\u09a8\u09cb \u09b8\u09ae\u09be\u09a8 \u099c\u09bf\u09a8\u09bf\u09b8 )", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The image is a meme that is not hateful, it is a comical scene of two people talking to each other.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/Halal Memes (49).jpg", "text": "23 years old Unmarried me attending a family function     Relatives: \u09a4\u09b0 \u0995\u09bf \u099c\u09be\u09ae\u09be\u0987 \u09b2\u09be\u0997\u09ac\u09cb ? ", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The meme is not hateful, it is just a funny picture of two men with a caption that is not hateful.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/ovodro_img (351).jpg", "text": "\u09aa\u09be\u09b0\u09cd\u09a5\u0995\u09cd\u09af \u09ac\u09c1\u099d\u09c1\u09a8   \u098f\u099f\u09be\u09df \u09a7\u09cb\u09a8 \u0996\u09be\u0981\u09dc\u09be \u09b9\u09df    \u0986\u09b0 \u098f\u099f\u09be\u09df \u09b2\u09cb\u09ae ", "label": 1}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The meme is not hateful, it is just a funny picture of a woman in a bra and a man in a shirt.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/TR (404).jpg", "text": "Frnd : - \u09a6\u09cb\u09b8\u09cd\u09a4 \u099a\u09b2 \u09b8\u09c2\u09b0\u09cd\u09af\u09ae\u09c1\u0996\u09c0\u09b0 \u09ac\u09be\u0997\u09be\u09a8 \u09a5\u09c7\u0995\u09c7 \u0998\u09c1\u09b0\u09c7 \u0986\u09b8\u09bf   me :-     \u0986\u09ae\u09cd\u09ae\u09c1 \u09a6\u09bf\u09ac\u09c7 \u09a8\u09be ", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The image is a meme that is not hateful, but it is a meme that is not hateful.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/ovodro_img (538).jpg", "text": "\u098f\u099f\u09be black hole    \u0986\u09b0 \u0986\u09ae\u09be\u09a6\u09c7\u09b0 \u099f\u09be red hole", "label": 1}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The meme is a picture of a woman with a red hole in the center of her face, with the words "hateful" and "not-hateful" written above it.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/ovodro_img (658).jpg", "text": "\u09ac\u09a8\u09cd\u09a7\u09c1\u09b0 \u09ac\u09cb\u09a8\u09c7\u09b0 \u09b8\u09be\u09a5\u09c7 \u09aa\u09cd\u09b0\u09c7\u09ae \u0995\u09b0\u09b2\u09c7 \u09b0\u09cb\u099c gf \u098f\u09b0 \u09ac\u09be\u09dc\u09bf\u09a4\u09c7 \u09af\u09c7\u09df\u09c7 \u09a6\u09c7\u0996\u09be \u0995\u09b0\u09be \u09af\u09be\u09df     \u0986\u09ac\u09be\u09b0 \u09a7\u09b0\u09be\u0993 \u09aa\u09b0\u09ac\u09c7\u09a8 \u09a8\u09be ", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The meme is a picture of a man with a phone to his ear, and the caption is in a foreign language. The meme is not hateful, but it is not hateful either.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/bamboo-vaiya (520).jpg", "text": "People who pronounce \u0995\u09be\u0981\u09a5\u09be\u0983    People who pronounce \u0995\u09cd\u09b7\u09cd\u09af\u09be\u09a4\u09be\u0983 ", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The meme is a comparison between two different types of people who pronounce words differently. The left side of the meme features a man who pronounces words in a way that is considered hateful. The right side of the meme features a man who pronounces words in a way that is not considered hateful. The meme is a comparison between two different types of people who pronounce words differently.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/bamboo-vaiya (395).jpg", "text": "When you accidentally open your front camera but you ar Sheikh Hasina", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: A woman is shown in a meme with the caption 'when you accidentally open your front camera but you are Shehzad Hasan.' The meme is not hateful, but it is a mistake.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/bangla-troll (7).jpg", "text": "\u09ae\u09be \u09b8\u09bf\u09b0\u09bf\u09df\u09be\u09b2 \u09a4\u09cb  \u09b6\u09c7\u09b7... \u098f\u0996\u09a8 \u0995\u09bf \u0986\u09ac\u09be\u09b0 \u09a8\u09be\u09a8\u09c0 \u09b8\u09bf\u09b0\u09bf\u09df\u09be\u09b2\u09c7\u09b0 \u0986\u0997\u09ae\u09a8 \u0998\u099f\u09ac\u09cb \u09a8\u09be\u0995\u09bf ?", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The meme is not hateful, it is just a funny joke.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/Memeholics (35).jpg", "text": "oops got arrested     only for few months ", "label": 1}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The image is a split screen with two different meme options, one labeled 'hateful' and the other labeled 'not-hateful'.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/ovodro_img (1205).jpg", "text": "Taimur \u09af\u0996\u09a8 \u099c\u09be\u09a8\u09a4\u09c7 \u09aa\u09be\u09b0\u09c7 \u09a4\u09be\u09b0 \u09ae\u09be Kareena Kapoor \u0986\u09ac\u09be\u09b0\u0993 Pregnant \u098f\u09ac\u0982 \u09a4\u09be\u09b0 \u09a8\u09be\u09ae-\u09af\u09b8 , \u09b8\u09ae\u09cd\u09aa\u09a4\u09cd\u09a4\u09bf \u09b8\u09ac\u0995\u09bf\u099b\u09c1\u09b0 \u09ad\u09be\u0997 \u09b9\u09a4\u09c7 \u099a\u09b2\u099b\u09c7 !     \u098f\u099f\u09be \u09b6\u09be\u09b2\u09be \u09ac\u09c7\u0988\u09ae\u09be\u09a8\u09c7\u09b0 \u09a6\u09c1\u09a8\u09bf\u09df\u09be  ", "label": 1}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The meme is a picture of a child with a caption that is not hateful.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/ovodro_img (619).jpg", "text": "\u09ac\u09be\u09dc\u09bf\u09a4\u09c7 \u09af\u0996\u09a8 \u0995\u09cb\u09a8\u09ad\u09be\u09ac\u09c7 \u099f\u09be\u0995\u09be \u09b9\u09be\u09b0\u09bf\u09df\u09c7 \u09af\u09c7\u09a4   10 years old me:- \u09ae\u09be \u0986  \u0986  \u0986   \u0986\u09ae\u09bf \u099a\u09c1\u09b0\u0987\u0987\u0987 \u0995\u09b0\u09bf\u09a8\u09bf  ", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The meme is not hateful, it is just a funny picture of a man making a funny face.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/chintashil (694).jpg", "text": "\"\u09aa\u09c1\u09b0\u09cb \u09aa\u09c3\u09a5\u09bf\u09ac\u09c0 \u098f\u0995\u09a6\u09bf\u0995\u09c7 \u0986\u09b0 \u0986\u09ae\u09bf \u0985\u09a8\u09cd\u09af\u09a6\u09bf\u0995\u09c7 \" ", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The man on the motorcycle is in a busy city street, and the text on the meme is in a foreign language. The meme is not hateful, but it is not hateful either.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/TR (309).jpg", "text": "\u0986\u0997\u09be\u09ae\u09c0 \u09b8\u09aa\u09cd\u09a4\u09be\u09b9 \u09a5\u09c7\u0995\u09c7 \u09b8\u09c7\u09ae\u09bf\u09b7\u09cd\u099f\u09be\u09b0 \u09ab\u09be\u0987\u09a8\u09be\u09b2 \u09b6\u09c1\u09a8\u09be\u09b0 \u09aa\u09b0 \u0985\u09ac\u09b8\u09cd\u09a5\u09be -    * \u09ae\u09be\u09a5\u09be \u09a7\u09b0\u09b8\u09c7    * \u09ac\u09c1\u0995\u09c7\u09b0 \u09ac\u09cd\u09af\u09be\u09a5\u09be\u09a4\u09c7 \u09ae\u09b0\u09b2\u09be\u09ae     *\u0986\u09b8\u09b2\u09c7\u0987 \u0995\u09bf \u0986\u09ae\u09bf \u0986\u09b0 \u09ac\u09be\u0981\u099a\u09ac\u09cb \u09a8\u09be ! ", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The image is a meme that is not hateful, it is a funny picture of an old man with a heart attack. The meme is not hateful, it is just a funny picture.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/TR (258).jpg", "text": "\u09ab\u09b0\u09bf\u09a6\u09aa\u09c1\u09b0 \u099c\u09bf\u09b2\u09be \u09b8\u09cd\u0995\u09c1\u09b2\u09c7 \u099a\u09be\u09a8\u09cd\u09b8 \u09aa\u09be\u0993\u09df\u09be\u09b0 \u09aa\u09b0 \u09aa\u09cb\u09b2\u09be\u09aa\u09be\u0987\u09a8 \u098f\u09a4 \u09ad\u09be\u09ac \u09a6\u09c7\u0996\u09be\u09df \u0995\u09c7\u09a8\u09cb ?    Faridpuirra public :-   \u098f\u099f\u09be\u0987 \u09b8\u09be\u0987\u09a8\u09cd\u09b8 ", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The image is a meme that is not hateful, it is just a funny picture of a man with a funny caption.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/TR (98).jpg", "text": "\u0997\u09cb\u09df\u09be\u09b2\u099a\u09be\u09ae\u099f ( \u0986\u09b2\u09c0\u09aa\u09c1\u09b0 \u09ac\u09cd\u09b0\u09bf\u099c )    \u0986\u09b2\u09c0\u09aa\u09c1\u09b0 ", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The meme is not hateful, it is just a play on words.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/ovodro_img (600).jpg", "text": "if '\u09ac\u09cc\u09a6\u09bf \u099c\u09be\u09a8\u09a4\u09c7 \u09aa\u09be\u09b0\u09c7 \u09a6\u09be\u09a6\u09be\u09b0 \u0985\u09a8\u09cd\u09af \u0995\u09be\u09b0\u0993 \u09b8\u09be\u09a5\u09c7 \u0987\u09a8\u09cd\u099f\u09c1\u09aa\u09bf\u09a8\u09cd\u099f\u09c1 \u099a\u09b2\u099b\u09c7'  had a face ", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The meme is a picture of a woman with a caption that reads 'if it explicitly intends to denigrate, vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.' The meme is not hateful, but it is a warning to be careful with what we post online.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/ovodro_img (846).jpg", "text": "\u09af\u0996\u09a8  \u09a6\u09be\u09a6\u09c1 \u09ac\u09c1\u099d\u09a4\u09c7 \u09aa\u09be\u09b0\u09c7 \u09a4\u09be\u09b0 \u09b2\u09c7\u0996\u09be \u0997\u09be\u09a8\u0997\u09c1\u09b2\u09cb\u09b0 \u09b8\u09c1\u09a8\u09cd\u09a6\u09b0 \u0995\u09b0\u09c7 \u09aa\u09cb\u0981\u09a6 \u09ae\u09c7\u09b0\u09c7 \u09a6\u09bf\u099a\u09cd\u099b\u09c7 \u09b0\u09a6\u09cd\u09a6\u09c1\u09b0 \u09b0\u09df     \u09ae\u09b0\u09c7\u0993 \u09b6\u09be\u09a8\u09cd\u09a4\u09bf \u09a8\u09c7\u0987  ", "label": 1}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The meme is a painting of an old man with a beard, and the text is in a foreign language. The meme is not hateful, but it is not hateful either.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/TR (200).jpg", "text": "\u09af\u0996\u09a8 \u09a4\u09c1\u09ae\u09bf \u09ab\u09b0\u09bf\u09a6\u09aa\u09c1\u09b0 \u099c\u09bf\u09b2\u09be \u09b8\u09cd\u0995\u09c1\u09b2\u09c7 \u09aa\u09dc\u09c7 \u09ab\u09b0\u09bf\u09a6\u09aa\u09c1\u09b0 \u09ae\u09c7\u09a1\u09bf\u0995\u09c7\u09b2\u09c7 \u09aa\u09dc\u09be \u09ae\u09c7\u09df\u09c7\u09b0 \u0989\u09aa\u09b0 \u0995\u09cd\u09b0\u09be\u09b6 \u0996\u09be\u0993    \u09a4\u09c1\u09ae\u09bf \u0997\u09be\u09b0\u09cd\u09b2\u09b8 \u09b8\u09cd\u0995\u09c1\u09b2\u09c7\u09b0 \u09ae\u09c7\u09df\u09c7    \u09ac\u09dc \u0986\u09aa\u09c1 ", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The image is a meme that is not hateful, it is a funny picture of three men standing next to a Christmas tree.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/Bangla Thug Life (121).jpg", "text": "* When you say, \" Mother Teresa is the mother of humanity\" instead of Sheikh Hasina ;", "label": 1}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The image is a meme that is not hateful, it is a picture of a woman with red eyes and the caption reads "when you say mother Teresa is the mother of humanity, Shelih Hassan." The meme is not hateful, it is a joke.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/KAM (166).png", "text": "\u098f\u0995\u099f\u09be\u0995\u09be \u09a6\u09c1\u0987\u099f\u09be\u0995\u09be \u0985\u09aa\u09cd\u09b0\u09df\u09cb\u099c\u09a8\u09c0\u09df \u0985\u0997\u09c1\u09b2\u09be \u09a4\u09c1\u09b2\u09c7 \u09a6\u09c7\u0993\u09df\u09be \u09b9\u09ac\u09c7 \u0995\u09be\u09b0\u09a8 \u0993\u0987 \u09a8\u09cb\u099f \u0997\u09c1\u09b2\u09be \u09aa\u09cd\u09b0\u09df\u09cb\u099c\u09a8\u09c0\u09df\u09a4\u09be \u0986\u09ae\u09be\u09b0 \u0995\u09be\u099b\u09c7 \u09b8\u09ac \u099a\u09c7\u09df\u09c7 \u09ac\u09c7\u09b6\u09bf", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The meme is not hateful, it is just a picture of two men with a caption that is not hateful.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/Memeholics (203).jpg", "text": "*Padma bridge has only one span left*   BD journalists:    \u0986\u09ae\u09be\u09b0 \u099a\u09bf\u09ce\u0995\u09be\u09b0 \u0995\u09b0\u09c7 \u0995\u09be\u0981\u09a6\u09a4\u09c7 \u0987\u099a\u09cd\u099b\u09be \u0995\u09b0\u099b\u09c7 ", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The meme is a picture of a woman with the caption "PADMA BRIDGE HAS ONLY ONE SPAN LEFT" and the words "Bd Journalists" above it. The meme is not hateful, but it is not hateful either.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/bangla-gag (111).jpg", "text": "THE ULTIMATE LIFE CYCLE MOST OF THE BANGLADESHI PEOPLE       GRADUATION AT 24    JOB AT 25   WEDDING AT 26     BABY AT 30    RETIREMENT 60      THEN WAIT IN AN EXPENSIVE HOSPITAL FOR THE LAST BREATH ", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The poster is a meme that is not hateful, it is just a collection of images with captions that are not meant to be taken seriously.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/netflix (179).jpg", "text": "FULL METAL ALCHEMIST BROTHERHOOD FANS BE LIKE     DAMN ALPHONSE BE LOOKING HOT ", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The meme is not hateful, it is just a funny image of a man in a suit with a helmet on.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/tangaila (271).jpg", "text": "\u0997\u09cd\u09b0\u09be\u09ae\u09c7\u09b0 \u09b8\u09cd\u0995\u09c1\u09b2\u09c7 \u09aa\u09dc\u09be\u09b0 \u09b8\u09ae\u09df    \u099f\u09be\u0982\u0997\u09be\u0987\u09b2 \u098f\u09b8\u09c7 \u0995\u09c1\u09ae\u09c1\u09a6\u09bf\u09a8\u09c0\u09a4\u09c7 \u09ad\u09b0\u09cd\u09a4\u09bf \u09b9\u09ac\u09be\u09b0 \u09aa\u09b0 ", "label": 1}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The image is a meme that is not hateful, it is a picture of a woman with a caption that is not hateful.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/CM (506).jpg", "text": "\u0997\u09cd\u09b0\u09be\u09ae\u09c7 \u09ac\u09c7\u09dc\u09be\u09a4\u09c7 \u09af\u09be\u0993\u09df\u09be\u09b0 \u09aa\u09b0 \u09af\u0996\u09a8 \u0997\u09cd\u09b0\u09be\u09ae\u09c7\u09b0 \u0995\u09c7\u0993 \u09ae\u09bf\u09a5\u09cd\u09af\u09be \u09ad\u09c1\u09a4\u09c7\u09b0 \u0997\u09b2\u09cd\u09aa \u09ac\u09be\u09a8\u09bf\u09df\u09c7 \u0986\u09ae\u09be\u0995\u09c7 \u09ad\u09df \u09a6\u09c7\u0996\u09be\u09df       Reality can be whatever I want ", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The meme is a quote from the movie Avengers, and it is not hateful.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/chintashil (933).jpg", "text": "Prakash Raj     Kazi Maruf ", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The meme is not hateful, it is just a picture of two men with different facial expressions.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/Halal Memes (199).jpg", "text": "\u09ac\u09be\u09ac\u09c1, \u09a4\u09cb\u09ae\u09be\u09b0 \u099c\u09a8\u09cd\u09ae\u09a6\u09bf\u09a8\u09c7 \u098f\u0995\u099f\u09be \u09b0\u09bf\u0982 \u09a6\u09bf\u09ac\u09cb    \u0987\u09b6 ! \u0986\u09ae\u09be\u09b0 \u09ac\u09be\u09ac\u09c1\u099f\u09be \u0986\u09ae\u09be\u09df \u0995\u09a4\u09cd\u09a4 \u09ad\u09be\u09b2\u09cb\u09ac\u09be\u09b8\u09c7 !     \u09a7\u09b0\u09bf\u0993 \u09a8\u09be \u0986\u09ac\u09be\u09b0 \u0986\u09ae\u09be\u09b0 \u09ab\u09cb\u09a8\u09c7 \u0995\u09bf\u09a8\u09cd\u09a4\u09c1 \u09ac\u09cd\u09af\u09be\u09b2\u09c7\u09a8\u09cd\u09b8 \u09a5\u09be\u0995\u09c7 \u09a8\u09be ", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The image is a meme that is not hateful, it is a funny and lighthearted scene with two people in it.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/bangla-memes (23).jpg", "text": "\u09a4\u09c1\u09ae\u09bf \u0995\u09bf \u09a7\u09b0\u09a8\u09c7\u09b0 \u09a8\u09be\u09ae\u09be\u099c\u09bf \u09ac\u09be\u09a8\u09cd\u09a6\u09be ?     \u0986\u09ae\u09bf\u0983 ", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The image is a meme that is not hateful, it is a picture of a woman with a caption that is not hateful.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/bangla-gag (94).jpg", "text": "\u09ad\u09be\u0997\u09cd\u09af \u09ad\u09be\u09b2 \u0986\u09ae\u09b0\u09be \u0993\u09df\u09be\u09a8\u09a1\u09c7\u09a4\u09c7 \u0996\u09c7\u09b2\u09bf \u09a8\u09be\u0987     \u09a8\u09be \u09b9\u09b2\u09c7 \u0995\u09cd\u09af\u09be\u09b0\u09bf\u09df\u09be\u09b0 \u09b6\u09c7\u09b7 \u09b9\u09df\u09c7 \u09af\u09be\u0987\u09a4 ! ", "label": 1}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: A meme with two men in green and yellow jerseys, one of them smiling and the other with a toothy grin. The caption is written in a foreign language, possibly Chinese.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/Bangla Thug Life (122).jpg", "text": "\u09ae\u09be\u09ae\u09be \u09ab\u09c1\u099a\u0995\u09be\u09a4\u09c7 \u098f\u0995\u09cd\u09b8\u099f\u09cd\u09b0\u09be \u099d\u09be\u09b2 \u09a6\u09bf\u09df\u09c7\u09a8*  \u0996\u09be\u0993\u09df\u09be\u09b0 \u09aa\u09b0\u09c7\u09b0 \u0985\u09ac\u09b8\u09cd\u09a5\u09be\u0983", "label": 1}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The image is a meme that is not hateful, it is a funny picture of a woman making a funny face. The meme is not hateful, it is just a funny picture.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/CM (380).jpg", "text": "\u09ac\u09be\u09b8\u09be \u09a5\u09c7\u0995\u09c7 \u099d\u0997\u09dc\u09be \u0995\u09b0\u09c7 \u09ac\u09c7\u09b0 \u09b9\u0993\u09df\u09be\u09b0 \u09aa\u09b0 \u09af\u0996\u09a8 \u0986\u09ac\u09be\u09b0 \u098f\u0995\u099f\u09c1 \u09aa\u09b0\u09c7 \u09ac\u09be\u09b8\u09be\u09df \u099a\u09b2\u09c7 \u0986\u09b8\u09bf     I came because I had no choice  ", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The image is a meme that is not hateful, but it is a quote from the movie Aquaman. The quote is from the movie Aquaman and is not hateful.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/TR (14).jpg", "text": "\u09af\u0996\u09a8 \u0986\u09ae\u09bf \u09aa\u09b0\u09c0\u0995\u09cd\u09b7\u09be\u09df \u09ac\u09a8\u09cd\u09a7\u09c1\u09b0 \u0996\u09be\u09a4\u09be \u09a6\u09c7\u0996\u09c7 \u09b2\u09bf\u0996\u09bf \u0986\u09b0 \u0993\u0987 \u09b8\u09ae\u09df \u09b8\u09cd\u09af\u09be\u09b0 \u0986\u09ae\u09be\u09b0 \u09b8\u09be\u09ae\u09a8\u09c7 \u09a6\u09bf\u09df\u09c7 \u09af\u09be\u09df     \u0986\u09ae\u09bf - ", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The image is a meme that is not hateful, it is a woman with a red sari and a caption that says 'hateful'.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/bamboo-vaiya (146).jpg", "text": "\u09e8\u09e6\u09e7\u09ef \u09b8\u09be\u09b2 \u09a5\u09c7\u0995\u09c7 \u09b8\u09c3\u099c\u09a8\u09b6\u09c0\u09b2 \u09aa\u09cd\u09b0\u09b6\u09cd\u09a8 \u09e8\u099f\u09bf \u0995\u09ae\u09bf\u09df\u09c7 \u09eb\u099f\u09bf \u0995\u09b0\u09be \u09b9\u09ac\u09c7    \u0986\u09b0\u09c7 \u09ad\u09be\u0987, \u098f\u0987\u099f\u09be prank \u099b\u09bf\u09b2\u09cb \u0990 \u09af\u09c7 \u09a6\u09c7\u0996\u09c7\u09a8 camera  ", "label": 1}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: A man is sitting in front of a blue background with a camera in the foreground. The man is wearing a suit and tie, and he is speaking to the camera. The man is sitting in front of a blue background with a camera in the foreground.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/CM (185).jpg", "text": "\u0986\u09ae\u09bf\u0983 \u09a4\u09c1\u0987 \u0986\u09ae\u09be\u09b0\u09c7 \u09aa\u09cd\u09b0\u09a5\u09ae \u09b2\u09be\u0987\u09a8 \u099f\u09be \u09a6\u09c7\u0996\u09be \u09a4\u09be\u0987\u09b2\u09c7\u0987 \u09b9\u09ac\u09c7 \u09aa\u09b0\u09c7 \u0986\u09ae\u09bf \u09b2\u09bf\u0996\u09a4\u09c7 \u09aa\u09be\u09b0\u09ac\u09cb    \u09ac\u09a8\u09cd\u09a7\u09c1\u0983  \u0986\u099a\u09cd\u099b\u09be \u09ad\u09be\u09b2\u09cb \u09ae\u09a4\u09cb \u09a6\u09c7\u0996 \u0986\u09b0 \u09a1\u09be\u0995 \u09a6\u09bf\u09ac\u09bf\u09a8\u09be   \u09aa\u09cd\u09b0\u09a5\u09ae \u09b2\u09be\u0987\u09a8 \u09b2\u09c7\u0996\u09be\u09b0 \u09aa\u09b0 \u0986\u09ac\u09be\u09b0 \u0986\u09ae\u09bf\u0983      I am once again asking for your education support ", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: A man is shown in a meme with a caption that says "I am once again asking for your education support." The meme is not hateful, but it is a political statement.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/KAM (180).png", "text": "\u0986\u09ae\u09bf \u09b0\u09cb\u099c \u09b0\u09be\u09a4\u09c7 \u0998\u09c1\u09ae\u09be\u09a8\u09cb\u09b0 \u0986\u0997\u09c7 \u09b2\u09be\u0997\u09be\u0987 \u09ac\u09bf\u099b\u09be\u09a8\u09be\u09b0 \u0989\u09aa\u09b0 \u09a6\u09be\u0981\u09dc\u09be\u0987\u09df\u09be \u09b2\u09be\u0997\u09be\u0987 \u099a\u09c7\u09df\u09be\u09b0\u09c7\u09b0 \u0989\u09aa\u09b0 \u09a6\u09be\u0981\u09dc\u09be\u0987\u09df\u09be \u09b2\u09be\u0997\u09be\u0987 \u0986\u09ae\u09bf \u09ae\u09b6\u09be\u09b0\u09c0 \u09b2\u09be\u0997\u09be\u09a8\u09cb\u09b0 \u0995\u09a5\u09be \u09ac\u09b2\u09a4\u09c7\u099b\u09bf", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The image is a meme that is not hateful, it is a political statement that is not hateful.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/ovodro_img (1404).jpg", "text": "\u0993\u09b0 \u0995\u09a5\u09be \u09b8\u09ac\u09b8\u09ae\u09df \u09ae\u09a8\u09c7 \u09aa\u09b0\u099b\u09c7 ? \u098f\u0995\u09be \u098f\u0995\u09be \u09b9\u09be\u09b8\u09bf \u09aa\u09be\u099a\u09cd\u099b\u09c7 ?   \u09b9\u09cd\u09af\u09be\u0981 , \u098f\u099f\u09be\u0987 \u09b9\u099a\u09cd\u099b\u09c7   \u09a4\u09be\u09b9\u09b2\u09c7 \u09ac\u09c1\u099d\u09c7 \u09a8\u09c7 , \u09a4\u09cb\u09b0 \u09ae\u09be\u09a5\u09be\u09b0 \u09a4\u09be\u09b0 \u0995\u09c7\u099f\u09c7 \u0997\u09cd\u09af\u09be\u099b\u09c7 !    \u09a4\u09c1\u099a\u09bf\u09df\u09be \u09b6\u09be\u09b2\u09be ", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The meme is not hateful, it is just a funny picture of two men in bed.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/ovodro_img (1294).jpg", "text": "\u0995\u09bf\u099b\u09c1 \u09b8\u09ae\u09cd\u09aa\u09b0\u09cd\u0995\u09c7\u09b0 \u09a8\u09be\u09ae \u09b9\u09df \u09a8\u09be ...", "label": 1}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The meme is a collage of pictures, including one of a snake, and the text "hateful" is written in the center of the collage.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/bamboo-vaiya (451).jpg", "text": "*Nobel \u098f\u09b0 \u09ac\u09bf\u09b0\u09c1\u09a6\u09cd\u09a7\u09c7 \u099a\u09bf\u09b2\u09cd\u09b2\u09be\u09a4\u09c7 \u09a5\u09be\u0995\u09be Public    *\u09ac\u09be\u0987\u099e\u09cd\u099a\u09cb\u09a6 \u0995\u09bf \u0995\u09b0\u099b\u09c7 \u09a8\u09be \u099c\u09be\u09a8\u09be \u0986\u09ae\u09bf ", "label": 1}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The meme is a picture of two women pointing at a cat, with the caption "Noble 39 public". The caption is in a foreign language, possibly French.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/chintashil (641).jpg", "text": "\u09a6\u09c7\u0996\u09bf\u09b8    \u0986\u099c \u09ac\u09be\u0982\u09b2\u09be\u09a6\u09c7\u09b6\u09b0\u09c7 \u09b9\u09be\u09b0\u09be\u09df \u09a6\u09bf\u09ae\u09c1 ", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The meme is not hateful, it is just a sports meme.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/ovodro_img (512).jpg", "text": "\u0997\u09be\u09b2\u09ab\u09cd\u09b0\u09c7\u09a8\u09cd\u09a1\u0983 \u09ac\u09be\u09ac\u09c1 \u0986\u099c\u0995\u09c7 \u09ac\u09be\u09dc\u09bf\u09a4\u09c7 \u0995\u09c7\u0993 \u09a8\u09c7\u0987... \u09b6\u09c1\u09a7\u09c1 \u0986\u09ae\u09bf \u098f\u0995\u09be   \u09ac\u09df\u09ab\u09cd\u09b0\u09c7\u09a8\u09cd\u09a1\u0983", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The image is a meme that is not hateful, but it is a meme that is not hateful. It is a picture of a chicken running on a sidewalk with a caption that is not hateful.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/chintashil (526).jpg", "text": "\u09ac\u09be\u0982\u09b2\u09be\u09a6\u09c7\u09b6\u0995\u09c7 \u0985\u09b8\u09cd\u099f\u09cd\u09b0\u09c7\u09b2\u09bf\u09df\u09be\u09b0 \u09b8\u09be\u09a5\u09c7 \u09ea-\u09e7 \u09ac\u09cd\u09af\u09be\u09ac\u09a7\u09be\u09a8\u09c7 \u099f\u09bf-\u09e8\u09e6 \u09b8\u09bf\u09b0\u09bf\u099c \u099c\u09bf\u09a4\u09a4\u09c7 \u09a6\u09c7\u0996\u09be\u09b0 \u09aa\u09b0\u0983     \u098f\u0996\u09a8 \u09af\u09be\u0993\u09df\u09be \u09a0\u09bf\u0995 \u09b9\u09ac\u09c7 \u09a8\u09be ,   \u09ae\u09be\u09b0\u09a7\u09cb\u09b0 \u0995\u09b0\u09a4\u09c7 \u09aa\u09be\u09b0\u09c7 ", "label": 1}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The meme is not hateful, it is just a conversation between two men.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/nurani-memes (85).jpg", "text": "Left - \u09a6\u09cb\u09b8\u09cd\u09a4 \u099a\u09b2 \u09ac\u0987 \u09ae\u09c7\u09b2\u09be \u09af\u09be\u0987  \u0964  Right - \u0995\u09bf\u09a8\u09cd\u09a4\u09c1 \u0986\u09ae\u09bf \u09a4\u09cb \u09ac\u0987 \u09aa\u09dc\u09bf\u09a8\u09be \u0964   Left -  \u09b8\u09c1\u09a8\u09cd\u09a6\u09b0 \u09b8\u09c1\u09a8\u09cd\u09a6\u09b0 \u09ae\u09be\u0987\u09df\u09be \u0986\u0987\u09ac\u09cb \u0964    Right - \u099a\u09b2 \u0964   Left - \u099a\u09b2  ", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: A meme with two men standing next to each other, one of them pointing to the other, with the caption "Hateful if it intends to denigrate, vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status."
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/ovodro_img (990).jpg", "text": "\u0986\u09aa\u09a8\u09be\u09b0 \u098f\u09ae\u09a8 \u09b8\u09cd\u09aa\u09c7\u09b6\u09be\u09b2 \u0995\u09c0 \u099f\u09cd\u09af\u09be\u09b2\u09c7\u09a8\u09cd\u099f \u0986\u099b\u09c7 \u09af\u09c7, \u0986\u09ae\u09b0\u09be \u0986\u09aa\u09a8\u09be\u0995\u09c7 \u099c\u09ac\u099f\u09be \u09a6\u09c7\u09ac ?    \u0995\u09cb\u09df\u09be\u09b0\u09be\u09a8\u09cd\u099f\u09be\u0987\u09a8\u09c7 \u09a5\u09c7\u0995\u09c7 \u09ac\u09be\u09ac\u09be\u09b0 \u09ac\u09bf\u09dc\u09bf \u099a\u09c1\u09b0\u09bf \u0995\u09b0\u09c7 \u0995\u09b0\u09c7 \u09b0\u09cb\u099c \u0996\u09c7\u09df\u09c7\u099b\u09bf , \u0995\u09c7\u0989 \u09a7\u09b0\u09a4\u09c7 \u09aa\u09be\u09b0\u09c7\u09a8\u09bf !      \u09b8\u09cd\u09af\u09be\u09b2\u09be\u09b0\u09bf \u0995\u09a4 \u09a8\u09c7\u09ac\u09c7 ?   \u0995\u09cb\u09ae\u09cd\u09aa\u09be\u09a8\u09bf\u09b0 ca \u0995\u09b0\u09c7 \u09a6\u09c7\u09ac \u09a4\u09cb\u09ae\u09be\u0995\u09c7    \u0986\u09ae\u09be\u09b0 \u09ae\u09c7\u09df\u09c7\u0995\u09c7 \u09ac\u09bf\u09df\u09c7 \u0995\u09b0\u09ac\u09c7 ?", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The image is a meme that is not hateful, it is a funny and lighthearted joke.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/chintashil (789).jpg", "text": "\u09aa\u09b0\u09c0\u0995\u09cd\u09b7\u09be\u09b0 \u09b9\u09b2 \u09a5\u09c7\u0995\u09c7 \u09ac\u09c7\u09b0 \u09b9\u0993\u09df\u09be\u09b0 \u09aa\u09b0\u09aa\u09b0\u0987  *A Random Guy :     \u098f\u0987 \u09a8\u09c7\u09a8 \u09ad\u09be\u0987 , \u0986\u09ae\u09be\u09a6\u09c7\u09b0 \u0995\u09cb\u099a\u09bf\u0982\u099f\u09be \u09a6\u09c7\u0987\u0996\u09c7\u09a8 ", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: A man is holding up a piece of paper with a meme on it that is not hateful.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/KAM (107).png", "text": "\u09af\u09c7 \u0995\u09be\u09b0\u09a3\u09c7 \u09ae\u09c7\u09df\u09c7\u09b0\u09be \u09b0\u09be\u0997 \u0995\u09b0\u09c7 \u09a4\u09c1\u09ae\u09bf \u09b0\u09c7\u0997\u09c7 \u0986\u099b\u09cb \u0995\u09c7\u09a8\u09cb? \u0986\u09ae\u09bf \u098f\u0987 \u099c\u09a8\u09cd\u09af \u09b0\u09c7\u0997\u09c7 \u0986\u099b\u09bf \u0995\u09be\u09b0\u09a3 \u09a4\u09c1\u09ae\u09bf \u099c\u09be\u09a8\u09cb \u09a8\u09be \u0986\u09ae\u09bf \u0995\u09c7\u09a8 \u09b0\u09c7\u0997\u09c7 \u0986\u099b\u09bf!", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The image is a meme that is not hateful, it is a conversation between two people.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/Memeholics (95).jpg", "text": "\u0986\u09a8\u09cd\u099f\u09bf: \u09a4\u09cb \u09aa\u09dc\u09be\u09b6\u09cb\u09a8\u09be \u0995\u09b0\u09c7 \u0995\u09bf \u09b9\u09a4\u09c7 \u099a\u09be\u0993 ?      \u0986\u09ae\u09bf: \u09ab\u09bf\u099c\u09bf\u09b8\u09bf\u09df\u09be\u09a8     \u0986\u09a8\u09cd\u099f\u09bf:  \u0986\u09b0\u09c7 \u098f\u0987\u09b8\u09ac \u09ab\u09bf\u099c\u09bf\u0995\u09cd\u09b8 \u099f\u09bf\u099c\u09bf\u0995\u09cd\u09b8 \u09ac\u09be\u09a6 \u09a6\u09bf\u09df\u09c7 \u09a1\u09be\u0995\u09cd\u09a4\u09be\u09b0\u09bf \u09aa\u09dc\u09cb        \u0986\u09ae\u09bf: ", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The girl in the picture is wearing a uniform and is holding a pencil. The text on the page is in a foreign language, possibly Bengali.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/bamboo-vaiya (353).jpg", "text": "*\u09b0\u09bf\u09b2\u09c7\u09b6\u09a8\u09b6\u09bf\u09aa\u09c7\u09b0 \u09e6.\u09e6\u09e6\u09e6\u09e6\u09e7 \u09b8\u09c7\u0995\u09c7\u09a8\u09cd\u09a1\u09c7\u09b0 \u09ae\u09a7\u09cd\u09af\u09c7*   \u09ab\u09be\u0995\u09ac\u0987\u0983   \u0986\u09ae\u09be\u09b0 \u09b2\u0997\u09c7 \u0996\u09c7\u09b2\u09ac\u09bf ?  ", "label": 1}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The meme is not hateful, it is just a funny picture of a man and woman in a humorous situation.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/bamboo-vaiya (117).jpg", "text": "\u09af\u0996\u09a8 \u09a4\u09c1\u09ae\u09bf  \u0995\u09cb\u09a8\u09cb \u09ac\u09bf\u09df\u09c7 \u0996\u09c7\u09a4\u09c7 \u09af\u09be\u0993 \u0995\u09bf\u09a8\u09cd\u09a4\u09c1 \u0995\u09be\u0993\u0995\u09c7\u0987 \u099a\u09bf\u09a8\u09a8\u09be ", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The image is a meme that is not hateful, it is a picture of a man in a suit sitting on a chair.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/nurani-memes (97).jpg", "text": "\u09ac\u09dc\u09b2\u09cb\u0995 \u09ac\u09be\u09ac\u09be\u09b0 \u099b\u09c7\u09b2\u09c7\u0983  Dad, I raped a girl. Will there be any police problem ?  \u09ac\u09dc\u09b2\u09cb\u0995 \u09ac\u09be\u09ac\u09be\u0983   Just Chill Chill Just Chill ", "label": 1}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The meme is a joke that is not hateful, it is just a funny way to express the idea that the person is not a police officer. The meme is a joke that is not hateful, it is just a funny way to express the idea that the person is not a police officer.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/CM (259).jpg", "text": "\u0998\u09c1\u09ae\u09be\u09a8\u09cb\u09b0 \u09b8\u09ae\u09df \u09af\u0996\u09a8 \u0986\u09ae\u09be\u09b0 \u09b0\u09c1\u09ae\u09c7\u09b0\u09be \u09ae\u09b6\u09be\u09b0\u09c0 \u09ad\u09c1\u09b2 \u09ad\u09be\u09ac\u09c7 \u099f\u09be\u09a8\u09be\u09df \u09ab\u09c7\u09b2\u09bf  ", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The meme is a picture of a woman with a caption that says "hateful" or "not-hateful" depending on the context.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/CM (650).jpg", "text": "\u0985\u09a8\u09cd\u09af \u09b0\u0999\u09c7\u09b0 \u0995\u09be\u09aa\u09dc*     \u0985\u09a8\u09cd\u09af \u09b0\u0999\u09c7\u09b0 \u0995\u09be\u09aa\u09dc*      \u09ac\u09be\u09b0\u09ac\u09be\u09b0 \u0995\u09be\u09b2\u09cb \u09b0\u0999\u09c7\u09b0 \u0995\u09be\u09aa\u09dc \u09aa\u09dc\u09be \u0986\u09ae\u09bf* ", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The meme is not hateful, it is not-hateful.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/ovodro_img (1327).jpg", "text": "No Caption", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: A collage of four different images, including a woman, a man, a snake, and a coconut.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/CM (527).jpg", "text": "\u09b8\u09be\u09a7\u09be\u09b0\u09a3\u09a4 \u09a6\u09be\u09ac\u09be\u09b0 \u09ac\u09dc\u09c7     \u09a6\u09be\u09ac\u09be\u09b0 \u09ac\u09dc\u09c7 \u09af\u0996\u09a8 \u09ac\u09cb\u09b0\u09cd\u09a1\u09c7\u09b0 \u09b6\u09c7\u09b7 \u0998\u09b0\u09c7 \u0993\u09a0\u09c7  ", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The meme is not hateful, it is just a funny picture of a woman with a sword. The meme is not hateful, it is just a funny picture of a woman with a sword.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/chintashil (958).jpg", "text": "\"The bathroom is used for bathing\"    Married couple: ", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The meme is not hateful, it is just a joke.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/bamboo-vaiya (424).jpg", "text": "\u09ac\u09be\u099a\u09cd\u099a\u09be \u09ab\u09cd\u09b2\u09cb\u09b0\u09c7 \u09aa\u09b0\u09c7 \u0997\u09bf\u09df\u09c7 \u09ac\u09cd\u09af\u09be\u09a5\u09be \u09aa\u09be\u09ac\u09be\u09b0 \u09aa\u09b0 !  \u0986\u09ae\u09cd\u09ae\u09c1\u0983 \u09a0\u09c1\u09b8 \u09a0\u09c1\u09b8, \u098f\u0987\u09af\u09c7 \u09ab\u09cd\u09b2\u09cb\u09b0\u09b0\u09c7 \u09ae\u09be\u0987\u09b0\u09be \u09a6\u09bf\u099b\u09bf     \u09ac\u09be\u099a\u09cd\u099a\u09be\u0983     \u09ab\u09cd\u09b2\u09cb\u09b0\u0983 ", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The meme is not hateful, it is just a funny picture of two men with a caption that is not hateful.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/ovodro_img (1326).jpg", "text": "\u099a\u09bf\u09a8\u09bf **   \u09aa\u09bf\u09aa\u09dc\u09c7 **", "label": 1}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The image is a meme that is either hateful or not-hateful. The meme is a picture of a woman with a blindfold on, and the text is in a foreign language.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/Halal Memes (90).jpg", "text": "\u09b8\u09c7\u09b9\u09c7\u09b0\u09c0\u09a4\u09c7 \u0989\u09a0\u09be\u09b0 \u099c\u09a8\u09cd\u09af \u09b0\u09be\u09a4 \u09e9\u099f\u09be\u09b0 \u098f\u09b2\u09be\u09b0\u09cd\u09ae \u09af\u0996\u09a8 \u09a6\u09c1\u09aa\u09c1\u09b0 \u09e9\u099f\u09be\u09df \u09ac\u09c7\u099c\u09c7 \u0989\u09a0\u09c7 - \u0986\u09ae\u09bf\u0983   \u098f \u099c\u09c0\u09ac\u09a8 \u09b0\u09c7\u0996\u09c7 \u0995\u09c0 \u09b2\u09be\u09ad ??", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The meme is not hateful, it is just a funny picture of a man with a gun.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/TR (569).jpg", "text": "\u09a6\u09cc\u09b2\u09a4\u09a6\u09bf\u09df\u09be \u0998\u09be\u099f \u09a5\u09c7\u0995\u09c7 \u09ab\u09b0\u09bf\u09a6\u09aa\u09c1\u09b0\u09c7\u09b0 \u09b2\u09cb\u0995\u09be\u09b2 \u09ac\u09be\u09b8\u09c7 \u0993\u09a0\u09be Exist    \u09ac\u09be\u09b8\u09c7 \u0993\u09a0\u09be \u09b9\u0995\u09be\u09b0 to me :-     \u098f \u0996\u09be\u099c\u09be \u0996\u09be\u09a8 ...   \u0995\u09c1\u09b7\u09cd\u099f\u09bf\u09df\u09be\u09b0 \u09ac\u09bf\u0996\u09cd\u09af\u09be\u09a4 \u09a4\u09bf\u09b2\u09c7\u09b0 \u0996\u09be\u099c\u09be ", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The meme is not hateful, it is just a funny cartoon with a caption in a foreign language.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/chintashil (489).jpg", "text": "\u0995\u09bf\u099b\u09c1 \u09ae\u09a8\u09c7 \u0995\u09b0\u09a4\u09c7 \u09aa\u09be\u09b0\u099b\u09bf \u09a8\u09be    \u0995\u09be\u09b0\u09a3 \u0986\u09ae\u09bf  \"90's kid\"  \u09a8\u09be  ", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The meme is not hateful, it is just a funny picture of a man with a funny caption.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/ovodro_img (800).jpg", "text": "kid \u09a6\u09c7\u09b0 \u09aa\u09c2\u099c\u09cb\u09b0 \u09aa\u09cd\u09b2\u09be\u09a8    Men \u09a6\u09c7\u09b0 \u09aa\u09c2\u099c\u09cb\u09b0 \u09aa\u09cd\u09b2\u09be\u09a8    Legend \u09a6\u09c7\u09b0 \u09aa\u09c2\u099c\u09cb\u09b0 \u09aa\u09cd\u09b2\u09be\u09a8    ultra legend \u09a6\u09c7\u09b0 \u09aa\u09c2\u099c\u09cb\u09b0 \u09aa\u09cd\u09b2\u09be\u09a8 ", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The meme is a collage of images with the words 'hateful' and 'not-hateful' above it.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/KAM (121).jpg", "text": "\u09b6\u09b0\u09c0\u09b0\u099f\u09be \u09ad\u09be\u09b2\u09cb \u09a8\u09be... \u0995\u09c7\u09ae\u09a8 \u099c\u09be\u09a8\u09bf \u09b2\u09be\u0997\u09a4\u09c7\u099b\u09c7! \u09a4\u09be\u0987 \u09ae\u09be\u09a5\u09be \u0998\u09c1\u09b0\u09be\u09df...\u09ac\u09ae\u09bf \u09ac\u09ae\u09bf \u09ad\u09be\u09ac, \u09a4\u09c7\u0981\u09a4\u09c1\u09b2 \u0996\u09be\u0987\u09a4\u09c7 \u09ae\u09a8 \u099a\u09be\u09df... \u09a4\u09be\u0987\u09a8\u09be!", "label": 1}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The image is a meme that is not hateful, it is a funny and lighthearted joke.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/Memeholics (237).jpg", "text": "\u0986\u099c\u0995\u09c7 \u0986\u09ae\u09bf \u0986\u09aa\u09a8\u09be\u09a6\u09c7\u09b0 \u09b6\u09bf\u0996\u09be\u09ac\u09cb \u0987\u0982\u09b0\u09c7\u099c\u09c0\u09a4\u09c7 \" \u09b6\u09c1\u09ad \u09b8\u0995\u09be\u09b2 - \u0995\u09bf\u09ad\u09be\u09ac\u09c7 \u09ac\u09b2\u09a4\u09c7 \u09b9\u09df   ", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The image is a meme that is not hateful, it is a picture of a woman with glasses and a group of people in the background. The meme is not hateful, it is just a picture of a woman with a group of people.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/ovodro_img (1097).jpg", "text": "\u09ae\u09c1\u099c\u09b0\u09be \u0995\u09b0\u09c7 \u099f\u09bf\u0995\u099f\u0995\u09c7 \u0985\u09a8\u09c7\u0995 \u09ab\u09b2\u09cb\u09df\u09be\u09b0\u09b8 \u09ac\u09be\u09a8\u09be\u09a8\u09cb\u09b0 \u09aa\u09b0\u09c7    Dhokhaa swabhaav hai mera    Tiktoker :     ", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The meme is a picture of a man with a tiktok logo on his head, and the caption is in a foreign language. The meme is not hateful, but it is not hateful either.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/CM (558).jpg", "text": "Me and my friends hanging out at tong*   Random murobbi from nowhere:  I've seen things you people wouldn't believe ", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The image is a meme that is not hateful, but it is a meme that is hateful. The meme is a picture of a man with a sad face and the caption is "me and my friends hanging out at random mubi from nowhere."
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/chintashil (771).jpg", "text": "\u09af\u0996\u09a8 \u0986\u09ae\u09cd\u09ae\u09c1 \u09ac\u09b2\u09c7 \u09b8\u09c1\u0995\u09c7\u09b8 \u09a5\u09c7\u0995\u09c7 '\u0995\u09be\u099a\u09c7\u09b0 \u0997\u09cd\u09b2\u09be\u09b8' \u09a8\u09bf\u09df\u09c7 \u0986\u09b8\u09a4\u09c7* ", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The meme is a picture of a soccer player with a question mark above his head. The meme is not hateful, but it is a questionable image.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/ovodro_img (1082).jpg", "text": "\u0986\u09ae\u09be\u09a6\u09c7\u09b0 PM \u09af\u0996\u09a8 \u09b8\u09c7\u09b2\u09bf\u09ac\u09cd\u09b0\u09bf\u099f\u09bf\u09a6\u09c7\u09b0 \u09b8\u0999\u09cd\u0997\u09c7 \u09aa\u09be\u09b0\u09cd\u099f\u09bf \u099c\u09df\u09c7\u09a8 \u0995\u09b0\u09c7\u09a8 \u098f\u09ac\u0982 \u09a4\u09be\u09a6\u09c7\u09b0 \u09b8\u09c7\u09b2\u09ab\u09bf , \u09ab\u099f\u09cb \u09a8\u09bf\u09a4\u09c7 \u09a6\u09c7\u0996\u09c7 \u09a4\u09be\u0995\u09c7 \u099b\u09be\u09dc\u09be\u0987      ye kon si Photography hai jaha mujhe nhi bulate   ", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The meme is a picture of a man with a microphone, and the caption is in a foreign language. The caption is not hateful, but it is not hateful.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/netflix (65).jpg", "text": "\u0986\u09ae\u09be\u09b0 \u09b2\u09df\u09c7\u09b2\u09bf\u099f\u09bf \u09b2\u09c7\u09ad\u09c7\u09b2*     \u0995\u09cd\u09b0\u09be\u09b6\u09c7\u09b0 \u09ac\u09ab\u09c7\u09b0 \u09b2\u09df\u09c7\u09b2\u09bf\u099f\u09bf \u09b2\u09c7\u09ad\u09c7\u09b2* ", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The image is a meme that is not hateful, it is just a collection of different sports players.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/tangaila (243).jpg", "text": "\u09af\u0996\u09a8 \u0995\u09c1\u09ae\u09c1\u09a6\u09bf\u09a8\u09c0\u09b0 \u09aa\u09be\u09b6 \u09a6\u09bf\u09df\u09c7 \u09af\u09be\u0993\u09df\u09be\u09b0 \u09b8\u09ae\u09df \u0986\u09ae\u09be\u09b0 \u098f\u0995\u09cd\u09b8 \u099f\u09be\u0995\u09c7 \u09a6\u09c7\u0996\u09bf    Me to My friend:   \u0993\u0987\u09af\u09c7 \u09a8\u09a1\u09bf\u09b0\u09aa\u09c1\u09a4 ", "label": 1}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The image is a meme that is not hateful, but it is a meme that is hateful. The meme is a picture of a man pointing at a woman with a caption that says "me to my friend" and "tanggol" in the background. The meme is not hateful, but it is a meme that is hateful.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/ovodro_img (875).jpg", "text": " \u0986\u09aa\u09a8\u09be\u09b0 \u09a8\u09be\u09ae \u0995\u09c0 ? \u09a8\u09c0\u09b2 \u09a8\u09c0\u09a4\u09bf\u09a8 \u09ae\u09c1\u0995\u09c7\u09b6    \u0986\u09aa\u09a8\u09be\u09b0 \u09a8\u09be\u09ae \u099c\u09bf\u099c\u09cd\u099e\u09c7\u09b8 \u0995\u09b0\u09c7\u099b\u09bf \u09b8\u09be\u09a5\u09c7 \u09ac\u09be\u09ac\u09be \u0986\u09b0 \u09a6\u09be\u09a6\u09c1\u09b0 \u09a8\u09be\u09ae \u099c\u09be\u09a8\u09a4\u09c7 \u099a\u09be\u0987 \u09a8\u09bf   \u09ac\u09be\u0981#\u09a6 \u0987\u09ae\u09cb\u09b6\u09a8 \u09a8\u09bf\u09df\u09c7 \u0996\u09c7\u09b2\u09bf\u09b8 !  ", "label": 1}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The meme is a political one, with a man in a suit and another man in a suit, both with a serious expression. The meme is not hateful, but it is not hateful either.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/Bangla Thug Life (411).jpg", "text": "\u09ae\u09cb\u099f\u09b0\u09ac\u09be\u0987\u0995\u09c7 \u099a\u09c7\u09aa\u09c7 \u099c\u09df \u09b6\u09cd\u09b0\u09c0 \u09b0\u09be\u09ae\u09c7\u09b0 \u09b6\u09cd\u09b2\u09cb\u0997\u09be\u09a8 \u09a6\u09c7\u0993\u09df\u09be \u09ac\u09be\u0999\u09be\u09b2\u09bf \u09b8\u0982\u09b8\u09cd\u0995\u09c3\u09a4\u09bf \u09a8\u09df, - \u09b8\u09be\u09df\u09a8\u09c0 \u0998\u09cb\u09b7      \u09ac\u09be\u0999\u09be\u09b2\u09bf\u09b0 \u09b8\u0982\u09b8\u09cd\u0995\u09c3\u09a4\u09bf", "label": 1}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The image is a meme that is not hateful, it is a funny and lighthearted commentary on a woman's appearance. The meme is not hateful, it is not intended to harm or vilify any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/ovodro_img (801).jpg", "text": "\u0986\u09ae\u09be\u09b0 \u09ac\u09be\u09a8\u09cd\u09a7\u09ac\u09c0 \u09af\u09c7 \u09ac\u09cd\u09b0\u09c7\u0995 \u0986\u09aa \u09b9\u0993\u09df\u09be\u09b0 \u09aa\u09b0 \u098f\u0995\u09a6\u09bf\u09a8 \u09a8\u09bf\u099c\u09c7 \u0986\u0999\u09cd\u0997\u09c1\u09b2 \u09ae\u09c7\u09b0\u09c7\u099b\u09c7 \u09a4\u09be\u0987 \u0995\u09be\u0981\u09a6\u099b\u09c7    \u0986\u09b0 \u098f\u099f\u09be \u0986\u09ae\u09bf \u09af\u09c7 \u09ac\u099b\u09b0\u09c7\u09b0 \u09aa\u09b0 \u09ac\u099b\u09b0 \u0997\u09bf\u099f\u09be\u09b0 \u09ae\u09c7\u09b0\u09c7\u0987 \u0995\u09be\u099f\u09be\u099a\u09cd\u099b\u09bf ", "label": 1}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The meme is not hateful, it is just a funny picture of a man pointing at a woman and saying something. The meme is not hateful, it is just a funny picture of a man pointing at a woman and saying something.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/chintashil (80).jpg", "text": "\u0997\u09ab\u0983 \u09ac\u09be\u09ac\u09c1 , \u0995\u09bf \u0995\u09b0    \u09ac\u09ab\u0983 \u09ac\u09be\u09ac\u09c1 \u09ac\u09cd\u09b0\u09be\u09b6 \u0995\u09b0\u09bf    \u0997\u09ab\u0983 \u09ac\u09be\u09ac\u09c1 \u09a4\u09c1\u09ae\u09bf \u09ac\u09cd\u09b0\u09be\u09b6 \u0993 \u0995\u09b0\u09a4\u09c7 \u09aa\u09be\u09b0 , \u09aa\u09bf\u0995 \u09a6\u09c7\u0993 \u09a6\u09c7\u0996\u09bf     Desi Nigga: ", "label": 1}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The image is a meme that is not hateful, it is just a funny picture of a man brushing his teeth in a mirror.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/CM (268).jpg", "text": "\u0986\u09b8\u09a8\u09cd\u09a8 \u09a6\u09c1\u09b0\u09cd\u09ad\u09bf\u0995\u09cd\u09b7     \u099a\u09bf\u0995\u09a8 \u099c\u09bf\u09b2\u09be\u09aa\u09bf \u0995\u09cb\u09a5\u09be\u09df \u09aa\u09be\u09ac\u09cb  \u099a\u09bf\u09a8\u09cd\u09a4\u09be\u09df\u09bf\u09a4 \u0986\u09ae\u09bf  ", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The image is a meme that is not hateful, it is a picture of a man standing in front of a building with cars parked nearby. The meme is not hateful, it is just a picture of a man standing in front of a building with cars parked nearby.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/CM (153).jpg", "text": "\u0986\u09ae\u09bf\u0983 \u09a7\u09c1\u09b0\u09b0 \u09ad\u09be\u09b2\u09cd\u09b2\u09be\u0997\u09a4\u09be\u09b8\u09c7\u09a8\u09be \u0986\u099c\u0995\u09c7 \u09aa\u09dc\u09ac\u09cb\u09a8\u09be     \u0986\u09ae\u09cd\u09ae\u09c1\u0983   \u0986\u09ae\u09bf \u09af\u09a4\u09a6\u09bf\u09a8 \u0986\u099b\u09bf \u09b8\u09c1\u09af\u09cb\u0997 \u09a8\u09be\u0987 ", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The meme is not hateful, it is just a picture of a man with a caption that is not hateful.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/chintashil (671).jpg", "text": "\u09a8\u09bf\u09b0\u09cd\u09ac\u09be\u099a\u09a8\u09c0 \u09aa\u09cd\u09b0\u099a\u09be\u09b0\u09a3\u09be*   \u09a8\u09bf\u09b0\u09cd\u09ac\u09be\u099a\u09a8\u09c7 \u0985\u0982\u09b6\u0997\u09cd\u09b0\u09b9\u09a8 \u0995\u09b0\u09be \u09aa\u09cd\u09b0\u09be\u09b0\u09cd\u09a5\u09c0    \u098f\u09b2\u09be\u0995\u09be\u09ac\u09be\u09b8\u09c0  ", "label": 1}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The image is a meme that is not hateful, it is a funny scene of a man blowing a woman's hair with a hair dryer. The meme is not hateful, it is just a funny scene.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/ovodro_img (81).jpg", "text": "\u09a4\u09c1\u0987 \u0986\u09ae\u09be\u09b0 \u09b0\u09be\u09a8\u09bf \u0986\u09ae\u09bf \u09a4\u09cb\u09b0 \u09b0\u09be\u099c\u09be \u09b0\u09c7   \u098f\u0995\u099c\u09a8 \u09a4\u09cb\u09a4\u09b2\u09be \u09b0\u09be\u099c\u09be    \u0986\u09b0\u09c7\u0995\u099c\u09a8 \u09ac\u09be\u0997 \u09ac\u09be\u099c\u09be\u09b0\u09c7\u09b0 \u09b0\u09be\u09a8\u09bf ", "label": 1}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The meme is a picture of a man and woman, with the caption "Hateful if it intends to denigrate, vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status."
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/ovodro_img (1261).jpg", "text": "Not a meme \u09ad\u09be\u0987\u09df\u09c7 \u09ad\u09be\u0987\u09df\u09c7 \u099d\u0997\u09dc\u09be \u0995\u09b0\u09be\u09b0 \u09b8\u09ae\u09df \u09af\u0996\u09a8 \u09b9\u09a0\u09be\u09a4 \u09ac\u09be\u09ac\u09be \u09b8\u09be\u09ae\u09a8\u09c7 \u099a\u09b2\u09c7 \u0986\u09b8\u09c7 ", "label": 1}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The image is a meme that is not hateful, it is a picture of a man in yellow standing next to a cow. The meme is not hateful, it is just a funny picture of a man and a cow.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/CM (18).jpg", "text": "*When your ammu gives you 100tk but after few seconds she told you to give her 50 tk back     \u0986\u09b6\u09cd\u099a\u09b0\u09cd\u09af , \u09ae\u09a8\u09c7 \u09b9\u09df\u09c7\u099b\u09bf\u09b2\u09cb \u098f\u0995\u09c7\u09ac\u09be\u09b0\u09c7 \u09b0\u09bf\u09df\u09c7\u09b2 !!   ", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The meme is not hateful, it is just a funny picture of two men with a caption that says "when your ammi gives you 100 butter seconds but gives you 50 seconds back."
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/tangaila (48).jpg", "text": "Tahseenation    salman jessia ", "label": 1}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: A couple is sitting on a wet step, with a sign in the background that says 'hateful'. The couple is kissing, and the sign is not hateful.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/bamboo-vaiya (350).jpg", "text": "   \u09a8\u09bf\u0989 \u09ae\u09be\u09b0\u09cd\u0995\u09c7\u099f\u09c7\u09b0 \u09ab\u09c1\u099f\u09aa\u09be\u09a4\u09c7 \u09b9\u09be\u099f\u09be \u09ac\u09bf\u09a6\u09cd\u09af\u09ae\u09be\u09a8   \u09b2\u09c7 \u09b9\u0995\u09be\u09b0\u09b8-    \u09a4\u09cb\u09b0 \u0995\u09bf \u09ac\u09cd\u09b0\u09be \u09b2\u09be\u0997\u09ac\u09cb ? ", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The meme is not hateful, it is just a funny picture of two men talking to each other.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/Halal Memes (104).jpg", "text": "\u0995\u09cb\u09ad\u09bf\u09a1-\u09e7\u09ef \u098f\u09b0 \u09b8\u09be\u09a5\u09c7 \u09a6\u09c7\u0996\u09be \u09b9\u0993\u09df\u09be\u09b0 \u09aa\u09b0 \u09b8\u09be\u0987\u0995\u09cd\u09b2\u09cb\u09a8 \u0986\u09ae\u09cd\u09ab\u09be\u09a8\u0983 \u0995\u09cb\u09ad\u09bf\u09a1-\u09e7\u09ef   \u0986\u09ae\u09cd\u09ab\u09be\u09a8     \u0986\u09ae\u09b0\u09be \u0986\u09ae\u09b0\u09be\u0987 \u09a4\u09cb   ", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The meme is not hateful, it is just a funny picture of two men talking.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/Halal Memes (62).jpg", "text": "\"\u09b8\u09c7\u09aa\u09cd\u099f\u09c7\u09ae\u09cd\u09ac\u09b0 \u09aa\u09b0\u09cd\u09af\u09a8\u09cd\u09a4 \u09b8\u09cd\u0995\u09c1\u09b2-\u0995\u09b2\u09c7\u099c \u09b8\u09ac \u09ac\u09a8\u09cd\u09a7 \u09a5\u09be\u0995\u09ac\u09c7\"  \u09aa\u09cd\u09b0\u09a7\u09be\u09a8\u09ae\u09a8\u09cd\u09a4\u09cd\u09b0\u09c0 !  \u098f\u0987\u099f\u09be \u09a6\u09c7\u0996\u09c7\u0983      \u09ae\u09c7\u09df\u09c7\u09a6\u09c7\u09b0 Reaction   \u099b\u09c7\u09b2\u09c7\u09a6\u09c7\u09b0 Reaction      Halal memes", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The meme is a picture of a woman with a look of disgust on her face, and the caption is in Vietnamese. The meme is not hateful, but it is a reaction to a hateful meme.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/ovodro_img (150).jpg", "text": "\u09aa\u09b0 \u09aa\u09b0 \u09a6\u09c1\u09ac\u09be\u09b0 \u09a4\u09cb \u0995\u09b0\u09b2\u09c7 , \u09a4\u09be\u0993 \u09a4\u09cb\u09ae\u09be\u09b0 \u0993\u099f\u09be \u098f\u0996\u09a8\u09cb \u09a6\u09be\u0981\u09dc\u09bf\u09df\u09c7 \u0986\u099b\u09c7 \u0995\u09c0 \u0995\u09b0\u09c7 ?     \u09b9\u09c1 \u09b9\u09c1  \u09ac\u09be\u0993\u09df\u09be, \u0986\u09ae\u09bf \u0989\u09a8\u09cd\u09a8\u09df\u09a8 \u09ab\u09cd\u09b2\u09c7\u09ad\u09be\u09b0\u09c7\u09b0 \u0995\u09a8\u09cd\u09a1\u09cb\u09ae \u0987\u0989\u09b8 \u0995\u09b0\u09bf \u09af\u09c7 ", "label": 1}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The image is a meme that is not hateful, it is a funny and lighthearted scene between two people.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/Bangla Thug Life (353).jpg", "text": "\u09b6\u09b9\u09b0 \u09a5\u09c7\u0995\u09c7 \u09af\u0996\u09a8 \u0997\u09cd\u09b0\u09be\u09ae\u09c7 \u09af\u09be\u09df \u099a\u09be\u099a\u09be\u09a4\u09cb \u09ac\u09cb\u09a8    \u0997\u09cd\u09b0\u09be\u09ae\u09c7\u09b0 \u099a\u09be\u099a\u09be\u09a4\u09cb \u09ad\u09be\u0987\u0983", "label": 1}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The meme is not hateful, it is just a funny picture of a woman and a child.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/CM (312).jpg", "text": "\u09b8\u09c1\u09a8\u09cd\u09a8\u09be\u09a4\u09c7 \u0996\u09be\u09a4\u09a8\u09be \u0995\u09b0\u09be\u09a4\u09c7 \u09a5\u09be\u0995\u09be \u09a1\u09be\u0995\u09cd\u09a4\u09be\u09b0     \u0986\u09ae\u09be\u09b0 \u09b6\u09bf\u09b6\u09cd\u09a8     \u09b8\u0995\u09be\u09b2\u09c7\u09b0 \u09a8\u09be\u09b8\u09cd\u09a4\u09be\u09df \u0995\u09bf \u0996\u09c7\u09df\u09c7\u099b\u09bf \u09a1\u09be\u0995\u09cd\u09a4\u09be\u09b0 \u0995\u09c7 \u09ac\u09b2\u09a4\u09c7 \u09a5\u09be\u0995\u09be \u0986\u09ae\u09bf  ", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The man in the picture is eating a cupcake while standing in front of a tank. The cupcake is decorated with a red and white frosting, and the man is wearing a suit. The picture is a meme that is not hateful, but it is a humorous representation of a man eating a cupcake in front of a tank.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/TR (441).jpg", "text": "\u0995\u09be\u09a8\u09be\u0987\u09aa\u09c1\u09b0    \u09ab\u09b0\u09bf\u09a6\u09aa\u09c1\u09b0\u09c7\u09b0 \u09b8\u09ac \u099c\u09c1\u099f\u09ae\u09bf\u09b2  ", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The meme is not hateful, it is a romantic scene between two women.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/ovodro_img (559).jpg", "text": "\u09ac\u09be\u0999\u09be\u09be\u09b2\u09bf \u0995\u09c0 \u09b0\u0995 \u09b6\u09c1\u09a8\u09a4\u09c7 \u09b6\u09bf\u0996\u09c7\u099b\u09c7 ?   \u09b8\u09a4\u09cd\u09af\u09bf\u0987 \u09a4\u09c1\u09ae\u09bf \u09aa\u09be\u09b0\u09b2\u09c7 \u09ac\u09be\u0999\u09be\u09b2\u09bf\u0995\u09c7 \u09b0\u0995 \u09b6\u09cb\u09a8\u09be\u09a8\u09cb\u09b0 \u0985\u09ad\u09cd\u09af\u09be\u09b8 \u0995\u09b0\u09be\u09a4\u09c7... \u09b8\u09a4\u09cd\u09af\u09bf\u0987 \u09a4\u09c1\u09ae\u09bf \u09aa\u09be\u09b0\u09b2\u09c7     \u0986\u09b8\u09b2\u09c7 \u09b8\u09a4\u09cd\u09af\u09bf \u09ac\u09b2\u09a4\u09c7 \u0995\u09bf\u099b\u09c1 \u09a8\u09c7\u0987   \u09b8\u09ac\u0987 \u09ac\u09c7\u0981\u099a\u09c7 \u09a5\u09be\u0995\u09be\u09b0 \u0997\u09be\u09a8 ", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The meme is not hateful, it is just a funny conversation between two people.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/ovodro_img (1106).jpg", "text": "\u09ac\u09be\u09ac\u09be :  \u0995\u09c0 \u099b\u09c7\u09b2\u09c7 \u09ae\u09c7\u09df\u09c7 \u099c\u09a8\u09cd\u09ae\u09c7\u099b\u09c7 \u0995\u09cb\u09a8 \u0995\u09a5\u09be \u09b6\u09cb\u09a8\u09c7 \u09a8\u09be !     \u099b\u09c7\u09b2\u09c7\u09ae\u09c7\u09df\u09c7 :  \u09ae\u09a8\u09c1\u09b7\u09cd\u09af\u0995\u09cb \u0989\u099a\u0995\u09be \u0995\u09b0\u09cb\u09ae \u0995\u09bf \u0985\u09a8\u09c1\u09b8\u09be\u09b0 \u09ab\u09b2 \u09aa\u09cd\u09b0\u09be\u09aa\u09cd\u09a4 \u09b9\u09cb\u09a4\u09be \u09b9\u09cd\u09af\u09be\u09df      \u09ac\u09be\u09ac\u09be : \u09b6\u09be\u09b2\u09be \u0986\u09ae\u09be\u0995\u09c7\u0987 \u09a6\u09cb\u09b7\u09bf \u09ac\u09be\u09a8\u09bf\u09df\u09c7 \u09a6\u09bf\u09b2 ", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The image is a meme that is not hateful, it is a picture of a man with a caption in a foreign language.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/chintashil (763).jpg", "text": "When you accidentally call the teacher \u0986\u09ae\u09cd\u09ae\u09c1  in front of the whole class- ", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: A man is shown with a caption that says 'when you accidentally call the teacher in front of the whole class' with a meme that says 'hateful' or 'not-hateful' depending on the context.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/CM (237).jpg", "text": "\u0986\u099c\u0995\u09c7\u09b0 \u099c\u09a8\u09cd\u09af \u09b9\u0987\u099b\u09c7 \u0986\u09b0 \u09a8\u09be *   My stoner friend:   \u099a\u09b2\u09cb \u0986\u09b0\u09c7\u0995\u09ac\u09be\u09b0 \u0989\u09dc\u09bf   ", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: A man is singing into a microphone with a caption that says 'my stoner friend'. The caption is in a foreign language, possibly Vietnamese.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/Memeholics (52).jpg", "text": "That rain was such a blessing      *\u09ae\u09bf\u09b0\u09aa\u09c1\u09b0\u09ac\u09be\u09b8\u09c0 ", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The meme is a comparison between a hateful and not-hateful meme. The hateful meme is a woman talking on her phone while driving, and the not-hateful meme is a woman driving a car with a man in the passenger seat.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/chintashil (480).jpg", "text": "Don't think yourself dumb bro     There are literally people   \u09af\u09be\u09b0\u09be \u09aa\u09b0\u09bf\u0995\u09cd\u09b7\u09be\u09b0 \u09b9\u09b2\u09c7 \u09b0\u099a\u09a8\u09be \u09a6\u09c7\u0996\u09be\u09a4\u09c7 \u09ac\u09b2\u09c7 ,,  ", "label": 1}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The image is a meme that is not hateful, but it is a meme that is hateful. The meme is a picture of a man with a beard and a caption that says 'don't think yourself dumb bro, there are literally people who are dumb.' The meme is not hateful, but it is a meme that is hateful.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/CM (529).jpg", "text": "\u0989\u09a4\u09cd\u09a4\u09b0\u09ac\u0999\u09cd\u0997\u09c7\u09b0 \u09ae\u09be\u09a8\u09c1\u09b7 \u09ac\u09b0\u09cd\u09a3\u09a8\u09be \u0995\u09b0\u099b\u09c7 \u09a4\u09be\u09b0\u09be \u0995\u09bf\u09ad\u09be\u09ac\u09c7 \u09b6\u09c0\u09a4\u09c7\u09b0 \u0986\u09ae\u09c7\u099c \u0989\u09aa\u09ad\u09cb\u0997 \u0995\u09b0\u099b\u09c7*      * \u09a2\u09be\u0995\u09be , \u099a\u099f\u09cd\u09b0\u0997\u09cd\u09b0\u09be\u09ae\u09c7\u09b0 \u09ae\u09be\u09a8\u09c1\u09b7* ", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The image is a meme that is not hateful, it is a funny picture of a man and a seal with a caption that is not hateful.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/chintashil (1019).jpg", "text": "Peach    Pitch    Beach ", "label": 1}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The image is a collage of four pictures, each with a different fruit. The caption reads "Hateful or not-hateful?"
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/ovodro_img (961).jpg", "text": "Enough is not a century to win a match    \u0993\u0987 \u09b9\u09be\u09b2\u09be\u09b0\u09aa\u09c1\u09a4\u09c7 , \u0995\u09df \u0995\u09c0 ", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The meme is not hateful, it is just a funny picture of a man with a bat and a caption that says 'enough is not a century to win a match'. The caption is not hateful, it is just a funny comment.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/bangla-gag (105).jpg", "text": "MY FRIENDS    MY CRUSH    ME    BANGLA GAG", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The meme is a collage of three different images, one of which is a hateful meme and the other two are not.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/TR (481).jpg", "text": "\u09a8\u09bf\u0989 \u09ae\u09be\u09b0\u09cd\u0995\u09c7\u099f     \u09ac\u09be\u09b0\u09c0 \u09aa\u09cd\u09b2\u09be\u099c\u09be    \u09ab\u09b0\u09bf\u09a6\u09aa\u09c1\u0987\u09b0\u200d\u09cd\u09af\u09be \u099b\u09be\u0993\u09df\u09be\u09b2   ", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The meme is not hateful, it is not intended to denigrate, vilify, harm, mock, or abuse any entity based on their gender, race, ideology, belief, social, political, geographical, or organizational status.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/CM (270).jpg", "text": "FAKE    REAL  ", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: A man and a woman are shown in a gym, with the man punching the woman in the face. The man is wearing a boxing glove and the woman is wearing a bloody face. The man is saying "fake" and the woman is saying "real." The meme is not hateful, but it is not hateful either.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/TR (57).jpg", "text": "\u099a\u09b2\u09cb \u09a8\u09be , \u09a6\u09c1\u099c\u09a8\u09c7 \u0995\u09cb\u09a5\u09be\u0993 \u09b9\u09be\u09b0\u09bf\u09df\u09c7 \u09af\u09be\u0987      \u0995\u09aa\u09bf\u09b2\u09be , , \u09a4\u09c1\u0987 \u09ac\u09be\u09dc\u09bf \u09af\u09be \u0964 \u0986\u099c\u0995\u09c7 \u09ac\u09be\u09b0\u09cd\u09b8\u09be\u09b0 \u0996\u09c7\u09b2\u09be \u0986\u099b\u09c7 ", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The meme is not hateful, it is just a funny conversation between two people. The meme is not hateful, it is just a funny conversation between two people.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/Bangla Thug Life (29).jpg", "text": "\u09af\u0996\u09a8 \u09a4\u09c1\u09ae\u09bf \u09aa\u09b0\u09c0\u0995\u09cd\u09b7\u09be\u09b0 \u09aa\u09cd\u09b0\u09a5\u09ae \u09aa\u09cd\u09b0\u09b6\u09cd\u09a8\u09c7\u09b0 \u09a6\u09bf\u0995\u09c7 \u09a4\u09be\u0995\u09be\u0993 ! ", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The meme is a picture of a man with a hat on, and the caption is in a foreign language. The caption is not hateful, but it is not hateful either.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/ovodro_img (45).jpg", "text": "\u09aa\u09be\u0997\u09b2\u0989\u0989\u0989...  \u09a5\u09cb\u09dc\u09be\u09b8\u09be \u0995\u09be\u09b0\u09b2\u09c7 \u09b0\u09cb\u09ae\u09be\u09a8\u09cd\u09b8    \u09a7\u09c1\u09b0 \u09ac\u09be\u09b2, \u09aa\u09be\u0997\u09b2 \u09b9\u09b2\u09c7\u0993 \u09b8\u09ae\u09cd\u09ae\u09be\u09a8 \u0986\u099b\u09c7 \u0964  \u09a4\u09cb\u09a6\u09c7\u09b0 \u09ae\u09a4 \u09aa\u09be\u0997\u09b2\u09c1 \u09a1\u09cd\u09af\u09be\u09a8\u09cd\u09b8 \u0995\u09b0\u09bf \u09a8\u09be \u0964  ", "label": 1}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The meme is not hateful, it is just a funny picture of a man and woman in a foreign country.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/tangaila (276).jpg", "text": "Padma Bridge Total Cost - 3.6 billion   Burj Khalifa Total Cost - 1.5 billion ", "label": 1}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The meme is not hateful, it is just a comparison of two bridges. The Burj Khalifa is the tallest building in the world, and the Padma Bridge is the longest bridge in the world. The Padma Bridge is also the most expensive bridge in the world, costing 36 billion USD.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/Halal Memes (4).jpg", "text": "\u099c\u09c0\u09ac\u09a8\u09c7 \u09ac\u09b9\u09c1 \u09aa\u09be\u09aa \u0995\u09b0\u09c7\u099b\u09bf \u0995\u09bf\u09a8\u09cd\u09a4\u09c1 \u098f\u09b0\u0995\u09ae bakchodi \u0995\u0996\u09a8\u09cb \u0995\u09b0\u09bf\u09a8\u09bf ", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The image is a meme that is not hateful, it is a picture of a person with a scar on their arm with the caption "Bachhoi" in Bengali.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/CM (215).jpg", "text": "*\u0986\u09ae\u09bf    \u09a8\u09ae\u09cd\u09ac\u09b0 \u099f\u09bf \u09a6\u09bf\u09df\u09c7 \u09a6\u09bf\u09a8     *\u0986\u09ae\u09be\u09b0 \u09b8\u09cd\u09af\u09be\u09b0    \u0986\u09ae\u09be\u09b0 \u0995\u09cb\u099a\u09bf\u0982 \u0995\u09b0\u09b2\u09c7  \u09a8\u09ae\u09cd\u09ac\u09b0 \u099f\u09bf \u098f\u09ae\u09a8\u09bf \u09aa\u09c7\u09df\u09c7 \u09af\u09be\u09ac\u09c7\u09a8   ", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The image is a meme that is not hateful, it is a funny conversation between two people. The meme is not hateful, it is just a funny conversation between two people.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/KAM (84).png", "text": "\u0987\u09a8\u09cd\u09a1\u09bf\u09df\u09be \u0995\u09bf \u0995\u09cd\u09b0\u09bf\u0995\u09c7\u099f \u0996\u09c7\u09b2\u09c7?  \u098f\u09a6\u09c7\u09b0 \u0996\u09c7\u09b2\u09be\u09b0 \u09af\u09c7\u09ad\u09be\u09ac\u09c7 \u098f\u09a1 \u09a6\u09c7\u0996\u09be\u09df \u09ae\u09a8\u09c7 \u09b9\u09df \u09af\u09c7 \u09a8\u09a4\u09c1\u09a8 \u09ae\u09c1\u09ad\u09bf \u0986\u0987\u09a4\u09be\u099b\u09c7!", "label": 1}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The image is a meme that is not hateful, it is a funny picture of a man pointing at something with a caption in a foreign language.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/CM (656).jpg", "text": "\u09ad\u09be\u09b2\u09cb \u0995\u09b0\u09c7 \u09aa\u09dc\u09be\u09b6\u09cb\u09a8\u09be \u0995\u09b0\u09c7 \u09a8\u09c7 \u09ae\u09be    \u09ac\u09dc \u09b9\u09df\u09c7 \u09b8\u09cb\u09b6\u09cd\u09af\u09be\u09b2 \u09ae\u09bf\u09a1\u09bf\u09df\u09be\u09a4\u09c7  unwanted opinion \u0993 \u09a4\u09cb \u09a6\u09bf\u09a4\u09c7 \u09b9\u09ac\u09c7 \u09a4\u09cb\u09b0   ", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The image is a meme that is not hateful, it is a picture of a mother and daughter working on a computer together. The caption is in Bengali and translates to "Hateful opinion."
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/chintashil (708).jpg", "text": " \u09aa\u09cd\u09b0\u099a\u09a8\u09cd\u09a1 \u09b6\u09c0\u09a4\u09c7 \u09ac\u09be\u09b8\u09c7 \u0989\u09a0\u09c7 \u09af\u0996\u09a8 \u0987\u099e\u09cd\u099c\u09bf\u09a8\u0993\u09df\u09be\u09b2\u09be \u09b8\u09bf\u099f\u09c7 \u09ac\u09b8\u09bf  ", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The meme is not hateful, it is just a picture of a man with a caption that is not hateful.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/bangla-memes (171).jpg", "text": "Girls 9 months after Valentine's Day :", "label": 1}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: A cat and a mouse are shown in a cartoon, with the caption 'girls 9 months after valentine's day' on the screen.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/chintashil (296).jpg", "text": "Contestant: \u09a4\u09c1\u09ae\u09bf \u09ac\u09c1\u099d\u09a8\u09bf , \u0986\u09ae\u09bf \u09ac\u09b2\u09bf\u09a8\u09bf , \u09a4\u09c1\u09ae\u09bf \u09b8\u09cd\u09ac\u09aa\u09cd\u09a8\u09a4\u09c7 \u0995\u09c7\u09a8 \u0986\u09b8\u09a8\u09bf       Le Neha Kakkar: ", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The meme is not hateful, it is just a funny picture of a woman with a funny caption.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/tangaila (160).jpg", "text": " \u0995\u09c1\u09ae\u09c1\u09a6\u09bf\u09df\u09be\u09a8\u09b0\u09be \u09ac\u09c3\u09b7\u09cd\u099f\u09bf\u09a4\u09c7 \u09ad\u09bf\u099c\u09be\u09b0 \u0986\u0997\u09c7    \u0986\u09b0 \u09ac\u09c3\u09b7\u09cd\u099f\u09bf\u09a4\u09c7 \u09ad\u09bf\u099c\u09be\u09b0 \u09aa\u09b0\u09c7 ", "label": 1}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The meme is not hateful, it is just a funny picture of two women with a caption that is not hateful.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/chintashil (939).jpg", "text": "DAILY         AFTER GAP      IF YOU KNOW WHAT I MEAN ", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The meme is a comparison between a hateful and not-hateful meme. The meme is a comparison between a hateful and not-hateful meme.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/bangla-gag (55).jpg", "text": "THAT REACTION WHEN YOU REALIZE SHE IS TAKEN ", "label": 1}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The meme is not hateful, it is just a funny scene from a movie.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/ovodro_img (245).jpg", "text": "\u0995\u09cb\u09b9\u09b2\u09bf\u09b0 \u09a1\u09be\u0995 \u09a8\u09be\u09ae \u099a\u09bf\u0995\u09c1 \u0964 \u09af\u0996\u09a8 \u09aa\u09cd\u09b0\u09a5\u09ae \u09a6\u09bf\u09b2\u09cd\u09b2\u09bf \u09b0\u099e\u09cd\u099c\u09bf \u099f\u09bf\u09ae\u09c7 \u0986\u09b8\u09c7 \u09aa\u09cd\u09b0\u09be\u0995\u09cd\u09a4\u09a8 \u09a6\u09bf\u09b2\u09cd\u09b2\u09bf \u0995\u09cb\u099a \u0985\u099c\u09bf\u09a4 \u099a\u09cc\u09a7\u09c1\u09b0\u09c0 \u098f\u0987 \u09a8\u09be\u09ae\u099f\u09bf \u09a6\u09bf\u09df\u09c7\u099b\u09bf\u09b2\u09c7\u09a8 \u0964 ", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The meme is not hateful, it is just a picture of a man with a quote that is not hateful.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/KAM (206).png", "text": "\u0986\u099c\u0995\u09be\u09b2 \u09e7 \u099f\u09be\u0995\u09be\u09b0 \u09ad\u09be\u0982\u09a4\u09bf \u09a8\u09be \u09a5\u09be\u0995\u09b2\u09c7 \u099a\u0995\u09b2\u09c7\u099f \u09a7\u09b0\u09be\u0987\u09df\u09be \u09a6\u09c7\u09df... \u09ad\u09be\u0997\u09cd\u09af\u09bf\u09b8 \u09b6\u09be\u09df\u09c7\u09b8\u09cd\u09a4\u09be \u0996\u09be\u09b0 \u0986\u09ae\u09b2\u09c7 \u099c\u09a8\u09cd\u09ae\u09be\u0987\u09a8\u09bf \u09a8\u0987\u09b2\u09c7 \u09a4\u09cb \u09e7 \u099f\u09be\u0995\u09be \u09ad\u09be\u0982\u09a4\u09bf \u09a8\u09be \u09a5\u09be\u0995\u09b2\u09c7 \u09ee \u09ae\u09a8 \u099a\u09be\u0987\u09b2\u09c7\u09b0 \u09ac\u09b8\u09cd\u09a4\u09be \u09a7\u09b0\u09be\u0987\u09df\u09be \u09a6\u09bf\u09a4...!", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The image is a meme that is not hateful, it is a quote from a man who is talking to someone else. The meme is not hateful, it is just a quote from a man who is talking to someone else.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/chintashil (470).jpg", "text": "**\u09ad\u09be\u09b0\u09cd\u09b8\u09bf\u099f\u09bf \u0997\u09cd\u09b0\u09cd\u09af\u09be\u099c\u09c1\u09df\u09c7\u099f \u0995\u09b0\u09c7 \u09ac\u09bf\u09df\u09c7 \u0995\u09b0\u09c7 \u09b8\u0982\u09b8\u09be\u09b0 \u0995\u09b0\u09be \u09aa\u09cd\u09b0\u09ac\u09be\u09b8\u09c7 \u09a5\u09be\u0995\u09be \u09b8\u09ae\u09ac\u09df\u09b8\u09c0 \u09ac\u09a8\u09cd\u09a7\u09c1**    *\u098f\u0996\u09a8\u09cb \u09aa\u09be\u09ac\u09b2\u09bf\u0995 \u09ad\u09be\u09b0\u09cd\u09b8\u09bf\u099f\u09bf\u09b0 \u09ad\u09b0\u09cd\u09a4\u09bf \u09aa\u09b0\u09c0\u0995\u09cd\u09b7\u09be\u09b0 \u099c\u09a8\u09cd\u09af \u0985\u09aa\u09c7\u0995\u09cd\u09b7\u09be \u0995\u09b0\u09be \u0986\u09ae\u09bf** ", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The meme is not hateful, it is a quote from a movie. The quote is from a movie and is not intended to be hateful.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/Halal Memes (113).jpg", "text": "Fuckboy \u09af\u0996\u09a8 \u09b0\u09bf\u09b2\u09c7\u09b6\u09a8 \u0995\u09b0\u09c7 \u0964 \u09a8\u09c7\u09b6\u09be \u0995\u09c7\u099f\u09c7 \u0997\u09c7\u09b2\u09c7, \u09a4\u09c1\u09ae\u09bf\u0993 \u0995\u09c7\u099f\u09c7 \u09af\u09be\u09ac\u09c7 \u0964 ", "label": 1}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: A man is singing into a microphone with a caption that says "Futboy" in the background. The caption is in a foreign language, possibly Bengali.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/chintashil (872).jpg", "text": "\u099c\u09c0\u09ac\u09a8\u09c7\u0993 \u099b\u09be\u09a4\u09cd\u09b0\u09b2\u09c0\u0997 \u0995\u09b0\u09ac\u09c7 \u09a8\u09be \u09ac\u09b2\u09be \u09ac\u09a8\u09cd\u09a7\u09c1\u09b0 \u09b8\u09be\u09a5\u09c7 \u09af\u0996\u09a8 \u099b\u09be\u09a4\u09cd\u09b0\u09b2\u09c0\u0997\u09c7\u09b0 \u0995\u09ae\u09c7\u09a8\u09cd\u099f \u09ac\u0995\u09cd\u09b8\u09c7 \u09a6\u09c7\u0996\u09be \u09b9\u09df\u09c7 \u09af\u09be\u09df ", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The meme is not hateful, it is just a funny conversation between two men.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/Memeholics (197).jpg", "text": "*A bangladeshi celebrity gets married*    Divorce lawyers:  ", "label": 1}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: A meme with a picture of a man with money and the caption "A Bangladeshi celebrity gets married - divorce lawyers" is a not-hateful meme.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/netflix (97).jpg", "text": "Social distance  \u09a8\u09bf\u09df\u09c7 \u09b2\u09bf\u0996\u09be\u09b0 \u09aa\u09b0 \u09ac\u09bf\u09df\u09c7\u09b0 \u0985\u09a8\u09c1\u09b7\u09cd\u09a0\u09be\u09a8\u09c7 \u09af\u09be\u0993\u09df\u09be \u0986\u09ae\u09be\u09b0 \u09ac\u09a8\u09cd\u09a7\u09c1     Quarantine  \u098f\u09b0 \u09aa\u09cd\u09b0\u09df\u09cb\u099c\u09a8\u09c0\u09df\u09a4\u09be\u09b0 \u0989\u09aa\u09b0 \u0995\u09a5\u09be \u09ac\u09b2\u09c7 \u09b0\u09c7\u09b8\u09cd\u099f\u09c1\u09b0\u09c7\u09a8\u09cd\u099f\u09c7 \u09af\u09be\u0993\u09df\u09be \u0986\u09ae\u09bf ", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: A man and woman are in a car, and the man is looking out the window. The car is a blue one, and the woman is in the passenger seat. The car is in a foreign country, and the man is looking out the window at a sign that says 'social distance' in a foreign language. The sign is in a foreign country, and the man is looking out the window at a sign that says 'social distance' in a foreign language.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/tangaila (71).jpg", "text": "SOME OF THE SUPERHEROES WITH THEIR SOURCES OF POWER ", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The image is a collage of different superheroes with their sources of power. The caption reads "some of the superheroes with their sources of power."
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/nurani-memes (4).jpg", "text": "\u0986\u09b0\u09c7 \u09ac\u09c7\u099f\u09be \u0995\u09bf \u09ac\u09be\u09b2\u09c7\u09b0 Game of Thrones \u09a6\u09c7\u0996\u09b8, \u0988\u09a6 \u098f\u09b0 \u09a8\u09be\u099f\u0995\u0997\u09c1\u09b2\u09cb \u09a6\u09c7\u0996 \u09b8\u09c7\u0987 \u09ae\u099c\u09be \u09aa\u09be\u09ac\u09bf   \u09b9\u09cd\u09af\u09be\u09b2\u09cb, \u09aa\u09be\u09ac\u09a8\u09be \u09ae\u09be\u09a8\u09b8\u09bf\u0995 \u09b9\u09be\u09b8\u09aa\u09be\u09a4\u09be\u09b2 ? ", "label": 1}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The meme is a cartoon of a cat on a phone, with the caption "Tom and Jerry game of thrones" in a foreign language.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/chintashil (937).jpg", "text": "\u09b0\u09be\u09ae\u09bf\u0995\u09be \u09b8\u09c7\u09a8    \u09aa\u09cd\u09b0\u09c7\u09ae\u09bf\u0995\u09be \u09b8\u09c7\u09a8 ", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The meme is not hateful, it is just a picture of two women with different expressions.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/TR (163).jpg", "text": "\u09ab\u09b0\u09bf\u09a6\u09aa\u09c1\u09b0\u09c7\u09b0 \u0987\u099c\u09bf\u09ac\u09be\u0987\u0995 \u0993 \u09b0\u09bf\u0995\u09cd\u09b8\u09be\u099a\u09be\u09b2\u0995 \u09a8\u09bf\u099c\u09c7\u0995\u09c7 \u09af\u09c7\u09ae\u09a8\u099f\u09be \u09ae\u09a8\u09c7 \u0995\u09b0\u09c7 ***  ", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The meme is not hateful, it is just a joke.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/ovodro_img (1359).jpg", "text": "\u0986\u09b0 \u0995\u09a4\u0995\u09cd\u09b7\u09a3 \u09a8\u09be\u09dc\u09be\u09a4\u09c7 \u09b9\u09ac\u09c7 ?   \u09b8\u09ae\u09df \u098f\u09b2\u09c7 \u09aa\u09dc\u09ac\u09c7 \u099a\u09c1\u09df\u09c7 , \u09a8\u09bf\u099c\u09c7\u09b0 \u09b8\u09cd\u09ac\u09ad\u09be\u09ac\u09c7 ", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The meme is a picture of a woman with red eyes and a man with a speech bubble. The caption is in a foreign language, but the words "hateful" and "not-hateful" are written in English.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/tangaila (106).jpg", "text": "\u09af\u0996\u09a8 \u09b8\u09c3\u09b7\u09cd\u099f\u09bf \u09b8\u09cd\u0995\u09c1\u09b2 \u099b\u09c1\u099f\u09bf \u09a6\u09c7\u09df...  Then me:-  ", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The meme is a picture of a man in a cage with the caption "then me" in a foreign language. The meme is not hateful, but it is not hateful either.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/TR (260).jpg", "text": "jokhon tumi porikkhay shobar age khata joma dao     Tomar Khata :      Mujhe chhod kar jo tum jaoge bada pachtaoge  ", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The meme is a picture of a man with a caption that says 'Jokhon Tum Porkiya Shahee Jote Kha Kha Do' which translates to 'I'll make you laugh with my jokes'. The caption is a quote from a movie called 'Tum Bin'. The meme is not hateful, but it is a joke that is not appropriate for all audiences.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/nurani-memes (217).jpg", "text": "Beta ek zamana tha jab hum bhi Politics krte the ", "label": 1}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The meme is not hateful, it is just a political statement.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/CM (314).jpg", "text": "My mother convincing me  \u09af\u09c7 \u098f\u0987 \u0988\u09a6\u09c7 \u09aa\u09be\u099e\u09cd\u099c\u09be\u09ac\u09bf \u0995\u09bf\u09a8\u09c7 \u0995\u09cb\u09a8\u09cb \u09b2\u09be\u09ad \u09a8\u09be\u0987   ", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The meme is a picture of a man with a caption that says "My mother convincing me to do something." The caption is in a foreign language, possibly Vietnamese.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/bamboo-vaiya (494).jpg", "text": "*\u09ad\u09be\u09a6\u09cd\u09b0 \u09ae\u09be\u09b8 exists*  \u098f\u0995 \u0995\u09c1\u0995\u09c1\u09b0 to \u0985\u09a8\u09cd\u09af \u0995\u09c1\u0995\u09c1\u09b0    \u0995\u09c0\u09b0\u09c7, \u09aa\u09c7\u099b\u09a8 \u09a5\u09c7\u0995\u09c7 \u0996\u09cb\u099a\u09be\u099a\u09cd\u099b\u09bf\u09b8 \u0995\u09c7\u09a8 ? ", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The meme is a political cartoon that is not hateful, but it is a political cartoon that is not hateful.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/bangla-gag (35).jpg", "text": "\u0995\u09bf \u09ad\u09be\u09ac\u09b8\u09bf\u09b2\u09be ?     \u0986\u09ae\u09bf \u09b6\u09c1\u09a7\u09c1 \u0993\u09df\u09be\u09a8\u09a1\u09c7\u09a4\u09c7 \u0987 \u09b8\u09c7\u099e\u09cd\u099a\u09c1\u09b0\u09bf \u0995\u09b0\u09a4\u09c7 \u09aa\u09be\u09b0\u09bf ? ", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The image is a meme that is not hateful, it is a funny picture of a man with a funny caption.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/chosha (19).jpg", "text": "\u099c\u09be\u09a8\u09c1 \u0986\u09ae\u09bf \u0995\u09bf \u0997\u09be\u099b ?     \u09a8\u09be\u09a4\u09cb \u0995\u09c7\u09a8\u09cb !    \u09a4\u09be\u09b9\u09b2\u09c7 \u09ac\u09b2\u09b2\u09c7 \u0995\u09c7\u09a8\u09cb \u09e7\u09ea \u09ab\u09cd\u09b0\u09c7\u09ac\u09cd\u09b0\u09c1\u09df\u09be\u09b0\u09c0 \u0986\u09ae\u09be\u0995\u09c7 \u09b2\u09be\u0997\u09be\u09ac\u09c7 ?", "label": 1}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The meme is not hateful, it is just a picture of a man and woman with a caption in a foreign language.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/bangla-troll (11).jpg", "text": "\"\u09ae\u09c7\u09df\u09c7\u099f\u09bf \u09b6\u09aa\u09bf\u0982 \u0995\u09b0\u09a4\u09c7 \u099a\u09be\u0987\u099b\u09c7\" \u098f\u0987\u099f\u09be \u0995\u09cb\u09a8 \u09aa\u09a6 ? \u09ac\u09bf\u09aa\u09a6 !", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The meme is not hateful, it is just a joke.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/TR (528).jpg", "text": "\u09ad\u09be\u09ac\u09c0\u09b0 \u09a6\u09c1\u09a7 \u099a\u09be    \u0986\u09ae\u09bf**     \u09b0\u0998\u09c1 \u09a6\u09be\u09b0 \u099a\u09be ", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The meme is not hateful, it is just a comedic scene with a man and woman in it.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/Memeholics (129).jpg", "text": "\u09ad\u09c7\u0999\u09cd\u0997\u09c7 \u09ae\u09cb\u09b0 \u0998\u09b0\u09c7\u09b0 \u099a\u09be\u09ac\u09bf \u09a8\u09bf\u09df\u09c7 \u09af\u09be\u09ac\u09bf \u0995\u09c7 \u0986\u09ae\u09be\u09b0\u09c7 ...    \u09a4\u09be\u09b2\u09be \u09a8\u09be \u09ad\u09c7\u0999\u09cd\u0997\u09c7 , \u099a\u09be\u09ac\u09bf \u0995\u09c7\u09a8 \u09ad\u09be\u0999\u09ac\u09c7 \u09b8\u09c7\u099f\u09be \u09a8\u09bf\u09df\u09c7 \u099a\u09bf\u09a8\u09cd\u09a4\u09be \u0995\u09b0\u09be \u09aa\u09be\u09a0\u0995 ", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The image is a meme that is not hateful, it is just a funny picture of a man with a beard and a woman in a store.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/bangla-gag (5).png", "text": "Hey Mathews !    YES SAKIB BHAI ?    YOU THOUGHT BANGLADESH'S NOTHING ME, DIDN'T YOU?", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: A meme with two different pictures of a man, one with a hateful message and the other with a not-hateful message.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/ovodro_img (378).jpg", "text": "No Caption ", "label": 1}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: A man is shown in a meme with a caption that says 'hateful' and 'not-hateful' in the same sentence.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/bamboo-vaiya (391).jpg", "text": "\u09ad\u09bf\u0995\u09cd\u09b7\u09c1\u0995\u09c7\u09b0 \u09ae\u09a4 \u09ad\u09cb\u099f \u099a\u09c7\u09df\u09c7 \u09ab\u099f\u09cb \u0995\u09a8\u099f\u09c7\u09b8\u09cd\u099f \u099c\u09bf\u09a4\u09be\u09b0 \u09aa\u09b0 \u0995\u09be\u09ae\u09b2\u09be\u09b0\u09be-   LIFE IS A GAME OF COMPETITION ", "label": 1}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The meme is a picture of a man with a gun, and the text is in Bengali. The text is a quote from a Bengali movie, and it is not hateful.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/bamboo-vaiya (128).jpg", "text": "Crush:-  \u09af\u09be\u09b0\u09be profile \u098f candid \u099b\u09ac\u09bf upload \u09a6\u09c7\u09df, \u09a4\u09be\u09a6\u09c7\u09b0\u0995\u09c7 \u0986\u09ae\u09be\u09b0 \u0985\u09a8\u09c7\u0995 \u09ad\u09be\u09b2\u09cb \u09b2\u09be\u0997\u09c7  *10 seconds later    Me:- ", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The meme is a picture of a man standing in front of a waterfall, with the caption "10 seconds later" and a comment about the man's appearance. The meme is not hateful, but it is not hateful either.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/chintashil (698).jpg", "text": "\u0995\u09ac\u09bf / \u09b8\u09be\u09b9\u09bf\u09a4\u09cd\u09af\u09bf\u0995  when they write using their real name      \u0995\u09ac\u09bf / \u09b8\u09be\u09b9\u09bf\u09a4\u09cd\u09af\u09bf\u0995  when they write using their  \u099b\u09a6\u09cd\u09ae\u09a8\u09be\u09ae   ", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The meme is a comparison between a hateful and not-hateful meme. The hateful meme is a picture of a group of people in a line, with the caption "when they write their real names." The not-hateful meme is a picture of a group of people in a line, with the caption "when they write their names."
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/TR (207).jpg", "text": "Stamford First Year    Aur ye main aasmaan ki unchaaiyn mein          Stamford Last Year      Main madarchod hoon ismein aaya", "label": 1}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The image is a meme that is not hateful, it is a funny picture of a man on a parachute with a caption that says "Stanford First Year" and "Stanford Last Year."
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/ovodro_img (674).jpg", "text": "\u09aa\u09be\u0997\u09b2\u09c0\u09a6\u09c7\u09b0 \u09aa\u099b\u09a8\u09cd\u09a6\u09c7\u09b0 \u0995\u09bf\u099b\u09c1 \u099c\u09bf\u09a8\u09bf\u09b8     \u09b9\u09be\u0993\u09df\u09be\u0987 \u099a\u099f\u09bf    \u0986\u0987\u09ab\u09cb\u09a8    \u09ac\u0996\u09be\u099f\u09c7 \u099b\u09c7\u09b2\u09c7\u09aa\u09bf\u09b2\u09c7    \u099a\u09aa \u09b6\u09bf\u09b2\u09cd\u09aa ", "label": 1}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The meme is not hateful, it is just a collection of different items and a caption in a foreign language.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/ovodro_img (30).jpg", "text": "\u09b8\u09be\u09ab\u09b2\u09cd\u09af\u09c7\u09b0 \u09a6\u09bf\u0995\u09c7 \u098f\u0997\u09cb\u09a4\u09c7 \u09a6\u09bf\u09ac\u09bf \u09a4\u09cb ?    \u09b9\u09cd\u09af\u09be\u0981, \u09a6\u09c7\u09ac   \u09a4\u09be\u09b9\u09b2\u09c7 \u099a\u09cb\u0996 \u09ac\u09a8\u09cd\u09a7 \u0995\u09b0\u09b2\u09bf \u0995\u09c7\u09a8 ?    \u09b8\u09be\u09ab\u09b2\u09cd\u09af\u09c7\u09b0 \u09aa\u09a5 \u0995\u09be\u09b0 \u0995\u09be\u09b0 \u099c\u09a8\u09cd\u09af \u09ae\u09a8\u09c7 \u0995\u09b0\u099b\u09bf\u09b2\u09be\u09ae ! ", "label": 1}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The image is a meme that is not hateful, it is a romantic scene between two people.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/KAM (231).png", "text": "\u09ac\u09be\u0982\u09b2\u09be\u09a6\u09c7\u09b6\u09c7\u09b0 \u09b8\u09ac\u099a\u09c7\u09df\u09c7 \u09ac\u09dc \u09b8\u09cb\u09a8\u09be\u09b0 \u0996\u09a8\u09bf \u0995\u09cb\u09a5\u09be\u09df \u0985\u09ac\u09b8\u09cd\u09a5\u09bf\u09a4 ??  \u099c\u09bf\u09df\u09be \u0986\u09a8\u09cd\u09a4\u09b0\u09cd\u099c\u09be\u09a4\u09bf\u0995 \u09ac\u09bf\u09ae\u09be\u09a8\u09ac\u09a8\u09cd\u09a6\u09b0\u09c7", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The image is a meme that is not hateful, it is a funny picture of two men with different ages and one of them is pointing at the other.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/ovodro_img (837).jpg", "text": "\u09ac\u099b\u09b0\u09c7 \u09e7\u09e6 \u0995\u09cb\u099f\u09bf SALARY \u09a8\u09c7\u0993\u09df\u09be\u09b0 \u09aa\u09b0     \u09a6\u09be\u0981\u09dc\u09be \u09a4\u09cb\u09b0 \u09b9\u099a\u09cd\u099b\u09c7  ", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The meme is a picture of a man in a car with a caption that says "salary" in a foreign language. The meme is not hateful, but it is not hateful either.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/Bangla Thug Life (239).jpg", "text": "\u09ac\u09cc\u09ae\u09be \u09a8\u09be\u09a4\u09bf \u09a6\u09c7\u0996\u09a4\u09c7 \u09a4\u09cb \u0986\u09ae\u09be\u09b0 \u099b\u09c7\u09b2\u09c7\u09b0 \u09ae\u09a4\u09cb \u09b9\u09b2\u09cb \u09a8\u09be     \u09b6\u09cb\u09a8\u09c7\u09a8 \u0986\u09ae\u09bf \u0995\u09cb\u09a8\u09cb \u09ab\u099f\u09cb \u09ae\u09c7\u09b6\u09bf\u09a8 \u09a8\u09be \u09af\u09c7 \u09b9\u09c1\u09ac\u09b9\u09c1 \u09a1\u09c7\u09b2\u09bf\u09ad\u09be\u09b0\u09bf \u09a6\u09bf\u09ac\u09cb ", "label": 1}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The image is a meme that is not hateful, it is a quote from a woman who is talking to another woman. The quote is in a foreign language, but the words are still legible.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/ovodro_img (930).jpg", "text": "\u09b0\u09a8\u09ac\u09c0\u09b0 \u0986\u09ae\u09be\u09b0 \u09a8\u09a4\u09c1\u09a8 \u09a1\u09cd\u09b0\u09c7\u09b8 \u0996\u09c1\u0981\u099c\u09c7 \u09aa\u09be\u099a\u09cd\u099b\u09bf \u09a8\u09be !   \u09a6\u09c7\u0996\u09c7\u099b\u09cb \u0995\u09c0 \u09a4\u09c1\u09ae\u09bf ?     \u09a8\u09be \u09a6\u09c7\u0996\u09bf\u09a8\u09bf \u09a6\u09bf\u09aa\u09c1 ", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The meme is not hateful, it is not intended to denigrate, vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/KAM (130).jpg", "text": "\u09a1\u09be\u0995\u09cd\u09a4\u09be\u09b0 \u0986\u09b8\u09bf\u09ac\u09be\u09b0 \u09aa\u09c2\u09b0\u09cd\u09ac\u09c7 \u09b0\u09cb\u0997\u09bf\u099f\u09bf \u09ae\u09be\u09b0\u09be \u0997\u09c7\u09b2 \u098f\u0987\u099f\u09be \u0995\u09cb\u09a8 \u0995\u09be\u09b2? \u0987\u09a8\u09cd\u09a4\u09c7\u0995\u09be\u09b2", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The image is a meme that is not hateful, it is a funny and lighthearted image.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/CM (571).jpg", "text": "\u099b\u09cb\u099f\u09ac\u09c7\u09b2\u09be\u09df \u0986\u09ae\u09bf \u0993 \u0986\u09ae\u09be\u09b0 \u09ac\u09a8\u09cd\u09a7\u09c1\u09b0\u09be \u09aa\u09cd\u09b0\u09a4\u09bf\u09ac\u09c7\u09b6\u09c0\u09b0 \u0995\u09b2\u09bf\u0982 \u09ac\u09c7\u09b2 \u09ac\u09be\u099c\u09be\u09a8\u09cb\u09b0 \u09aa\u09b0 -     \u099a\u09b2\u09cb \u09aa\u09be\u09b2\u09be\u0987 \u09aa\u09be\u09b2\u09be\u0987  ", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The meme is a picture of a man sitting in a car with a caption that is written in a foreign language. The caption is not hateful, but it is not not-hateful either.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/bangla-memes (26).jpg", "text": "\u09af\u0996\u09a8 \u09a4\u09cb\u09ae\u09be\u09b0 \u099b\u09c7\u09b2\u09c7\u09b0\u09be \u0986\u09b0\u09cd\u099c\u09c7\u09a8\u09cd\u099f\u09bf\u09a8\u09be \u09b8\u09be\u09aa\u09cb\u09b0\u09cd\u099f \u0995\u09b0\u09be \u099b\u09c7\u09dc\u09c7 \u09a6\u09c7\u09df        \u09ae\u09be\u09a6\u0995\u0995\u09c7 '\u09a8\u09be' \u09ac\u09b2\u09cb  PROTHOMALO.COM     '\u0986\u09ae\u09be\u09b0 \u099b\u09c7\u09b2\u09c7\u09b0\u09be \u098f\u0996\u09a8 \u09ae\u09be\u09a6\u0995\u09cd\u09ae\u09c1\u0995\u09cd\u09a4'    \u09a4\u09bf\u09a8\u09bf \u098f\u0995\u099c\u09a8 \u09af\u09c1\u09a6\u09cd\u09a7\u099c\u09df\u09c0 \u09ac\u09be\u09ac\u09be \u0964 \u09ae\u09be\u09a6\u0995\u09be\u09b8\u0995\u09cd\u09a4 \u09a6\u09c1\u0987 \u099b\u09c7\u09b2\u09c7\u0995\u09c7 \u09b8\u09c1\u09b8\u09cd\u09a5 \u099c\u09c0\u09ac\u09a8\u09c7 \u09ab\u09bf\u09b0\u09bf\u09df\u09c7   ", "label": 1}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The image is a meme that is not hateful, but it is a political statement. The man in the picture is a politician, and the meme is a political statement.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/chintashil (129).jpg", "text": "Notification Fact    Nibbi Sent a photo:    Nibba's Reaction: ", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The image is a meme that is not hateful, it is a funny picture of two people with a caption that is not meant to harm or denigrate anyone.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/Bangla Thug Life (110).jpg", "text": "\u09b8\u09bf\u09a8\u09bf\u09df\u09b0\u0983 \u0995\u09bf\u09b0\u09c7 \u09e8/\u09e9 \u099f\u09be \u099c\u09bf\u098f\u09ab \u098f\u0995\u09b8\u09be\u09a5\u09c7 \u0995\u09c7\u09ae\u09a8\u09c7 ? \u099c\u09c1\u09a8\u09bf\u09df\u09b0\u0983   \u09ae\u09a8\u09c7 \u0995\u09b0\u09c7\u09a8 \u09ad\u09be\u0987 \u09b8\u09ac\u0987 \u0995\u09aa\u09be\u09b2 ", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The image is a meme that is not hateful, it is a funny picture of two men talking to each other. The caption is in a foreign language, but the image is not hateful.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/netflix (173).jpg", "text": "\u0986\u09ae\u09be\u09b0 \u09ac\u09be\u09ac\u09be-\u09ae\u09be\u0983 \u09ac\u09dc \u09b9\u09df\u09c7 \u0986\u09ae\u09be\u09a6\u09c7\u09b0 \u09b8\u09a8\u09cd\u09a4\u09be\u09a8 \u0986\u09ae\u09be\u09a6\u09c7\u09b0 \u09ae\u09c1\u0996 \u0989\u099c\u09cd\u099d\u09b2 \u0995\u09b0\u09ac\u09c7    \u09ac\u09dc \u09b9\u0993\u09df\u09be\u09b0 \u09aa\u09b0 \u0986\u09ae\u09bf\u0983      I will kill myself. ", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The meme is a quote from the TV show The Office, and it is not hateful.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/ovodro_img (1274).jpg", "text": "\u0995\u09be\u09b2 \u09b0\u09be\u09a4\u09c7 \u0986\u09ae\u09bf \u0998\u09c1\u09ae\u09be\u09a8\u09cb\u09b0 \u09aa\u09b0 \u0995\u09cb\u09a5\u09be\u09df \u099b\u09bf\u09b2\u09c7 ?   \u09ac\u09be\u09a5\u09b0\u09c1\u09ae\u09c7    \u0986\u09ae\u09be\u09a6\u09c7\u09b0 \u09ac\u09be\u09a5\u09b0\u09c1\u09ae \u09a5\u09be\u0995\u09a4\u09c7 \u09ac\u09be\u09ac\u09be\u09b0 \u09ac\u09be\u09a5\u09b0\u09c1\u09ae\u09c7 \u09a6\u09c1\u0998\u09a8\u09cd\u099f\u09be \u0995\u09be\u099f\u09be\u09a4\u09c7 \u09b9\u09b2\u09cb ! ", "label": 1}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The image is a meme that is not hateful, it is a funny picture of a couple with a caption that is not intended to harm or mock anyone.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/TR (77).jpg", "text": "\u09af\u0996\u09a8 \u0995\u09cd\u09b2\u09be\u09b8 \u099f\u09bf\u099a\u09be\u09b0 \u09ac\u09b2\u09c7 \u09af\u09be\u09b0\u09be \u09af\u09be\u09b0\u09be \u0995\u09be\u09b2\u0995\u09c7 \u09b8\u09cd\u0995\u09c1\u09b2 \u09aa\u09b2\u09be\u09df\u099b\u09bf\u09b2\u09bf \u09a4\u09be\u09b0\u09be \u09b8\u09ac\u09be\u0987 \u09b9\u09be\u09a4 \u09a4\u09cb\u09b2    \u09a4\u0996\u09a8 \u0986\u09ae\u09bf  ", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The meme is not hateful, it is just a funny picture of a young boy with a funny caption.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/nurani-memes (168).jpg", "text": "Me   My unconditional Love     *My Crush  \u098f\u0987 ,\u098f\u0987\u099f\u09be \u098f\u0987\u0996\u09be\u09a8 \u09a5\u09bf\u0995\u09be \u09a8\u09bf\u09df\u09be \u09af\u09be\u0993 \u0964", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The image is a meme that is not hateful, but it is a meme that is hateful.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/ovodro_img (719).jpg", "text": "\u09af\u0996\u09a8 \u0995\u09cd\u09b2\u09be\u09b6\u09c7 \u09ae\u09cd\u09af\u09be\u09ae \u09b8\u09cd\u099f\u09c1\u09a1\u09c7\u09a8\u09cd\u099f\u09a6\u09c7\u09b0 \u09ac\u0995\u09be\u09ac\u0995\u09bf \u0995\u09b0\u09c7      Students :     Maam's husband can't fuck her well  ", "label": 1}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The meme is a picture of two women with the caption "Students: Mom's husband can't fuck her well." The meme is not hateful, but it is not appropriate for all audiences.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/chintashil (816).jpg", "text": "\u09b6\u09bf\u0995\u09cd\u09b7\u09be\u09ae\u09a8\u09cd\u09a4\u09cd\u09b0\u09a3\u09be\u09b2\u09df :-    Gonna Cry? ", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: A man is shown on a television screen with a caption that says "gone cry?" in a foreign language. The caption is not hateful, but it is a question that is asking if the man is crying.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/bamboo-vaiya (545).jpg", "text": "THIS IS RAB : \u0996\u09be\u09a8\u0995\u09bf\u09b0\u09aa\u09cb\u09b2\u09be \u09a6\u09b0\u099c\u09be \u0996\u09cb\u09b2 ", "label": 1}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The meme is not hateful, it is a political statement.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/chintashil (143).jpg", "text": "Nobody:  \u09a8\u09be\u0989\u099c\u09c1\u09ac\u09bf\u09b2\u09cd\u09b2\u09be\u09b9 Level khaccors  \u099a\u09c7\u09a4\u09a8\u09be \u099a\u09c1\u09b2\u0995\u09be\u09a8\u09cb\u09b0 \u09aa\u09b0\u0983 ", "label": 1}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The meme is a collage of three different people, one of whom is making a face. The meme is not hateful, but it is not hateful either.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/chintashil (1023).jpg", "text": "\u099c\u0997     \u099c\u09be\u0997\u09bf     \u09ae\u0997     ", "label": 1}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The meme is a picture of a child with the words "hateful" and "not-hateful" above it. The child is shown in a state of discomfort, and the meme is meant to be humorous.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/KAM (7).png", "text": "\u099b\u09c7\u09b2\u09c7 \u09ef\u09ef% \u09ad\u09be\u09b2\u09cb..\u09b6\u09c1\u09a7\u09c1 indiar \u09a6\u09be\u09b2\u09be\u09b2\u09bf \u0995\u09b0\u09c7 \u0986\u09b0\u0995\u09bf!", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The meme is not hateful, it is just a funny picture of a man with a mustache and a hat.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/TR (188).jpg", "text": "\u0997\u09a4\u09bf\u09b0 \u09a6\u09bf\u0995 \u09a6\u09bf\u09df\u09c7    \u09ae\u09df\u09ae\u0982\u09b8\u09bf\u09b9\u09c7 \u0986\u099b\u09c7 \u098f\u09a8\u09be \u09aa\u09b0\u09bf\u09ac\u09b9\u09a8     \u0986\u09b0 \u09ab\u09b0\u09bf\u09a6\u09aa\u09c1\u09b0\u09c7 \u0986\u099b\u09c7 \u0985\u099f\u09cb\u09b0\u09bf\u0995\u09cd\u09b8\u09be \u09aa\u09b0\u09bf\u09ac\u09b9\u09a8  ", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The image is a meme that is not hateful, it is a picture of a bus and a tuk-tuk with a caption that is not hateful.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/bangla-gag (57).jpg", "text": " \u09ae\u09c7\u09df\u09c7\u09b0\u09be \u09ae\u09c1\u0996\u09c7 \u098f\u09a4\u09cd\u09a4\u0997\u09c1\u09b2\u09be \u09ae\u09c7\u0995\u09be\u09aa \u09ae\u09be\u09b0\u09c7 !    \u09a4\u09be\u09b0\u09aa\u09b0\u09c7\u0993 \u09b8\u09c7\u09b2\u09ab\u09bf \u09a4\u09c1\u09b2\u09c7 \u098f\u09a1\u09bf\u099f \u0995\u09b0\u09c7 \u099a\u09c7\u09b9\u09be\u09b0\u09be \u09b8\u09be\u09a6\u09be \u0995\u09b0\u09c7 ! ", "label": 1}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The meme is not hateful, it is just a funny picture of a man in a clown costume with a caption that is not hateful.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/ovodro_img (1333).jpg", "text": "\u09aa\u09cd\u09b0\u09a5\u09ae\u09c7 \u09ac\u09b2 \u09a1\u099f \u0995\u09b0\u09be\u09b0 \u099c\u09a8\u09cd\u09af \u09af\u0996\u09a8 \u09b8\u09ac\u09be\u0987 \u0997\u09be\u09b2\u09bf \u09a6\u09c7\u09df \u098f\u09ac\u0982 \u09b6\u09c7\u09b7\u09c7 \u098f\u0995 \u0993\u09ad\u09be\u09b0\u09c7 \u09a4\u09cd\u09b0\u09bf\u09b6 \u0995\u09b0\u09c7 \u09ae\u09cd\u09af\u09be\u099a \u099c\u09bf\u09a4\u09bf\u09df\u09c7 \u09a6\u09be\u0993 \u0986\u09b0 \u09b8\u09ac\u09be\u0987 \u09ad\u09be\u09ac\u09c7 \u0997\u09be\u09b2\u09be\u0997\u09be\u09b2\u09bf \u0995\u09b0\u09be\u099f\u09be \u09ad\u09c1\u09b2 \u09b9\u09df\u09c7\u099b\u09c7     \u09a4\u0996\u09a8 \u09b0\u09be\u09b9\u09c1\u09b2 \u099f\u09c7\u0993\u099f\u09bf\u09df\u09be    Kaisa laga mera mazak", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The image is a meme that is not hateful, it is a funny picture of a man with a beard and a caption that is not intended to harm or mock anyone.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/bangla-memes (156).jpg", "text": "UDVASH waiting for my birthday to wish me through messages like :", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The meme is a birthday message to someone, but the person is not happy about it.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/bangla-gag (59).jpg", "text": "\u09ac\u09be\u0982\u09b2\u09be\u09a6\u09c7\u09b6\u09c7\u09b0 \u099f\u09bf\u09ad\u09bf \u099a\u09cd\u09af\u09be\u09a8\u09c7\u09b2\u0997\u09c1\u09b2\u09cb      \u09ac\u099b\u09b0\u09c7\u09b0 \u09e7\u09e7 \u09ae\u09be\u09b8     \u09b0\u09ae\u099c\u09be\u09a8 \u09ae\u09be\u09b8\u09c7  ", "label": 1}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The image is a meme that is not hateful, it is not intended to denigrate, vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/ovodro_img (585).jpg", "text": "\u09a4\u09c1\u09ae\u09bf \u09a6\u09c7\u0996\u09c7\u099b\u09cb \u0986\u09b8\u09b2 \u09aa\u09cd\u09b0\u09ac\u09b2\u09c7\u09ae \u099f\u09be \u0995\u09cb\u09a5\u09be\u09df \u09b6\u09c1\u09b0\u09c1 \u09b9\u09df\u09c7\u099b\u09bf\u09b2 !     \u09ae\u09a6\u09a8 \u09a6\u09be\u09b0 \u098f\u0987 \u09b9\u09be\u0981\u09b8\u09bf\u099f\u09be    \u09b9\u09cd\u09af\u09be\u0981, \u098f\u0987 cute \u09b9\u09be\u0981\u09b8\u09bf\u099f\u09be\u09a4\u09c7\u0987 \u09b8\u09ac \u09ae\u09c7\u09df\u09c7 \u0995\u09cd\u09b0\u09be\u09b6 \u0996\u09be\u09df ", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The image is a meme that is not hateful, it is a funny picture of a man and a woman with a caption that says 'cute'.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/chintashil (187).jpg", "text": "\u099c\u09c0\u09ac\u09a8\u09c7 \u0995\u09cb\u09a8\u09cb\u09a6\u09bf\u09a8 \u0997\u09bf\u099f\u09be\u09b0 \u09ae\u09be\u09b0\u09ac\u09cb \u09a8\u09be \u09b8\u09bf\u09a6\u09cd\u09a7\u09be\u09a8\u09cd\u09a4 \u09a8\u09c7\u09df\u09be\u09b0 \u09e8 \u0998\u09a8\u09cd\u099f\u09be \u09aa\u09b0\u0987 \u09af\u0996\u09a8 \u0986\u09ac\u09be\u09b0 \u0997\u09bf\u099f\u09be\u09b0 \u09ac\u09be\u099c\u09be\u09a4\u09c7 \u09b9\u09df     \u0986\u09ae\u09bf \u09b6\u09be\u09b2\u09be\u09b0 \u099c\u09be\u09a4\u09c0\u09df \u09ac\u09c7\u0988\u09ae\u09be\u09a8 ", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The meme is not hateful, it is just a funny picture of a man in a jail cell with a caption that says "I'm not hateful, I'm just a little bit in love with you."
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/CM (211).jpg", "text": "Coronavirus    Covid-19  ", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The meme is a comparison between two women, one of whom is wearing glasses and the other is not. The meme is not hateful, but it is not hateful either.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/bangla-gag (47).jpg", "text": "\u0986\u0997\u09c7 \u09b6\u09c1\u09a7\u09c1 \u098f\u0995 \u09ae\u09be\u09b6\u09b0\u09be\u09ab\u09bf \u099b\u09bf\u09b2 !    \u0986\u09b0 \u098f\u0996\u09a8 \u09ae\u09be\u09b6\u09b0\u09be\u09ab\u09bf\u09b0 \u09b8\u09be\u09a5\u09c7 \u09ae\u09c1\u09b8\u09cd\u09a4\u09be\u09ab\u09bf\u099c, \u09a4\u09be\u09b8\u0995\u09bf\u09a8, \u09b0\u09c1\u09ac\u09c7\u09b2 !", "label": 1}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The meme is not hateful, it is just a funny picture of two men with a caption that is not meant to be taken seriously.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/ovodro_img (1295).jpg", "text": "She : \u09ac\u09be\u09ac\u09c1 \u09a4\u09c1\u09ae\u09bf \u0996\u09be\u0987\u09b8\u09cb ?    \u09ac\u09be\u09ac\u09c1 : -      \u09a8\u09be , \u0996\u09be\u099a\u09cd\u099b\u09bf ", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The meme is a picture of a woman breastfeeding her baby, with the caption "She She She She She She She She She She She She She She She She She She She She She She She She She She She She She She She She She She She She She She She She She She She She She She She She She She She She She She She She She She She She She She She She She She She She She She She She She She She She She She She She
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/bamboo-vaiya (254).jpg", "text": "exam er first srijonshil    exam er last srijonshil", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The meme is a collage of three pictures of a girl, one of which is hateful and the other two are not. The girl is smiling in the hateful picture, and the other two are not.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/KAM (96).jpg", "text": "\u09b6\u09c2\u09a8\u09cd\u09af \u0995\u09c7 \u0986\u09ac\u09bf\u09b7\u09cd\u0995\u09be\u09b0 \u0995\u09b0\u09c7\u09a8? \u0997\u09cc\u09a4\u09ae \u0997\u09ae\u09cd\u09ad\u09c0\u09b0 \u0995\u09c7\u0989 \u0993\u0995\u09c7 \u09ae\u09c7\u09b0\u09c7 \u09ab\u09c7\u09b2! ", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The image is a meme that is not hateful, it is a funny and lighthearted joke.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/ovodro_img (750).jpg", "text": "\u099a\u09be\u09b0 \u0987\u099e\u09cd\u099a\u09bf     \u0986\u099f \u0987\u099e\u09cd\u099a\u09bf  ", "label": 1}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The meme is a picture of a woman with a banana in her mouth, and the caption is in Hindi. The meme is not hateful, but it is not hateful either.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/tangaila (272).jpg", "text": "No Caption", "label": 1}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The meme is not hateful, it is just a funny picture of a man in the mud with a phone in his mouth.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/chintashil (669).jpg", "text": "\u0995\u09b2\u09c7\u099c \u09b2\u09be\u0987\u09ab\u09c7 \u098f\u0995\u09cd\u09b8\u09be\u09ae\u09c7\u09b0 \u0986\u0997\u09c7\u09b0 \u09b0\u09be\u09a4\u09c7 \u09a4\u09a5\u09cd\u09af \u0993 \u09af\u09cb\u0997\u09be\u09af\u09cb\u0997 \u09aa\u09cd\u09b0\u09af\u09c1\u0995\u09cd\u09a4\u09bf \u09ac\u0987 \u09a8\u09bf\u09df\u09c7 \u09aa\u09dc\u09a4\u09c7 \u09ac\u09b8\u09be\u09b0 \u09aa\u09b0     \u0986\u09ae\u09bf\u0983 ", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The meme is a picture of a soccer player with a question mark above his head. The meme is not hateful, but it is not hateful either.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/bangla-memes (27).jpg", "text": "\u0996\u09be\u09b2\u09c7\u09a6\u09be \u099c\u09bf\u09df\u09be \u099c\u09c7\u09b2\u09c7 \u09af\u09be\u0993\u09df\u09be\u09b0 \u09aa\u09b0\u09c7 \u09ae\u09bf\u09b0\u09cd\u099c\u09be \u09ab\u0996\u09b0\u09c1\u09b2 \u0987\u09b8\u09b2\u09be\u09ae \u09af\u09c7\u09ad\u09be\u09ac\u09c7 \u09ac\u09bf\u098f\u09a8\u09aa\u09bf\u0995\u09c7 \u098f\u0997\u09bf\u09df\u09c7 \u09a8\u09bf\u099a\u09cd\u099b\u09c7\u09a8  ", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The image is a meme that is not hateful, it is a political cartoon that is not intended to harm or mock any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/chintashil (382).jpg", "text": "15 \u09ac\u099b\u09b0 /\u09ac\u09df\u09b8\u09c0 \u0986\u09ae\u09bf \u09aa\u09cd\u09b0\u09a5\u09ae\u09ac\u09be\u09b0    \"Sex Education\" Movie \u09a6\u09c7\u0996\u09be\u09b0 \u09aa\u09b0    Where Sex ? ", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The image is a meme that is not hateful, it is a joke. The three monkeys are sitting in front of a TV with the caption "1555 ಸಂಸಸಿಕೆಟುಗಳಿని ಸಂಸಸಸಿ
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/TR (154).jpg", "text": "\u09aa\u09b0\u09c0\u0995\u09cd\u09b7\u09be\u09b0 \u0986\u0997\u09c7\u09b0  \u09b0\u09be\u09a4\u09c7\u09b0 \u09aa\u09dc\u09be\u09b6\u09cb\u09a8\u09be     Me    Semester Final", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The meme is a picture of a man pointing a gun at someone, with the caption "Semester Final" in the background. The meme is not hateful, but it is a play on words, as the word "Semester" is often used in academic settings, and "Final" is a term used to indicate the end of a semester.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/chintashil (837).jpg", "text": "\u0986\u09ae\u09bf \u099f\u09be\u09a8\u09be \u09eb\u099f\u09be 'Man of the match'   \u099c\u09bf\u09a4\u09c7\u099b\u09bf  *IPL teams   I don't even know who you are    ", "label": 1}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The meme is a picture of a man in a green shirt with the caption 'I don't even know who you are.' The caption is a response to a hateful meme that is not hateful.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/nurani-memes (79).jpg", "text": "When you go to the examhall and teacher puts you in the first bench ", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The meme is a picture of a man with a caption that reads "when you go to the exam and the teacher puts you in the first bench." The meme is not hateful, but it is a humorous caption that is meant to be funny.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/chintashil (522).jpg", "text": "\u09e7\u09e6 \u099c\u09a8 \u09ac\u09a8\u09cd\u09a7\u09c1 \u09ae\u09bf\u09b2\u09c7 \u099f\u09cd\u09af\u09c1\u09b0\u09c7\u09b0 \u09aa\u09cd\u09b2\u09cd\u09af\u09be\u09a8 \u0995\u09b0\u09b2\u09be\u09ae;  \u099f\u09cd\u09af\u09c1\u09b0\u09c7\u09b0 \u09a6\u09bf\u09a8:    Where are all the people ?    ", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: A man and a woman are standing in front of a bus, with the woman asking the man where they are all people. The man is wearing a suit and the woman is wearing a dress. The meme is not hateful, but it is not hateful either.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/ovodro_img (265).jpg", "text": "\u0986\u09b2\u09ab\u09cd\u09b0\u09c7\u09a1 \u0986\u09ae\u09bf \u0995\u09bf\u099b\u09c1 \u098f\u0995\u099f\u09be \u0995\u09b0\u09bf\u09a8\u09bf \u0995\u09b0\u09bf\u09a8\u09bf \u09ae\u09a8\u09c7 \u09b9\u099a\u09cd\u099b\u09c7   \u0995\u09bf \u0995\u09b0\u09c7\u09a8\u09a8\u09bf Bruce ?     \u09a8\u09be ! \u0993\u099f\u09be \u0995\u09b0\u09c7\u099b\u09bf , \u0986\u09b0\u09c7\u0995\u099f\u09be \u0995\u09bf \u09af\u09c7\u09a8 \u09aa\u09c7\u099f\u09c7 \u0986\u09b8\u099b\u09c7 \u09ae\u09c1\u0996\u09c7 \u0986\u09b8\u099b\u09c7\u09a8\u09be    \u09b9\u09be\u0997\u09c1 ? ", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The meme is not hateful, it is just a funny joke.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/CM (257).jpg", "text": "\u09af\u0996\u09a8 \u0986\u09ae\u09bf \u09ac\u09bf\u09df\u09c7\u09b0 \u0985\u09a8\u09c1\u09b7\u09cd\u09a0\u09be\u09a8\u09c7 \u09a6\u09c1\u0987\u099f\u09be \u09b0\u09cb\u09b8\u09cd\u099f \u099a\u09be\u0987    \u09b8\u09ac\u09be\u0987     \u098f\u0987 \u09a4\u09cb\u09b0 \u0995\u09df\u09a1\u09be \u09b2\u09be\u0997\u09c7 ?  ", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The meme is not hateful, it is just a picture of a woman talking to another woman. The meme is not hateful, it is just a picture of a woman talking to another woman.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/bangla-memes (36).jpg", "text": "\u09ad\u09cb\u099f\u09be\u09b0\u0983 \u098f\u09a4 \u09a6\u09c1\u09b0\u09cd\u09a8\u09c0\u09a4\u09bf\u09b0 \u09aa\u09b0\u09c7\u0993 \u0986\u09aa\u09a8\u09be\u09b0\u09be \u09ad\u09cb\u099f \u099a\u09be\u0987\u09a4\u09c7 \u0986\u09b8\u09c7\u09a8 \u0995\u09bf\u09ad\u09be\u09ac\u09c7?  \u09b2\u099c\u09cd\u099c\u09be \u09b2\u09be\u0997\u09c7 \u09a8\u09be?     \u09aa\u09cd\u09b0\u09be\u09b0\u09cd\u09a5\u09c0\u0983   \u09b2\u099c\u09cd\u099c\u09be ? \u09b9\u09c7\u0987\u09a1\u09be\u09a4\u09c7\u0993 \u09aa\u09cd\u09b0\u09bf\u099c\u09be\u09b0\u09ad\u09c7\u099f\u09bf\u09ad \u09a6\u09c7\u0993\u09df\u09be \u0986\u099b\u09c7 ", "label": 1}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The meme is not hateful, it is just a funny picture of a man with a caption that is not hateful.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/bamboo-vaiya (65).jpg", "text": "First two seconds of studying    Then after another 2 seconds    Again after another 3 seconds    And after total 10 seconds", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: A man is shown reading a book with a caption that says "First two seconds of studying." The caption is a meme that is not hateful.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/TR (203).jpg", "text": "\u099d\u09bf\u09b2\u099f\u09c1\u09b2\u09bf     \u099d\u09bf\u09b2\u099f\u09c1\u09a8\u09bf ", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The meme is a picture of a man in an orange jacket, with the words "hateful" and "not-hateful" written above it. The meme is a comparison of two different types of content, one of which is considered hateful and the other not.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/KAM (203).png", "text": "\u0993\u0987\u09a6\u09bf\u09a8 \u0996\u09cb\u09b2\u09be\u09b0 \u09aa\u09b0 \u09a5\u09c7\u0995\u09c7 \u0986\u09ae\u09be\u09b0 \u09ae\u09be\u09a5\u09be \u099a\u09c1\u09b2\u0995\u09be\u0987\u099b\u09c7! \u0995\u09c7\u09a8 \u0995\u09bf \u09b9\u0987\u09b8\u09c7? \u0986\u09b0\u09c7 \u09ac\u09c7\u099f\u09be...\u09a4\u09cb\u09b0 \u09ae\u09be\u09a5\u09be \u09a5\u09c7\u0995\u09c7 \u09b8\u09ac \u0989\u0995\u09c1\u09a8 \u0986\u09ae\u09be\u09b0 \u09ae\u09be\u09a5\u09be\u09df \u099a\u09b2\u09c7 \u0986\u09b8\u099b\u09c7! *\u0995\u09c1\u09a4\u09cd\u09a4\u09be!", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The meme is not hateful, it is just a funny picture of a group of men with different hairstyles and a caption that says 'haircut'.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/Bangla Thug Life (251).jpg", "text": "\u09aa\u09be\u09b6\u09c7\u09b0 \u09ac\u09be\u09b8\u09be\u09b0 \u09b8\u09be\u09a6\u09bf\u09df\u09be\u09b0 \u09b0\u09c7\u099c\u09be\u09b2\u09cd\u099f \u0985\u09a8\u09c7\u0995 \u09ad\u09be\u09b2\u09cb \u09b9\u0987\u099b\u09c7 \u09a4\u09be\u0987 \u0993\u09b0 \u09aa\u09be \u09a7\u09c1\u09df\u09c7 \u09aa\u09be\u09a8\u09bf \u0996\u09c7\u09a4\u09c7 \u0986\u09b8\u09be \u0986\u09ae\u09bf ", "label": 1}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The image is a meme that is not hateful, it is a picture of two people laying down in a pool with a caption that is not hateful.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/Memeholics (151).jpg", "text": "\u09b9\u09cd\u09af\u09be\u0981 \u09ad\u09be\u0987 , \u0986\u099c\u0995\u09be\u09b2 \u09ae\u09c7\u09df\u09c7\u09b0\u09be \u0985\u09b8\u09ad\u09cd\u09af , \u09ac\u09c7\u09b9\u09be\u09df\u09be , \u09ac\u09c7\u09aa\u09b0\u09cd\u09a6\u09be      \u0986\u09b0 \u09ac\u09c7\u09aa\u09b0\u09cd\u09a6\u09be \u09a8\u09be\u09b0\u09c0\u09a6\u09c7\u09b0 \u09a6\u09bf\u0995\u09c7 \u09a4\u09be\u0995\u09be\u09a8\u09cb \u09aa\u09be\u09aa , \u09a4\u09be\u0987 \u098f\u0996\u09a8\u09bf \u0986\u09aa\u09a8\u09be\u09b0 \u0986\u0987\u09a1\u09bf \u09a1\u09bf\u09b2\u09bf\u099f \u0995\u09b0\u09c7 \u09a8\u09bf\u099c\u09c7\u0995\u09c7 \u098f\u0987 \u09aa\u09be\u09aa \u09a5\u09c7\u0995\u09c7 \u09b0\u0995\u09cd\u09b7\u09be \u0995\u09b0\u09c1\u09a8  ", "label": 1}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: A man is holding a whiteboard with a message written in a foreign language. The message is not hateful, but it is not hateful either.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/Halal Memes (139).jpg", "text": "\u09b2\u0995\u09a1\u09be\u0989\u09a8 \u09b6\u09c7\u09b7\u09c7 \u0995\u09cb\u099a\u09bf\u0982 - \u098f/\u09b8\u09cd\u0995\u09c1\u09b2\u09c7 / \u0995\u09b2\u09c7\u099c\u09c7      \u099f\u09bf\u099a\u09be\u09b0     \u099b\u09be\u09a4\u09cd\u09b0     ", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The meme is in a foreign language, and it is not hateful.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/chintashil (394).jpg", "text": "Me after going to the University and losing all the friends from high school and college  \u099b\u09bf\u09b2\u09cb \u09a4\u09cb \u0985\u09a8\u09c7\u0995\u09c7\u0987, \u09aa\u09a5\u09c7 \u0995\u09df\u099c\u09a8\u09b0\u09c7 \u09b9\u09be\u09b0\u09be\u0987\u09b2\u09be\u09ae ", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The meme is a picture of two men talking, one of whom is wearing a school uniform. The caption reads "Me after going to the university and losing all the friends from high school."
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/KAM (95).jpg", "text": "\u0995\u09bf\u099b\u09c1 \u09ae\u09be\u09a8\u09c1\u09b7 \u0995\u09c7\u09a8 \u099d\u0997\u09dc\u09be \u0995\u09b0\u09be\u09b0 \u09aa\u09b0 \u09b0\u09bf\u09b2\u09c7\u09b6\u09a8\u09b6\u09bf\u09aa \u09b8\u09cd\u099f\u09cd\u09af\u09be\u099f\u09be\u09b8 Single \u09a6\u09bf\u09df\u09c7 \u09b0\u09be\u0996\u09c7? \u0995\u0987 \u0986\u09ae\u09bf \u09a4\u09cb \u09ac\u09be\u09ac\u09be-\u09ae\u09be\u09b0 \u09b8\u09be\u09a5\u09c7, \u099d\u0997\u09dc\u09be \u0995\u09b0\u09be\u09b0 \u09aa\u09b0 \u098f\u09a4\u09bf\u09ae \u09b2\u09bf\u0996\u09c7 \u09b0\u09be\u0996\u09bf \u09a8\u09be!", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The meme is not hateful, it is just a funny joke.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/bamboo-vaiya (366).jpg", "text": "\u09a4\u09c7\u09ae\u09a8 \u0995\u09bf\u099b\u09c1 \u09a8\u09be just my mom making me talk to my relatives over the phone ", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: A man is on the phone with a woman, and the caption reads "just my mom making me talk to my relatives over the phone."
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/netflix (70).jpg", "text": "\u09b8\u09c1\u09af\u09cb\u0997 \u09aa\u09c7\u09df\u09c7 \u0995\u09cd\u09b0\u09be\u09b6 \u0986\u09b0 \u09a4\u09be\u09b0 \u09ac\u09ab\u09c7\u09b0 \u09ac\u09cd\u09b0\u09c7\u0995 \u0986\u09aa \u0995\u09b0\u09bf\u09df\u09c7 \u09a6\u09c7\u0993\u09df\u09be\u09b0 \u09aa\u09b0 :     \u09ac\u09bf\u09b6\u09cd\u09ac \u09ac\u09be\u099f\u09aa\u09be\u09b0  ", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The book is a movie poster with a caption that says "Hateful" in Bengali.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/KAM (157).jpg", "text": "\u09b8\u09cd\u09af\u09be\u09b0 \u0990 \u09b2\u09cb\u0995\u09c7\u09b0 \u09b6\u09b0\u09c0\u09b0\u09c7 \u09e8\u099f\u09be \u09ac\u09b2\u09c7\u099f \u09aa\u09be\u0993\u09df\u09be \u0997\u09c7\u099b\u09c7\u0964 \u098f\u099f\u09be\u09b0 \u09ae\u09be\u09a8\u09c7 \u09ac\u09c1\u099d\u099b\u09cb \u09a6\u09df\u09be? \u098f\u09b0 \u09ae\u09be\u09a8\u09c7 \u09b9\u09b2 \u0990 \u09b2\u09cb\u0995\u0995\u09c7 \u0997\u09c1\u09b2\u09bf \u0995\u09b0\u09c7 \u09ae\u09be\u09b0\u09be \u09b9\u0987\u099b\u09c7!", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The image is a meme that is not hateful, it is just a funny picture of a man with a funny expression. The meme is not hateful, it is just a joke.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/ovodro_img (715).jpg", "text": "\u09af\u0996\u09a8   \u09aa\u09bf\u09b0\u09bf\u09df\u09a1\u09b8 \u099a\u09b2\u09be\u0995\u09be\u09b2\u09bf\u09a8\u0993 BF SEX \u0995\u09b0\u09a4\u09c7 \u099a\u09be\u09df     \u09a4\u0996\u09a8 GF :    blowjob blowjob  ", "label": 1}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The meme is not hateful, it is just a funny picture of two women dancing.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/bamboo-vaiya (73).jpg", "text": "Hollywood \u0995\u09bf ?   \u09b8\u09cd\u09af\u09be\u09b0, \u09ac\u09bf\u09b0\u09bf \u0986\u099b\u09c7 Hollywood \u09a8\u09be\u09ae\u09c7 ", "label": 1}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The image is a meme that is not hateful, it is a political ad for a show called 'Hollywood'.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/TR (584).jpg", "text": "\u09ab\u09b0\u09bf\u09a6\u09aa\u09c1\u09b0 \u09b8\u09b0\u0995\u09be\u09b0\u09bf \u09ac\u09be\u09b2\u09bf\u0995\u09be \u0989\u099a\u09cd\u099a \u09ac\u09bf\u09a6\u09cd\u09af\u09be\u09b2\u09df   \u09b8\u09cd\u09a5\u09be\u09aa\u09bf\u09a4\u0983 \u09e7\u09ef\u09e7\u09e6 \u0996\u09cd\u09b0\u09bf\u0983    \u09ae\u09be\u09ae\u09be \u09a6\u09c7\u0996 \u09ae\u09c7\u09df\u09be\u09a1\u09be \u0995\u09bf \u099c\u09cb\u09b6 !!    \u09a8\u099c\u09b0 \u09a6\u09bf\u09b8 \u09a8\u09be \u09b6\u09be\u09b2\u09be \u0990\u09a1\u09be \u09a4\u09cb\u0997\u09cb \u09ad\u09be\u09ac\u09c0    \u09a4\u09be\u0987\u09b2\u09c7 \u09aa\u09be\u09b6\u09c7\u09b0\u09a1\u09be \u0986\u09ae\u09be\u09b0    \u09b9 \u09a4\u09cb\u09b0\u09be\u0987 \u09b8\u09ac \u09a8\u09c7 \u0986\u09ae\u09be\u09b0 \u09a8\u09c7\u0993\u09df\u09be \u09b2\u09be\u0997\u09ac\u09c7 \u09a8\u09be  ", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The meme is not hateful, it is just a picture of two men with a sign in the background.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/chintashil (370).jpg", "text": "me trying to be friend with them     cool people in my friend circle doing cool stuff ", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The meme is not hateful, it is just a funny picture of a group of women in saris.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/ovodro_img (201).jpg", "text": "\u09ac\u09b2 \u09aa\u09be\u0997\u09b2\u09c1    \u09aa\u09be\u09a6\u09b2\u09c1    \u0989\u099a\u09cd\u099a\u09be\u09b0\u09a8 \u09a4\u09cb \u09ae\u09b9\u09be\u09a8\u09be\u09df\u0995 \u09a6\u09c7\u09ac\u09c7\u09b0 \u09ae\u09a4 ", "label": 1}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The meme is a comedic one, with a caption that says "Hateful if it intends to denigrate, vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status." The meme is not hateful, but it is a comedic one that is meant to be funny.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/TR (34).jpg", "text": "\u09b8\u09bf \u09aa\u09cd\u09b0\u09cb\u0997\u09cd\u09b0\u09be\u09ae \u098f\u09b0 ' \u09b9\u09cd\u09af\u09be\u09b2\u09cb \u0993\u09df\u09be\u09b0\u09cd\u09b2\u09cd\u09a1 ' \u0995\u09cb\u09a1 \u09b6\u09c7\u0996\u09be\u09b0 \u09aa\u09b0 \u09af\u0996\u09a8 \u09a4\u09c1\u09ae\u09bf \u09a8\u09bf\u099c\u09c7\u0995\u09c7 \u09b9\u09cd\u09af\u09be\u0995\u09be\u09b0 \u09ad\u09be\u09ac\u09a4\u09c7 \u09b6\u09c1\u09b0\u09c1 \u0995\u09b0\u09cb !!   ", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The image is a meme that is not hateful, it is a political statement that is not intended to harm or mock any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/ovodro_img (261).jpg", "text": "\u09af\u0996\u09a8 Flop Movie Hit \u0995\u09b0\u09be\u09a4\u09c7 \u09b9\u09df  \u09a4\u0996\u09a8 Stardom \u09af\u09c7\u09ad\u09be\u09ac\u09c7 \u0995\u09be\u099c \u0995\u09b0\u09c7     Thugs of Hindustan ", "label": 1}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The meme is a cartoon of three people, two of which are men, and one of which is a woman. The caption reads "Flop Movie Hit Thugs of Hindostan."
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/CM (523).jpg", "text": "\u0986\u09ae\u09cd\u09ae\u09c1       \u09b0\u09be\u09b8\u09cd\u09a4\u09be\u09df \u09b9\u09a0\u09be\u09a4 \u0986\u09ae\u09cd\u09ae\u09c1\u09b0 \u09b8\u09be\u09a5\u09c7 \u09a6\u09c7\u0996\u09be \u09b9\u0993\u09df\u09be \u0986\u09a8\u09cd\u099f\u09bf       \u0986\u09ae\u09bf ", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The image is a meme that is not hateful, it is a funny picture of a dog sitting at a table with a woman.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/bamboo-vaiya (492).jpg", "text": "Application \u098f The Headmaster \u098f\u09b0 \u09aa\u09b0 \u0995\u09ae\u09be \u09b9\u09ac\u09c7 \u0995\u09bf \u09a8\u09be \u09a4\u09be \u09a8\u09bf\u09df\u09c7 \u0986\u09b2\u09cb\u099a\u09a8 \u09b8\u09ad\u09be ", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The meme is not hateful, it is just a funny video of three boys sitting on a couch.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/Bangla Thug Life (289).jpg", "text": "\u098f\u0987 \u09a4\u09cb\u09ae\u09be\u09b0 \u09b2\u09be\u099a\u09cd\u099b\u09bf \u09a8\u09be\u0987 \u0995\u09c7\u09a8\u09cb?  \u0986\u09b8\u09b2\u09c7 \u09ab\u09be\u09b9\u09bf\u09ae\u09c7\u09b0 \u098f\u0996\u09a8 \u0986\u09b0 \u09b2\u09be\u099a\u09cd\u099b\u09bf \u09ac\u09c7\u09b0 \u09b9\u09df\u09a8\u09be  \u098a\u09b0\u09cd\u09a7 \u0997\u0997\u09a8\u09c7 \u09a4\u09c1\u09b2\u09bf\u09df\u09be \u09a0\u09cd\u09af\u09be\u0982 \u09b9\u09c1\u09a6\u09be\u0987 \u0995\u09b0\u09bf\u09b2\u09be\u09ae \u09ac\u09cd\u09af\u09be\u0982 \u09ac\u09cd\u09af\u09be\u0982 ", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The image is a meme that is not hateful, it is not intended to denigrate, vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/tangaila (327).jpg", "text": "\u09a4\u09c1\u0987 \u09ac\u09cd\u09b2\u09be\u09b6 \u0995\u09b0\u09b8 \u09a8\u09be, \u09a4\u09cb\u09b0 \u09ae\u09c1\u0996\u09c7 \u0997\u09a8\u09cd\u09a7     \u0995\u09bf\u09b8 \u09a1\u09c7 \u0995\u09bf\u09b8 \u09a6\u09bf\u09ac\u09bf \u09a8\u09be \u0995\u09aa\u09bf\u09b2\u09be ? ", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The image is a meme that is not hateful, it is not intended to denigrate, vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/bamboo-vaiya (547).jpg", "text": "She: Ekta kotha boli ?   Me: Bolo  She: \"Ekta kotha\"  Hahaha    *Me   *She", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The meme is a comparison between two different types of memes, one hateful and one not hateful. The meme is a comparison between two different types of memes, one hateful and one not hateful.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/chintashil (361).jpg", "text": "*Classmate offering me to have a chewing gum on his birthday treat     *Me who chew this gum every day while getting out of the \u099f\u0982 ", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The meme is not hateful, it is just a funny picture of two men with a bottle of water in the background.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/tangaila (319).jpg", "text": "\u0987\u09a8\u09cd\u09a1\u09bf\u09df\u09be\u09a8 \u0995\u09cb\u09ac\u09b0\u09be    \u0986\u09ab\u09cd\u09b0\u09bf\u0995\u09be\u09a8 \u0995\u09cb\u09ac\u09b0\u09be   \u099f\u09be\u0982\u0997\u09be\u0987\u09b2\u09c7\u09b0 \u0995\u09cb\u09ac\u09b0\u09be  ", "label": 1}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The image is a meme that is not hateful, it is just a funny picture of a snake spraying water.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/chintashil (716).jpg", "text": "Hijab for din    Ass for Nur Uddin", "label": 1}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The meme is not hateful, it is just a funny picture of three women sitting in an airport.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/chintashil (377).jpg", "text": "When someone asks you to pick between \u099c\u09bf\u09b2\u09be\u09aa\u09bf \u09a6\u09bf\u09df\u09c7 \u09ae\u09c1\u09dc\u09bf and \u099a\u09c0\u09b0\u09be \u09a6\u09bf\u09df\u09c7 \u09a6\u0987 for iftaar    If I have to choose between one evil over another , I prefer not to choose at all.   ", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The meme is a quote from the movie The Witcher, and it is not hateful.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/TR (204).jpg", "text": "\u09af\u0996\u09a8  \u0986\u09ae\u09be\u09b0 \u09ac\u09a8\u09cd\u09a7\u09c1 \u0986\u09ae\u09be\u0995\u09c7 \u09ac\u09b2\u09c7\u0983    \u099a\u09b2 \u0986\u099c\u0995\u09c7 \u0986\u09ae\u09bf \u0996\u09be\u0993\u09df\u09be\u09ae\u09c1     \u0986\u09ae\u09bf ", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The image is a meme that is not hateful, it is not intended to denigrate, vilify, harm, mock, or abuse any entity based on their gender, race, ideology, belief, social, political, geographical, or organizational status. It is a meme that is not hateful.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/TR (376).jpg", "text": "Campus er junior     me     Batchmate GF ", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The image is a meme that is either hateful or not-hateful.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/bamboo-vaiya (476).jpg", "text": "Remember this girl ?    This is her now: ", "label": 1}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The meme is a picture of a woman with the caption 'remember this girl? This is her now.' The meme is not hateful, but it is not hateful either.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/tangaila (240).jpg", "text": "\u09b9\u09cb\u09ae\u0993\u09df\u09be\u09b0\u09cd\u0995 \u09a8\u09be \u09a8\u09bf\u09df\u09c7 \u09af\u0996\u09a8 \u09b8\u09cd\u0995\u09c1\u09b2\u09c7 \u09af\u09be\u0987, \u0986\u09b0 \u09b8\u09cd\u09af\u09be\u09b0 \u09b8\u09ac\u09be\u09b0 \u09b8\u09be\u09ae\u09a8\u09c7 \u09ae\u09be\u09a0\u09c7 \u09a6\u09be\u0981\u09dc \u0995\u09b0\u09bf\u09df\u09c7 \u09b0\u09be\u0996\u09c7 !", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The image is a meme that is not hateful, it is a group of men posing for a picture.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/bangla-troll (50).jpg", "text": "\u09ad\u09be\u0987 \u09a5\u09be\u09ae\u09c7\u09a8 DSLR \u09a5\u09be\u0995\u09b2\u09c7\u0987 \u09ab\u099f\u09cb\u0997\u09cd\u09b0\u09be\u09ab\u09be\u09b0 \u09b9\u0993\u09df\u09be \u09af\u09be\u09df\u09a8\u09be  \u09ac\u09dc\u099c\u09cb\u09b0 \u0995\u09cd\u09af\u09be\u09ae\u09c7\u09b0\u09be\u09ae\u09cd\u09af\u09be\u09a8 \u09b9\u0993\u09df\u09be \u09af\u09be\u09df ! ", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: A lemur is shown in a meme with the caption "Dslj lamboo bach" which translates to "Dslj is a lemur." The lemur is making a gesture with its hand, and the meme is not hateful.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/nurani-memes (47).jpg", "text": "Types of Headache   Migraine   Hypertension Stress   A+ \u09aa\u09be\u0987 \u09a8\u09be\u0987 ", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The meme is not hateful, it is just a funny way to describe the different types of headaches. The meme is not hateful, it is just a funny way to describe the different types of headaches.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/Halal Memes (34).jpg", "text": "\u0995\u09be\u09a0\u09c1\u09b0\u09c7\u09b0 \u0995\u09c1\u09a0\u09be\u09b0 \u09a8\u09a6\u09c0\u09a4\u09c7 \u09aa\u09b0\u09be exists:     \u099c\u09b2\u09aa\u09b0\u09c0\u0983      \u09a4\u09b0 \u0995\u09bf \u0995\u09bf\u099b\u09c1 \u09b2\u09be\u0997\u09ac\u09cb ? ", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The meme is a picture of two men with a caption that is written in a foreign language. The caption is asking if the two men are related. The meme is not hateful, but it is not hateful either.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/bangla-memes (64).jpg", "text": "Sadiq: What's the name of your favourite  educational website ?     Student : OnnorokomPathshala.com      Sadiq", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The meme is not hateful, it is just a funny picture of a man talking to a group of people.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/bamboo-vaiya (531).jpg", "text": "\u0986\u09ae\u09be\u09b0 \u099b\u09c7\u09b2\u09c7\u0983  \u098f\u0987 \u0985\u0982\u0995 \u099f\u09be \u09ae\u09bf\u09b2\u09bf\u09df\u09c7 \u09a6\u09be\u0993, \u0986\u09ae\u09bf \u09aa\u09be\u09b0\u099b\u09bf\u09a8\u09be   \u0986\u09ae\u09bf\u0983   \u09a4\u09c1\u0987 \u098f\u0995\u099f\u09be \u09ac\u09cb\u09a6\u09be\u0987, \u0986\u09ae\u09bf \u09a8\u09bf\u099c\u09c7\u0993 \u098f\u0995\u099f\u09be \u09ac\u09cb\u09a6\u09be\u0987 ", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The meme is a picture of two men, one of whom is talking to the other. The caption is in a foreign language, but the words are translated into English. The meme is not hateful, but it is not not-hateful either.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/chosha (15).jpg", "text": "\u099c\u09be\u09a8\u09cb \u09ac\u09be\u09ac\u09c1, \u09a4\u09c1\u09ae\u09bf \u09b8\u09c7\u0987 \u09aa\u09cd\u09b0\u09a5\u09ae \u09aa\u09c1\u09b0\u09c1\u09b7 \u09af\u09be\u09b0 \u09b8\u09be\u09a5\u09c7 \u09b8\u09c7\u0995\u09cd\u09b8 \u0995\u09b0\u09b2\u09be\u09ae   \u0995\u09c7\u09a8, \u0986\u0997\u09c7 \u0995\u09bf \u0995\u09c1\u09a4\u09cd\u09a4\u09be\u09b0 \u09b8\u09be\u09a5\u09c7 \u09b8\u09c7\u0995\u09cd\u09b8 \u0995\u09b0\u09a4\u09be ? ", "label": 1}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The image is a meme that is not hateful, it is a romantic scene between two people. The meme is not hateful, it is a romantic scene between two people.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/tangaila (78).jpg", "text": "*\u09b9\u09be\u09b2\u0995\u09be \u09ac\u099c\u09cd\u09b0\u09aa\u09be\u09a4 \u09ac\u09bf\u09a6\u09cd\u09af\u09ae\u09be\u09a8*  \u0986\u09aa\u09a8\u09be\u09b0  DSLR \u0993\u09df\u09be\u09b2\u09be \u09ac\u09a8\u09cd\u09a7\u09c1\u0983 ", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: A poster with a collection of lightning strikes, with the caption "Dslr" in the middle.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/chintashil (443).jpg", "text": "Divorcing \u0985\u09ad\u09be\u0997\u09c0  *\u09b0\u09b8\u09bf\u0995 \u09ac\u09be\u0998    \u0985\u09ad\u09be\u0997\u09c0's funeral   ", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The meme is a comparison between two different men, one of whom is a celebrity and the other is not. The meme is not hateful, but it is not not-hateful either.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/CM (208).jpg", "text": " \u09ac\u09cd\u09af\u09be\u09ac\u09b9\u09be\u09b0\u09bf\u0995 \u0996\u09be\u09a4\u09be \u09a8\u09bf\u09df\u09c7 \u09af\u0996\u09a8 \u09b6\u09bf\u0995\u09cd\u09b7\u0995\u09a6\u09c7\u09b0 \u0995\u09be\u099b\u09c7 \u09af\u09be\u0987*     \u0986\u09ae\u09bf*     \u09b8\u09be\u0987\u09a8 \u099f\u09be \u09a6\u09bf\u09df\u09c7 \u09a6\u09bf\u09a8    \u09b6\u09bf\u0995\u09cd\u09b7\u0995*      \u09e9\u09e6\u09e6 \u099f\u09be\u0995\u09be \u09a6\u09bf\u09df\u09c7 \u09a5\u09be\u0995\u09b2\u09c7 \u098f\u09ae\u09a8\u09bf \u098f\u09ae\u09a8\u09bf \u09b9\u09df\u09c7 \u09af\u09be\u09ac\u09c7  ", "label": 1}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The meme is a picture of a man and a woman, with the woman saying something to the man. The meme is not hateful, but it is not hateful either.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/chintashil (338).jpg", "text": "When your best friend writes someone else's name in the  \u09aa\u09cd\u09b0\u09be\u09aa\u0995  section of the letter ", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The meme is a collage of pictures with the caption 'when your best friend writes someone else's name in the 's' section of the letter.'
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/nurani-memes (212).jpg", "text": "When you ask someone  \" \u09ad\u09be\u0987 \u0995\u09a4 \u09a8\u09bf\u09b2\u09cb ?\" But they don't reply and ignore", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The meme is a picture of a man sitting on a couch with a beer in his hand. The caption reads "when you ask someone something in Hindi but they don't reply and ignore."
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/bangla-memes (15).jpg", "text": "\u0986\u099c\u0995\u09c7 \u09b0\u09be\u09a4\u09c7 \u09b8\u09ac\u09be\u0987 \u09af\u09be\u0995\u09c7 \u09b2\u09be\u0997\u09be\u099a\u09cd\u099b\u09c7\u0983     -\u0995\u09c7", "label": 1}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The image is a meme that is not hateful, it is a picture of a man in a green shirt with a quote from a Bangladeshi cricketer.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/KAM (98).png", "text": "\u0995\u09b2\u09cb\u09ae\u09cd\u09ac\u09bf\u09df\u09be  \u0995\u09b2\u09ae \u09ac\u09bf\u09df\u09be", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The image is a collage of a soccer team, a pen, and a few words in a foreign language. The image is not hateful, but it is not hateful.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/KAM (114).png", "text": "\u09ac\u09be\u0982\u09b2\u09be\u09a6\u09c7\u09b6\u09c7\u09b0 \u09ac\u09bf\u09b0\u09c1\u09a6\u09cd\u09a7\u09c7 \u09b2\u09dc\u09a4\u09c7 \u09aa\u09cd\u09b0\u09b8\u09cd\u09a4\u09c1\u09a4 \u09ae\u09bf\u09df\u09be\u09a8\u09ae\u09be\u09b0!  \u09a8\u09bf\u099c\u09c7\u09b0\u09be \u09b2\u09dc\u09be\u0987 \u0995\u0987\u09b0\u09be \u0995\u09c2\u09b2 \u09aa\u09be\u0987\u09a8\u09be \u0986\u0987\u099b\u09c7 \u09b2\u09dc\u09be\u0987 \u0995\u09b0\u09ac\u09be\u09b0", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The meme is not hateful, it is just a funny picture of two soldiers with a caption that says "I'm not hateful, I'm just a soldier."
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/TR (407).jpg", "text": "Nibba :- \u09ac\u09bf\u09df\u09c7\u09b0 \u09aa\u09b0 \u0986\u09ae\u09bf \u09a4\u09c7\u0981\u09a4\u09c1\u09b2\u09a4\u09b2\u09be , \u09ac\u09be\u0997\u09be\u099f , \u09ae\u09df\u09b0\u09be\u09aa\u099f\u09cd\u099f\u09bf\u09b8\u09b9  \u09b8\u09ac \u09a6\u09cb\u0995\u09be\u09a8\u09c7\u09b0 \u09ae\u09bf\u09b7\u09cd\u099f\u09bf \u0996\u09be\u0993\u09df\u09be \u099b\u09c7\u09dc\u09c7 \u09a6\u09bf\u09ac\u09cb      Nibbi :-  \u0995\u09c7\u09a8\u09cb \u09ac\u09be\u09ac\u09c1 ??     Nibba :-   \u0995\u09be\u09b0\u09a3 \u09a4\u09c1\u09ae\u09bf \u0986\u099b\u09c7 \u09a4\u09cb    Govt: girls a Class 6 a pora Nibbi :-    ", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The image is a meme that is not hateful, but it is a cat with a funny expression. The cat is looking at the screen with a funny expression, and the caption is in a foreign language.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/ovodro_img (396).jpg", "text": "\u099c\u09df \u09b9\u09c7 \u09ac\u09be\u0982\u09b2\u09be\u09b0 \u09b8\u09b0\u09b8\u09cd\u09ac\u09a4\u09c0 \u09a6\u09c7\u09ac\u09c0 \u0964\u0964", "label": 1}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The image is a meme that is not hateful, it is a woman playing a musical instrument with a peacock in the background.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/ovodro_img (451).jpg", "text": "\u09ac\u09bf\u09b0\u09be\u099f 2019 world cup  \u098f \u09a4\u09cb\u09b0\u09be \u0986\u09ae\u09be\u09a6\u09c7\u09b0 \u09b9\u09be\u09b0\u09be\u09a4\u09c7 \u09aa\u09be\u09b0\u09ac\u09bf \u09a8\u09be !  \u0995\u09c7\u09a8\u09cb M.C ?   \u0986\u09ae\u09b0\u09be \u099c\u0999\u09cd\u0997\u09bf \u09b8\u09be\u09aa\u09cd\u09b2\u09be\u0987 \u0995\u09b0\u09bf \u09a4\u09be\u0987 \u0986\u09ae\u09be\u09a6\u09c7\u09b0 world cup \u09a5\u09c7\u0995\u09c7 \u09ac\u09be\u09a4\u09bf\u09b2 \u0995\u09b0\u09be \u09b9\u09df\u09c7\u099b\u09c7 ", "label": 1}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The image is a meme that is not hateful, it is just a funny picture of two men with a caption that is not meant to be offensive.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/KAM (133).png", "text": "\u09a6\u09cb\u09b8\u09cd\u09a4, \u09a4\u09ae\u09be\u09b0\u09c7 \u09ab\u09cb\u09a8 \u09a6\u09bf\u09df\u09be \u09ac\u09b2\u099b\u09bf\u09b2\u09be\u09ae \u0986\u09ae\u09be\u09b0 \u09ac\u09be\u09b8\u09be\u09b0 \u09a8\u09bf\u099a\u09c7 \u0986\u09b8\u09a4\u09c7 \u09aa\u09bf\u099b\u09a8 \u09a6\u09bf\u09df\u09be \u0997\u09be\u09b0\u09cd\u09b2\u09ab\u09cd\u09b0\u09c7\u09a8\u09cd\u09a1 \u09b6\u09c1\u0987\u09a8\u09be \u09ab\u09c7\u09b2\u099b\u09c7, \u09b8\u09be\u09a5\u09cd\u09b0 \u09b8\u09be\u09a5\u09c7\u0987 \u09ac\u09cd\u09b0\u09c7\u0995\u0986\u09aa! \u0985\u09a8\u09cd\u09af \u09ae\u09c7\u09df\u09c7\u09b0\u09c7 \u09ac\u09be\u09b8\u09be\u09df \u09a1\u09be\u0995\u09b2\u09c7\u09a4\u09cb \u09ac\u09cd\u09b0\u09c7\u0995\u0986\u09aa \u09b9\u0987\u09ac\u0987 BTW,\u0995\u09c7 \u098f\u0987 \u09a4\u09ae\u09be? \u0985\u09a8\u09c7\u0995 \u09b8\u09c1\u09a8\u09cd\u09a6\u09b0 \u09a8\u09be\u0995\u09bf? \u0986\u09b0\u09c7 \u0995\u09cb\u09a8 \u09ae\u09c7\u09df\u09c7 \u09a8\u09be... \u09a8\u09a4\u09c1\u09a8 \u099f\u09cd\u09af\u09be\u0995\u09cd\u09b8\u09bf \u0995\u09cd\u09af\u09be\u09ac \u0997\u09c1\u09b2\u09be!", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The image is a meme that is not hateful, it is just a funny picture of a man taking a picture with his phone.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/bamboo-vaiya (462).jpg", "text": "\u09b8\u09c1\u09b0\u09cd\u09af \u09ae\u09be\u09ae\u09be \u099c\u09be\u0997\u09be\u09b0 \u0986\u0997\u09c7 \u0989\u09a0\u09ac\u09cb \u0986\u09ae\u09bf \u099c\u09c7\u0997\u09c7 ", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: A cat is sitting on a couch with a caption that says "hateful" in the background. The cat is not hateful, but the caption is.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/Memeholics (274).jpg", "text": "*Bangladeshi female news presenters    *Bangladeshi actresses ", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The meme is not hateful, it is just a funny picture of a woman with a paper in her mouth.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/ovodro_img (341).jpg", "text": "\u09af\u09a4\u099f\u09be \u09a6\u09c2\u09b0\u09cd\u0997\u09be \u09aa\u09c2\u099c\u09cb\u09b0 \u09b8\u09ae\u09df\u09c7 \u0985\u09b7\u09cd\u099f\u09ae\u09bf\u09b0 \u09ac\u09bf\u0995\u09be\u09b2\u09c7 \u0996\u09bf\u099a\u09c1\u09dc\u09bf \u09aa\u09b0\u09bf\u09ac\u09c7\u09b6\u09a8 \u0995\u09b0\u09be\u09b0 \u0986\u0997\u09c7 \u098f\u0995 \u09ac\u09be\u09b2\u09a4\u09bf \u0996\u09bf\u099a\u09c1\u09dc\u09bf \u0986\u0997\u09c7\u0987 \u09a8\u09bf\u09b0\u09be\u09aa\u09a6\u09c7 \u09a4\u09c1\u09b2\u09c7 \u09b0\u09c7\u0996\u09c7 \u09a6\u09bf\u0987 !!   \u0986\u09ae\u09be\u0995\u09c7 \u0995\u09a4\u099f\u09be \u09a8\u09bf\u09b0\u09be\u09aa\u09a6\u09c7 \u09b0\u09c7\u0996\u09c7\u099b\u09cb \u09ac\u09c1\u09ae\u09cd\u09ac\u09be ??? ", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The image is a meme that is not hateful, it is a romantic scene between two people. The meme is not hateful, it is a romantic scene between two people.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/bamboo-vaiya (455).jpg", "text": "\u09af\u0996\u09a8 \u09a4\u09c1\u09c1\u09ae\u09bf \u09b0\u09cb\u09af\u09be \u09b0\u09c7\u0996\u09c7 \u0997\u09be\u09b2\u09bf \u09a6\u09bf\u09a4\u09c7 \u09aa\u09be\u09b0\u09ac\u09c7\u09a8\u09be \u09a6\u09c7\u0996\u09c7 \u0995\u09be\u09b0\u09cb \u09aa\u09cb\u09b8\u09cd\u099f\u09c7 \u09a4\u09cb\u09ae\u09be\u09b0 \u09b9\u09bf\u09a8\u09cd\u09a6\u09c1 \u09ac\u09a8\u09cd\u09a7\u09c1\u0995\u09c7 \u09ae\u09c7\u09a8\u09b6\u09a8 \u09a6\u09bf\u09df\u09c7 \u0997\u09be\u09b2\u09bf \u09a6\u09c7\u0993\u09df\u09be\u0993 \u0964  \u09a1\u09be\u09a8 \u0995\u09be\u09a7\u09c7\u09b0 \u09ab\u09c7\u09b0\u09c7\u09b8\u09cd\u09a4\u09be\u0983     \u09ac\u09be\u09ae \u0995\u09be\u09a7\u09c7\u09b0 \u09ab\u09c7\u09b0\u09c7\u09b8\u09cd\u09a4\u09be\u0983 ", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The meme is in a foreign language, and it is not hateful.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/ovodro_img (15).jpg", "text": "\u0986\u0987 \u09b2\u09cd\u09af\u09be\u09ac \u0987\u0989 \u0964 \u0986\u09ae\u09bf \u09a4\u09cb\u0995\u09c7 \u099b\u09be\u09dc\u09be \u09ac\u09be\u0981\u099a\u09ac \u09a8\u09be     \u0993\u099f\u09be \u09aa\u09c1\u09b0\u09be\u09a8\u09cb  \u09a1\u09be\u09df\u09b2\u09cb\u0997 \u09a8\u09a4\u09c1\u09a8 \u0995\u09bf\u099b\u09c1 \u09ac\u09b2    \u09a4\u09c1\u0987 \u0986\u09ae\u09be\u09b0 \u09b2\u09cd\u09af\u09be\u09ae\u09cd\u09aa \u09b9\u09df\u09c7 \u09af\u09be , \u0986\u09ae\u09bf \u09a4\u09cb\u09b0 \u09ad\u09bf\u09a4\u09b0\u09c7 \u0995\u09bf\u09b0\u09cb\u09b8\u09bf\u09a8 \u09a4\u09c7\u09b2 \u09a6\u09bf\u09df\u09c7 \u09ac\u0982\u09b6\u09c7\u09b0 \u09aa\u09cd\u09b0\u09a6\u09bf\u09aa \u099c\u09be\u09b2\u09a4\u09c7 \u099a\u09be\u0987 ", "label": 1}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The image is a meme that is not hateful, it is a romantic scene between two people.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/chintashil (71).jpg", "text": "\u0985\u0987\u09af\u09c7 \u098f\u0995\u099f\u09be \u09ae\u09be\u0987\u09df\u09be    \u0986\u0987\u09b9\u09be\u09df \u09ac\u09c1\u0987\u09dc\u09be \u09ac\u09c7\u09a1\u09bf \u09a6\u09c7\u09b9\u09bf    \u09af\u0996\u09a8 \u09a7\u09cd\u09b0\u09c1\u09ac \u09a6\u09c2\u09b0 \u09a5\u09c7\u0995\u09c7 \u09ae\u09c7\u09df\u09c7 \u09a6\u09c7\u0996\u09c7     \u09ae\u09c7\u09df\u09c7 \u099f\u09be \u0995\u09be\u099b\u09c7 \u0986\u09b8\u09be\u09b0 \u09aa\u09b0 ", "label": 1}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The image is a meme that is not hateful, it is just a funny picture of a man with a funny caption.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/Bangla Thug Life (390).jpg", "text": "\u09aa\u09cd\u09b0\u09a5\u09ae\u09ac\u09be\u09b0 \u09b0\u09c1\u09ae\u09a1\u09c7\u099f\u09c7 \u09af\u09be\u09ac\u09be\u09b0 \u09aa\u09b0 Nibba to his Nibbi :     \u098f \u09b8\u09c1\u0996\u09c7\u09b0 \u09a8\u09c7\u0987 \u0995\u09cb\u09a8\u09cb \u09b8\u09c0\u09ae\u09be\u09a8\u09be ", "label": 1}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The meme is a picture of a woman playing a piano with the caption 'Nibbi to his Nibbi'. The meme is not hateful, but it is not considered appropriate for all audiences.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/chintashil (687).jpg", "text": "You're not Peter Parker", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: A man is shown in a movie scene with the caption 'you're not peter parker' above it. The caption is a meme that is not hateful, but rather a playful jab at the character's name.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/ovodro_img (1026).jpg", "text": "* \u09b6\u09bf\u09b2 \u0995\u09c7\u099f\u09c7 \u09a6\u09c7\u0993\u09df\u09be\u09b0 \u09aa\u09b0 \u09af\u0996\u09a8 \u09ac\u09df\u09ab\u09cd\u09b0\u09c7\u09a8\u09cd\u09a1 \u09ac\u09cd\u09b0\u09c7\u0995\u0986\u09aa  \u0995\u09b0\u09c7 \u09a8\u09c7\u09df *    15 \u099f\u09be \u09ae\u09c7\u09df\u09c7\u09b0 \u09b6\u09bf\u09b2 \u0995\u09c7\u099f\u09c7 \u09ac\u09b8\u09c7 \u09a5\u09be\u0995\u09be \u09ac\u09df\u09ab\u09cd\u09b0\u09c7\u09a8\u09cd\u09a1      14 \u09ac\u099b\u09b0\u09c7\u09b0 Nibbi \u09af\u09c7 \u09aa\u09cd\u09b0\u09a5\u09ae \u09aa\u09cd\u09b0\u09c7\u09ae \u0995\u09b0\u09c7 \u09b8\u09c7\u0995\u09cd\u09b8 \u0995\u09b0\u09be\u09b0 \u09aa\u09b0 \u09ac\u09df\u09ab\u09cd\u09b0\u09c7\u09a8\u09cd\u09a1\u0995\u09c7 \u09b8\u09cd\u09ac\u09be\u09ae\u09c0 \u09ad\u09c7\u09ac\u09c7\u099b\u09bf\u09b2 ", "label": 1}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The image is a meme that is not hateful, but it is a meme that is not hateful. It is a meme that is not hateful.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/chintashil (316).jpg", "text": "\u0985\u09a8\u09c1\u09aa\u09ae\u09c7\u09b0 \u09ae\u09be\u09ae\u09be \u0997\u09b9\u09a8\u09be \u09af\u09be\u099a\u09be\u0987\u09df\u09c7\u09b0 \u099c\u09a8\u09cd\u09af \u09b8\u09c7\u0995\u09b0\u09be \u0986\u09a8\u09be\u09b0 \u09aa\u09b0    \u09b6\u09ae\u09cd\u09ad\u09c1\u09a8\u09be\u09a5\u0983     Did you summon him here to humiliate me ? ", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The meme is a quote from a movie, and it is not hateful.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/tangaila (114).jpg", "text": "\u09af\u0996\u09a8 \u09a6\u09c7\u0996\u09bf \u0995\u09cd\u09b0\u09be\u09b6 \u09b8\u09bf\u0997\u09be\u09b0\u09c7\u099f \u0996\u09be\u09df...... \u09a4\u0996\u09a8 \u0986\u09ae\u09bf......!", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The image is a meme that is not hateful, it is a funny picture of a man and woman smoking and talking to each other.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/Bangla Thug Life (140).jpg", "text": "No Caption", "label": 1}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The image is a collage of four different pictures, including a watermelon, a woman, and a man. The watermelon is cut in half, and the woman is holding one of the halves. The caption reads "Hateful if it explicitly intends to denigrate, vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status."
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/ovodro_img (492).jpg", "text": "\u09ac\u09c1\u09ae\u09cd\u09ac\u09be\u09a6\u09be \u09b9\u09be\u09a4\u099f\u09be \u09b8\u09b0\u09be\u0993 \u0964   \u09b8\u09ac\u09be\u0987 \u09a6\u09c7\u0996\u099b\u09c7 !    \u0986 \u0986 ... \u0986\u09ae\u09bf \u099f\u09bf\u09aa\u09c7 \u09a7\u09b0\u09bf \u09a8\u09bf ", "label": 1}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The image is a meme that is not hateful, it is a funny picture of two people with a caption that is not intended to harm or mock anyone.
##########
{"img": "/kaggle/input/bhm-dataset/BHM/Memes/bamboo-vaiya (382).jpg", "text": "\u09b8\u09c7\u09b9\u09c7\u09b0\u09c0\u09b0 \u09aa\u09b0\u09c7\u09b0 \u09b9\u09bf\u09b8\u09c1   \u0987\u09ab\u09a4\u09be\u09b0\u09c7\u09b0 \u0986\u0997\u09c7\u09b0 \u09b9\u09bf\u09b8\u09c1 ", "label": 0}
----------
Consider the following definitions.
1. hateful - if it explicitly intends to denigrate,vilify, harm, mock, abuse any entity based on their gender, race, ideology, belief, social, political, geographical and organizational status.
2. not-hateful - if it is not hateful and follows social norms.
Classify the given meme as hateful or not-hateful based on the above definitions. Provide the answer as either 'hateful' or 'not-hateful' only.
Example output for hateful meme : 'hateful'
Example output for not-hateful meme : 'not-hateful'
Assistant: The image is a meme that is not hateful, it is a picture of a river with boats and a caption that says "Bangladesh".
##########
