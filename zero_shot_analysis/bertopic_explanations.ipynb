{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":1246182,"sourceType":"datasetVersion","datasetId":715500},{"sourceId":8620946,"sourceType":"datasetVersion","datasetId":3985455},{"sourceId":8620970,"sourceType":"datasetVersion","datasetId":3983106},{"sourceId":8623389,"sourceType":"datasetVersion","datasetId":5161213},{"sourceId":10269596,"sourceType":"datasetVersion","datasetId":6199400},{"sourceId":10336659,"sourceType":"datasetVersion","datasetId":6400620},{"sourceId":10459631,"sourceType":"datasetVersion","datasetId":6475305},{"sourceId":10475743,"sourceType":"datasetVersion","datasetId":6486616}],"dockerImageVersionId":30823,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"! pip install bertopic","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-15T12:40:01.516628Z","iopub.execute_input":"2025-01-15T12:40:01.517293Z","iopub.status.idle":"2025-01-15T12:40:04.726385Z","shell.execute_reply.started":"2025-01-15T12:40:01.517238Z","shell.execute_reply":"2025-01-15T12:40:04.725342Z"}},"outputs":[{"name":"stderr","text":"/usr/lib/python3.10/pty.py:89: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  pid, fd = os.forkpty()\n","output_type":"stream"},{"name":"stdout","text":"Requirement already satisfied: bertopic in /usr/local/lib/python3.10/dist-packages (0.16.4)\nRequirement already satisfied: hdbscan>=0.8.29 in /usr/local/lib/python3.10/dist-packages (from bertopic) (0.8.40)\nRequirement already satisfied: numpy>=1.20.0 in /usr/local/lib/python3.10/dist-packages (from bertopic) (1.26.4)\nRequirement already satisfied: pandas>=1.1.5 in /usr/local/lib/python3.10/dist-packages (from bertopic) (2.1.4)\nRequirement already satisfied: plotly>=4.7.0 in /usr/local/lib/python3.10/dist-packages (from bertopic) (5.24.1)\nRequirement already satisfied: scikit-learn>=0.22.2.post1 in /usr/local/lib/python3.10/dist-packages (from bertopic) (1.2.2)\nRequirement already satisfied: sentence-transformers>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from bertopic) (3.3.1)\nRequirement already satisfied: tqdm>=4.41.1 in /usr/local/lib/python3.10/dist-packages (from bertopic) (4.66.5)\nRequirement already satisfied: umap-learn>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from bertopic) (0.5.7)\nRequirement already satisfied: scipy>=1.0 in /usr/local/lib/python3.10/dist-packages (from hdbscan>=0.8.29->bertopic) (1.13.1)\nRequirement already satisfied: joblib>=1.0 in /usr/local/lib/python3.10/dist-packages (from hdbscan>=0.8.29->bertopic) (1.4.2)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.5->bertopic) (2.8.2)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.5->bertopic) (2024.2)\nRequirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.5->bertopic) (2024.1)\nRequirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from plotly>=4.7.0->bertopic) (9.0.0)\nRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from plotly>=4.7.0->bertopic) (24.1)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.22.2.post1->bertopic) (3.5.0)\nRequirement already satisfied: transformers<5.0.0,>=4.41.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers>=0.4.1->bertopic) (4.44.2)\nRequirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers>=0.4.1->bertopic) (2.4.1+cu121)\nRequirement already satisfied: huggingface-hub>=0.20.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers>=0.4.1->bertopic) (0.24.7)\nRequirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from sentence-transformers>=0.4.1->bertopic) (10.4.0)\nRequirement already satisfied: numba>=0.51.2 in /usr/local/lib/python3.10/dist-packages (from umap-learn>=0.5.0->bertopic) (0.60.0)\nRequirement already satisfied: pynndescent>=0.5 in /usr/local/lib/python3.10/dist-packages (from umap-learn>=0.5.0->bertopic) (0.5.13)\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers>=0.4.1->bertopic) (3.16.1)\nRequirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers>=0.4.1->bertopic) (2024.6.1)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers>=0.4.1->bertopic) (6.0.2)\nRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers>=0.4.1->bertopic) (2.32.3)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers>=0.4.1->bertopic) (4.12.2)\nRequirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba>=0.51.2->umap-learn>=0.5.0->bertopic) (0.43.0)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas>=1.1.5->bertopic) (1.16.0)\nRequirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers>=0.4.1->bertopic) (1.13.3)\nRequirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers>=0.4.1->bertopic) (3.3)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers>=0.4.1->bertopic) (3.1.4)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers>=0.4.1->bertopic) (2024.9.11)\nRequirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers>=0.4.1->bertopic) (0.4.5)\nRequirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers>=0.4.1->bertopic) (0.19.1)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers>=0.4.1->bertopic) (2.1.5)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers>=0.4.1->bertopic) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers>=0.4.1->bertopic) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers>=0.4.1->bertopic) (2.2.3)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers>=0.4.1->bertopic) (2024.8.30)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.11.0->sentence-transformers>=0.4.1->bertopic) (1.3.0)\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"import json\n\nwith open(\"/kaggle/input/slic-data-cases/indices.json\", 'r') as json_file:\n    data_represent = json.load(json_file)\n\ncase_a = []\ncase_b = []\n\nmisclassified = []\n\ntag = 1\n\ncase_a_file = \"/GPT 4 Vision/HARM_C/CASE 3\"\ncase_b_file = \"/GPT 4 Vision/HARM_C/CASE 4\"\n\nfor itemize in data_represent[case_a_file]:\n    case_a.append(itemize)\n    misclassified.append(itemize)\n\nfor itemize in data_represent[case_b_file]:\n    case_b.append(itemize)\n    misclassified.append(itemize)\n\nassert len(misclassified) == len(case_a) + len(case_b)\nprint(len(misclassified), len(case_a), len(case_b))\n\ncase_a_file = \"/GPT 4 Vision/HARM_P/CASE 3\"\ncase_b_file = \"/GPT 4 Vision/HARM_P/CASE 4\"\n\nfor itemize in data_represent[case_a_file]:\n    case_a.append(itemize)\n    misclassified.append(itemize)\n\nfor itemize in data_represent[case_b_file]:\n    case_b.append(itemize)\n    misclassified.append(itemize)\n\nassert len(misclassified) == len(case_a) + len(case_b)\nprint(len(misclassified), len(case_a), len(case_b))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-15T12:40:04.728068Z","iopub.execute_input":"2025-01-15T12:40:04.728316Z","iopub.status.idle":"2025-01-15T12:40:04.738492Z","shell.execute_reply.started":"2025-01-15T12:40:04.728295Z","shell.execute_reply":"2025-01-15T12:40:04.737817Z"}},"outputs":[{"name":"stdout","text":"33 13 20\n92 25 67\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"import json\n\ndocs = []\n\nfilename = '/kaggle/input/gpt-4o-outputs/gpt-4o explanations/gpt_4o_harm_c_def_ocr_in_ex_out.txt'\nwith open(filename, 'r') as file: \n    content = file.read()\n\ncounter = 0\nfor sample in content.split(\"##########\"):\n    splitted_sample = sample.split(\"----------\")\n    if len(splitted_sample) == 2:\n        counter += 1\n        json_image = json.loads(splitted_sample[0])[\"image\"].split(\"/\")[-1]\n        output_image = splitted_sample[1]\n        if json_image in misclassified:\n            docs.append(output_image)\n            assert int(json.loads(splitted_sample[0])[\"label\"]) == tag\n\nprint(counter)\n\nfilename = '/kaggle/input/gpt-4o-outputs/gpt-4o explanations/gpt_4o_harm_p_def_ocr_in_ex_out.txt'\nwith open(filename, 'r') as file: \n    content = file.read()\n\ncounter = 0\nfor sample in content.split(\"##########\"):\n    splitted_sample = sample.split(\"----------\")\n    if len(splitted_sample) == 2:\n        counter += 1\n        json_image = json.loads(splitted_sample[0])[\"image\"].split(\"/\")[-1]\n        output_image = splitted_sample[1]\n        if json_image in misclassified:\n            docs.append(output_image)\n            assert int(json.loads(splitted_sample[0])[\"label\"]) == tag\n\nprint(counter)\n\nassert len(docs) == len(misclassified)\nprint(len(docs))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-15T12:40:04.739443Z","iopub.execute_input":"2025-01-15T12:40:04.739675Z","iopub.status.idle":"2025-01-15T12:40:04.764718Z","shell.execute_reply.started":"2025-01-15T12:40:04.739655Z","shell.execute_reply":"2025-01-15T12:40:04.764113Z"}},"outputs":[{"name":"stdout","text":"354\n355\n92\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"from bertopic import BERTopic\n\nfrom bertopic.representation import KeyBERTInspired, VisualRepresentation\nfrom bertopic.backend import MultiModalBackend\nfrom sklearn.cluster import KMeans\n\nfrom sklearn.feature_extraction.text import CountVectorizer\n\nfrom umap import UMAP\n\ncluster_model = KMeans(n_clusters=2)\n\numap_model = UMAP(n_neighbors=15, n_components=5, min_dist=0.0, metric='cosine', random_state=42)\n\n# Vectorizer\nvectorizer_model = CountVectorizer(stop_words=\"english\")\n\n# Train our model with images only\ntopic_model = BERTopic(\n    umap_model=umap_model,\n    vectorizer_model=vectorizer_model,\n    hdbscan_model=cluster_model\n)\ntopics, probs = topic_model.fit_transform(documents=docs)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-15T12:40:04.765345Z","iopub.execute_input":"2025-01-15T12:40:04.765534Z","iopub.status.idle":"2025-01-15T12:40:06.025722Z","shell.execute_reply.started":"2025-01-15T12:40:04.765517Z","shell.execute_reply":"2025-01-15T12:40:06.025022Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"from IPython.display import HTML\n\n\n# Extract dataframe\ndf = topic_model.get_topic_info()\n\n# Visualize the images\nHTML(df.to_html(escape=False))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-15T12:40:06.026538Z","iopub.execute_input":"2025-01-15T12:40:06.026778Z","iopub.status.idle":"2025-01-15T12:40:06.036507Z","shell.execute_reply.started":"2025-01-15T12:40:06.026758Z","shell.execute_reply":"2025-01-15T12:40:06.035975Z"}},"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Topic</th>\n      <th>Count</th>\n      <th>Name</th>\n      <th>Representation</th>\n      <th>Representative_Docs</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>53</td>\n      <td>0_notharmful_meme_harm_individual</td>\n      <td>[notharmful, meme, harm, individual, does, cause, defamation, organization, humorous, humorously]</td>\n      <td>[\\nnot-harmful - This meme is a humorous exchange and does not appear to cause any harm, such as defamation, mental abuse, or emotional\\n, \\nnot-harmful - The meme does not target or defame a specific individual, organization, or community, nor does it cause mental abuse or emotional\\n, \\nnot-harmful - The meme does not contain any content that would cause harm to an individual, organization, community, or society. It appears to\\n]</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>39</td>\n      <td>1_political_notharmful_meme_harm</td>\n      <td>[political, notharmful, meme, harm, causing, individuals, organizations, individual, society, organization]</td>\n      <td>[\\nnot-harmful - The meme expresses a humorous political opinion about taxes without causing harm or defamation to any individual, organization, community, or society\\n, \\nnot-harmful - The meme expresses a political opinion without causing direct harm, defamation, or emotional disturbance to any individual, organization, or society\\n, \\nnot-harmful - The meme expresses a political viewpoint without targeting or causing harm to individuals, organizations, communities, or society. It encourages political involvement\\n]</td>\n    </tr>\n  </tbody>\n</table>"},"metadata":{}}],"execution_count":12},{"cell_type":"code","source":"grouped_topics = {topic: [] for topic in set(topics)}\nfor index, topic in enumerate(topics):\n    grouped_topics[topic].append(index)\nprint(grouped_topics)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-15T12:40:06.036998Z","iopub.execute_input":"2025-01-15T12:40:06.037264Z","iopub.status.idle":"2025-01-15T12:40:06.053567Z","shell.execute_reply.started":"2025-01-15T12:40:06.037243Z","shell.execute_reply":"2025-01-15T12:40:06.052735Z"}},"outputs":[{"name":"stdout","text":"{0: [0, 1, 3, 4, 5, 6, 7, 8, 10, 11, 12, 14, 15, 16, 17, 18, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 35, 41, 43, 45, 46, 48, 50, 51, 52, 53, 58, 61, 66, 67, 74, 76, 77, 79, 80, 81, 83, 87, 88, 91], 1: [2, 9, 13, 19, 33, 34, 36, 37, 38, 39, 40, 42, 44, 47, 49, 54, 55, 56, 57, 59, 60, 62, 63, 64, 65, 68, 69, 70, 71, 72, 73, 75, 78, 82, 84, 85, 86, 89, 90]}\n","output_type":"stream"}],"execution_count":13},{"cell_type":"code","source":"print(case_a_file, case_b_file, sep=\"\\n\")\n\na = 0\nb = 0\n\nassert len(grouped_topics) == 2\nassert 0 in grouped_topics and 1 in grouped_topics\n\nfor item in grouped_topics[0]:\n    if misclassified[item] in case_a:\n        a += 1\n    else:\n        assert misclassified[item] in case_b\n        b += 1\n\nprint(int(round(a/(a+b), 2)*100), int(round(b/(a+b), 2)*100))\n\na = 0\nb = 0\n\nfor item in grouped_topics[1]:\n    if misclassified[item] in case_a:\n        a += 1\n    else:\n        assert misclassified[item] in case_b\n        b += 1\n\nprint(int(round(a/(a+b), 2)*100), int(round(b/(a+b), 2)*100))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-15T12:40:06.054523Z","iopub.execute_input":"2025-01-15T12:40:06.054836Z","iopub.status.idle":"2025-01-15T12:40:06.068212Z","shell.execute_reply.started":"2025-01-15T12:40:06.054806Z","shell.execute_reply":"2025-01-15T12:40:06.067434Z"}},"outputs":[{"name":"stdout","text":"/GPT 4 Vision/HARM_P/CASE 3\n/GPT 4 Vision/HARM_P/CASE 4\n26 74\n28 72\n","output_type":"stream"}],"execution_count":14},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}